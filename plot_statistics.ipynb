{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark on OGB, https://ogb.stanford.edu/docs/home/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load node feauture: imdb_degree_dist_shuffled.npy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'my_utils' from '/li_zhengdao/github/GenerativeGNN/my_utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import random\n",
    "import argparse\n",
    "import configparser\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_sparse\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.utils import negative_sampling, to_networkx\n",
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptPairTensor, Adj, OptTensor, Size\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "\n",
    "from dataset_utils import node_feature_utils\n",
    "from dataset_utils.node_feature_utils import *\n",
    "import my_utils as utils\n",
    "\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MyIter(object):\n",
    "    def __init__(self, ite_obj) -> None:\n",
    "        self.ite_obj = ite_obj\n",
    "        self.ite = None\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.ite = iter(self.ite_obj)\n",
    "        return self.ite\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.ite is None:\n",
    "            self.__reset__()\n",
    "        try:\n",
    "            res = next(self.ite)\n",
    "            return res\n",
    "        except StopIteration as e:\n",
    "            self.__reset__()\n",
    "            \n",
    "        return next(self.ite)\n",
    "    \n",
    "    def __reset__(self):\n",
    "        self.ite = iter(self.ite_obj)\n",
    "    \n",
    "    \n",
    "l= [ 1, 2, 3]\n",
    "a = MyIter(l)\n",
    "\n",
    "for i in range(10):\n",
    "    print(a.__next__())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dist = [3,3,3,2,2,2,1,1,1,1,1,1,1,1]\n",
    "node_fea = np.random.choice(sample_dist, size=100).__iter__()\n",
    "print(len(node_fea))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ss = []\n",
    "dd = []\n",
    "\n",
    "each_num = 33\n",
    "for i in list(range(80, 80+2*60+1, 60)):\n",
    "    # NOTE: class1 N = 80, p=0.4, avgD = 30, \n",
    "    # NOTE: class2 N = 140, p=0.4, avgD = 50,\n",
    "    # NOTE: class3 N = 200, p=0.4, avgD = 80, \n",
    "    for _ in range(each_num):\n",
    "        g = nx.erdos_renyi_graph(i, 0.4)\n",
    "        stats = graph_stats_degree(adj=nx.to_numpy_array(g))\n",
    "        ss.append(stats)\n",
    "\n",
    "for i in list(np.arange(0.3, 1, 0.3)):\n",
    "    # NOTE: class1 N = 100, p=0.3, avgD = 30,\n",
    "    # NOTE: class2 N = 100, p=0.6, avgD = 50,\n",
    "    # NOTE: class3 N = 100, p=0.9, avgD = 80, \n",
    "    for _ in range(each_num):\n",
    "        g = nx.erdos_renyi_graph(100, i)\n",
    "        stats = graph_stats_degree(adj=nx.to_numpy_array(g))\n",
    "        dd.append(stats)\n",
    "    \n",
    "ss = np.stack(ss, axis=0)\n",
    "dd = np.stack(dd, axis=0)\n",
    "plt.plot(ss[:, 0],label='same p, avgD')\n",
    "plt.plot(dd[:, 0],label='same N, avgD')\n",
    "# plt.plot(ss[:, 2], label='totalD')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "# here..\n",
    "cmaps = {}\n",
    "\n",
    "gradient = np.linspace(0, 1, 256)\n",
    "gradient = np.vstack((gradient, gradient))\n",
    "\n",
    "\n",
    "x_y_label_font = 20\n",
    "x_y_legend_font = 20\n",
    "\n",
    "plt.rc('font', family='Times New Roman')\n",
    "fig_dpi = 220\n",
    "fig_shape_squre = (6, 5)\n",
    "\n",
    "def plot_color_gradients(category, cmap_list):\n",
    "    # Create figure and adjust figure height to number of colormaps\n",
    "    nrows = len(cmap_list)\n",
    "    figh = 0.35 + 0.15 + (nrows + (nrows - 1) * 0.1) * 0.22\n",
    "    fig, axs = plt.subplots(nrows=nrows + 1, figsize=(6.4, figh), dpi=100)\n",
    "    fig.subplots_adjust(top=1 - 0.35 / figh, bottom=0.15 / figh,\n",
    "                        left=0.2, right=0.99)\n",
    "    axs[0].set_title(f'{category} colormaps', fontsize=14)\n",
    "\n",
    "    for ax, name in zip(axs, cmap_list):\n",
    "        ax.imshow(gradient, aspect='auto', cmap=plt.get_cmap(name))\n",
    "        ax.text(-0.01, 0.5, name, va='center', ha='right', fontsize=10,\n",
    "                transform=ax.transAxes)\n",
    "\n",
    "    # Turn off *all* ticks & spines, not just the ones with colormaps.\n",
    "    for ax in axs:\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    # Save colormap list for later.\n",
    "    cmaps[category] = cmap_list\n",
    "    plt.show()\n",
    "\n",
    "class MyColor(object):\n",
    "    def __init__(self, cmap_name='tab10', skip_idx=5, backup_name='Set1', backup_color=3):\n",
    "        self.color_set  = plt.get_cmap(cmap_name).colors\n",
    "        self.backup_set = plt.get_cmap(backup_name).colors\n",
    "        self.backup_color = backup_color\n",
    "        self.skip_idx=skip_idx\n",
    "        self.idx = 0\n",
    "        self.color_len = len(self.color_set)\n",
    "        \n",
    "    def get_color(self, by_id=None):\n",
    "        if by_id is not None:\n",
    "            return self.color_set[by_id]\n",
    "        \n",
    "        if self.idx == self.color_len - 1:\n",
    "            self.idx = 0\n",
    "        if self.idx == self.skip_idx:\n",
    "            self.idx += 1\n",
    "            return self.backup_set[self.backup_color]\n",
    "        color = self.color_set[self.idx]\n",
    "        self.idx += 1\n",
    "        return color\n",
    "    \n",
    "\n",
    "plot_color_gradients('Qualitative',\n",
    "                     ['Pastel1', 'Pastel2', 'Paired', 'Accent', 'Dark2',\n",
    "                      'Set1', 'Set2', 'Set3', 'tab10', 'tab20', 'tab20b',\n",
    "                      'tab20c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: 0918. For all benchmark datasets.\n",
    "* check the correlation between degree and CC \n",
    "* or $|C_k|$, $k>3$\n",
    "* Why related to training difficulty? because that GNN cannot learn them.\n",
    "* Why cannot learn? computational graphs are the same and is bounded by k-WL-test.\n",
    "* So requires additional information of subgraphs, but $O(kN)$ complexity.\n",
    "* so sampling may be a good choice.\n",
    "* may use DP to sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* based on above figure, pick same horizontal points\n",
    "- blueK=0.2, p=0.3, orangeK=0.25, p=0.35, greenK=0.3, p= 0.6,\n",
    "- redK=0.35,p=0.6, orangek=0.25, p=0.3 (try this first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate WS graph node feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct node clustring coefficient label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate WS graph dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCA (Canical Component Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check whether GNN can learn the CC ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate CC historgram with same degree\n",
    "# cc without degree correlation bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load OGB dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import ticker\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "\n",
    "\n",
    "x_y_label_font = 10\n",
    "x_y_legend_font = 10\n",
    "\n",
    "\n",
    "def plot_bars(X, y, y_err=None, legend_pos=None, label=\"None\", ax=None, colors=None, width=0.1):\n",
    "    color = 'black'\n",
    "    err_attr={\"elinewidth\":2,\"ecolor\":\"black\",\"capsize\":6}\n",
    "    if colors is None:\n",
    "         colors = ['#F9DA4A','#96DB35', '#66C2A5','#81B0D3','#EF8C61']\n",
    "         \n",
    "    # ax.bar(X, y, yerr=y_err, error_kw=err_attr, color = colors,\n",
    "    #         width=width, label=label)\n",
    "    ax.bar(X, y, color = colors,\n",
    "             width=width, tick_label=label)\n",
    "    \n",
    "    ax.set_ylabel('Correlation', color=color, fontsize=x_y_label_font)\n",
    "    \n",
    "     # fontsize=15, fontweight='bold')\n",
    "    ax.tick_params(axis='y', labelcolor=color, labelsize=x_y_label_font)\n",
    "    ax.tick_params(axis='x', rotation=70, labelsize=x_y_label_font)\n",
    "    # plt.xticks(rotation=180)\n",
    "    \n",
    "    # ax.tick_params(axis='x)\n",
    "    # ax.legend([logit.m1], prop={'size': 15}, labelspacing=0.1)\n",
    "#     ax.set_title(label, fontsize=x_y_label_font)\n",
    "    # plt.rcParams['xtick.direction'] = 'in'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test bar:\n",
    "xxx = np.linspace(0, 1, num=3)\n",
    "fig, axess = plt.subplots(1, 2)\n",
    "\n",
    "plot_bars(xxx, [1,-1,2], ax=axess[0])\n",
    "plot_bars(xxx, [1,-1,2], ax=axess[1])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_utils as utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "import networkx as nx\n",
    "from functools import reduce\n",
    "import models\n",
    "importlib.reload(models)\n",
    "\n",
    "\n",
    "def graphs_statistics(adjs:list, labels:list):\n",
    "    \n",
    "    statistics = []\n",
    "    for i, A in enumerate(adjs):\n",
    "        nx_g = nx.from_numpy_array(A)\n",
    "        avg_cc = nx.average_clustering(nx_g)\n",
    "        degree_set = node_feature_utils.node_degree_feature(adj=A)\n",
    "        avg_degree = np.mean(degree_set).item()\n",
    "        tris = np.mean(node_feature_utils.node_tri_cycles_feature(adj=A)).item()\n",
    "        cycles = nx.cycle_basis(nx_g)\n",
    "        N = A.shape[0]\n",
    "        minD = np.min(degree_set)\n",
    "        maxD = np.max(degree_set)\n",
    "        statistics.append((N, avg_cc, avg_degree, tris, cycles, labels[i], minD, maxD))\n",
    "    \n",
    "    return statistics\n",
    "\n",
    "\n",
    "def plot_cyc_degree_corr(title:str, statistics_sorted:list, data_labels:tuple, axe=None, \n",
    "                           sort_idx=None, show_idx:list=None, anchor:int=None,corrs_type='MIC', need_filter=True):\n",
    "    # NOTE: Sorted by other index\n",
    "    if sort_idx is not None:\n",
    "        statistics_sorted = sorted(statistics_sorted, key=lambda x: x[sort_idx])\n",
    "        \n",
    "    if need_filter:\n",
    "        # TODO: Filter cycles and degree outliers, abs(z-score) > 3.\n",
    "        statistics_sorted_filtered = []\n",
    "        for i in statistics_sorted:\n",
    "            # NOTE: filter any outliers:\n",
    "            need_filter = False\n",
    "            for l in range(len(i)):\n",
    "                if i[l] < -3 or i[l] > 3 or i[l] < -3 or i[l] > 3:\n",
    "                    need_filter = True\n",
    "                    break\n",
    "                \n",
    "            if need_filter:\n",
    "                continue\n",
    "            \n",
    "            statistics_sorted_filtered.append(i)\n",
    "        \n",
    "        statistics_sorted = statistics_sorted_filtered\n",
    "        \n",
    "    # TODO: Get correlation:\n",
    "    corrs = utils.get_corrs(statistics_sorted, cate='all')\n",
    "\n",
    "    if axe is None:\n",
    "        fig = plt.figure()\n",
    "        axe = plt.gca()\n",
    "        \n",
    "    axe.set_title(title)\n",
    "    \n",
    "    if show_idx is None:\n",
    "        show_idx = list(range(len(statistics_sorted[0])))\n",
    "    print('corrs shape', corrs[corrs_type].shape)\n",
    "    X = np.linspace(0, 1, len(show_idx))\n",
    "    y = np.array([np.abs(corrs[corrs_type][id, anchor]) for id in show_idx])\n",
    "    color = MyColor('Accent', skip_idx=3, backup_name='Set1', backup_color=7)\n",
    "    colors = [color.get_color() for _ in show_idx]\n",
    "    legends = [data_labels[i] for i in show_idx]\n",
    "    plot_bars(X, y,label=legends, ax=axe, colors=colors)\n",
    "    \n",
    "    \n",
    "def plot_graphs_statistics(title:str, statistics_sorted:list, data_labels:tuple, axe=None, \n",
    "                           sort_idx=None, show_idx:list=None, plot_corr_bar=False, need_filter=True):\n",
    "    from matplotlib import lines\n",
    "    line_styles = list(lines.lineStyles.keys())\n",
    "    def get_style(next_id):\n",
    "        if next_id < 0:\n",
    "            next_id += len(line_styles)\n",
    "        return line_styles[next_id%len(line_styles)]\n",
    "    \n",
    "    colors = MyColor()\n",
    "    \n",
    "    if not isinstance(statistics_sorted, list):\n",
    "        statistics_sorted = [i for i in statistics_sorted]\n",
    "        \n",
    "    print(statistics_sorted[0].shape)\n",
    "    # NOTE: Sorted by other index\n",
    "    if sort_idx is not None:\n",
    "        statistics_sorted = sorted(statistics_sorted, key=lambda x: x[sort_idx])\n",
    "        \n",
    "    # TODO: Filter cycles and degree outliers, abs(z-score) > 3.\n",
    "    if need_filter:\n",
    "        statistics_sorted_filtered = []\n",
    "        for i in statistics_sorted:\n",
    "            # NOTE: filter any outliers:\n",
    "            need_filter = False\n",
    "            for l in range(len(i)-2):\n",
    "                \n",
    "                # TODO: only filter normlized data:\n",
    "                if i[l] < -3 or i[l] > 3 or i[l] < -3 or i[l] > 3:\n",
    "                    need_filter = True\n",
    "                    break\n",
    "            if need_filter:\n",
    "                continue\n",
    "            \n",
    "            statistics_sorted_filtered.append(i)\n",
    "        \n",
    "        statistics_sorted = statistics_sorted_filtered\n",
    "    # TODO: Get correlation:\n",
    "    # corrs = utils.get_corrs(statistics_sorted, cate='all')\n",
    "    \n",
    "    if plot_corr_bar:\n",
    "        axe.set_title(title)\n",
    "        axe.plot_bar\n",
    "    \n",
    "    if axe is not None:\n",
    "        # MIC_corr = f\"M(dc)={round(corrs['MIC'][1, -2], 2)}, M(dy)={round(corrs['MIC'][1, -1], 2)},\" \\\n",
    "                    #  + f\" M(cy)={round(corrs['MIC'][-2, -1], 2)}\"\n",
    "        # axe.set_title(title+f\"\\n C(dc)={round(corrs['pearson'][1, -2], 2)}, C(dy)={round(corrs['pearson'][1, -1], 2)},\" \\\n",
    "                    #  + f\" C(cy)={round(corrs['pearson'][-2, -1], 2)}\\n{MIC_corr}\")\n",
    "        axe.set_title(title)\n",
    "        # NOTE: C: correlation, d:degree, c: cycles, y:labels of samples.\n",
    "        \n",
    "        \n",
    "        if show_idx is None:\n",
    "            show_idx = list(range(len(statistics_sorted[0])))\n",
    "        \n",
    "        \n",
    "        for sid in show_idx:\n",
    "            # TODO: color?\n",
    "            axe.plot([i[sid] for i in statistics_sorted], label=data_labels[sid], \n",
    "                     linestyle=get_style(sid), color=colors.get_color())\n",
    "            \n",
    "    else:\n",
    "        plt.figure()\n",
    "        plt.title(title)\n",
    "        if show_idx is None:\n",
    "            show_idx = list(range(len(statistics_sorted[0])))\n",
    "            \n",
    "        print('avgD/N', statistics_sorted[0][4])\n",
    "        \n",
    "        for id in show_idx:\n",
    "            plt.plot([i[id] for i in statistics_sorted], label=data_labels[id], color=colors.get_color())\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_cc_degree_distribution(cc_degree_graphs, cc_degree_y, g_label='train'):\n",
    "    \n",
    "    # random add edges:\n",
    "    # add E edges, repeat for 5 times.\n",
    "    print(type(cc_degree_graphs[0].todense()))\n",
    "\n",
    "    data_graphs = [(cc_degree_y[i],np.mean(np.sum(cc_degree_graphs[i].todense(), axis=1)), np.mean(node_feature_utils.node_tri_cycles_feature(adj=cc_degree_graphs[i])).item(), i) for i in range(len(cc_degree_graphs))]\n",
    "\n",
    "    data_graphs_s_train = sorted(data_graphs, key=lambda x: x[0])\n",
    "\n",
    "    ccs = [d[0] for d in data_graphs_s_train]\n",
    "    degrees = [d[1]/10 for d in data_graphs_s_train]\n",
    "    tri_cycles = [d[2]/4 for d in data_graphs_s_train]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(g_label)\n",
    "    plt.plot(ccs, label='labels')\n",
    "    plt.plot(degrees, label='degree',  linestyle='--')\n",
    "    plt.plot(tri_cycles, label='tri_cycles', linestyle='-.')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Real-world dataset from PyG generic datasets\n",
    "website: `https://pytorch-geometric.readthedocs.io/en/latest/notes/data_cheatsheet.html`\n",
    "\n",
    "* graph classification:\n",
    "    * TUDataset\n",
    "    * ZINC\n",
    "\n",
    "## TODO: \n",
    "1. use. # due: 6.30.\n",
    "2. profile. # due: 7.1.\n",
    "\n",
    "## TODO (2022.09.24):\n",
    "* 1. load from gnn-comparison module.\n",
    "* 2. check the avg.CC avg.Degree and performance associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets:\n",
    "\n",
    "import sys,os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "\n",
    "import my_utils\n",
    "\n",
    "from PrepareDatasets import DATASETS\n",
    "\n",
    "import dataset_utils\n",
    "print(DATASETS.keys())\n",
    "\n",
    "datasets_obj = {}\n",
    "for k, v in DATASETS.items():\n",
    "    print('dataset name:', k)\n",
    "    dat = v()\n",
    "    datasets_obj[k] = dat\n",
    "    print(type(dat.dataset.get_data()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['REDDIT-BINARY', 'REDDIT-MULTI-5K', 'COLLAB', 'IMDB-BINARY', 'IMDB-MULTI', 'NCI1', 'ENZYMES', 'PROTEINS', 'DD', 'MUTAG', 'CSL'])\n",
      "loaded dataset, name: PROTEINS\n",
      "processed_dir:  DATA/PROTEINS_full/processed\n",
      "total node num: 43471\n",
      "in _process\n",
      "saved: DATA/PROTEINS_full/processed / saved : PROTEINS_full.pt\n",
      "load dataset !\n",
      "dataset len:  1113\n",
      "split counts: 10\n",
      "<class 'list'>\n",
      "loaded dataset, name: DD\n",
      "processed_dir:  DATA/DD/processed\n",
      "total node num: 334925\n",
      "in _process\n",
      "saved: DATA/DD/processed / saved : DD.pt\n",
      "load dataset !\n",
      "dataset len:  1178\n",
      "load splits: DATA/DD/processed/DD_splits.json\n",
      "split counts: 10\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Load specific dataset:\n",
    "\n",
    "import sys,os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "\n",
    "from PrepareDatasets import DATASETS\n",
    "import my_utils\n",
    "import dataset_utils\n",
    "\n",
    "\n",
    "print(DATASETS.keys())\n",
    "\"\"\"\n",
    "    'REDDIT-BINARY': RedditBinary,\n",
    "    'REDDIT-MULTI-5K': Reddit5K,\n",
    "    'COLLAB': Collab,\n",
    "    'IMDB-BINARY': IMDBBinary,\n",
    "    'IMDB-MULTI': IMDBMulti,\n",
    "    'NCI1': NCI1,\n",
    "    'ENZYMES': Enzymes,\n",
    "    'PROTEINS': Proteins,\n",
    "    'DD': DD,\n",
    "    \"MUTAG\": Mutag,\n",
    "    'CSL': CSL\n",
    "\"\"\"\n",
    "\n",
    "data_names = ['IMDB-BINARY']\n",
    "data_names = ['PROTEINS', 'DD']\n",
    "datasets_obj = {}\n",
    "for k, v in DATASETS.items():\n",
    "    if k not in data_names:\n",
    "        continue\n",
    "    \n",
    "    print('loaded dataset, name:', k)\n",
    "    dat = v(use_node_attrs=True, DATA_DIR='./DATA')\n",
    "    datasets_obj[k] = dat\n",
    "    print(type(dat.dataset.get_data()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(N=20, edge_index=[2, 146], x=[20, 0], y=[1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_obj['IMDB-BINARY'].dataset.get_data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pyg_dataset_stats(pyg_data):\n",
    "    adjs = []\n",
    "    # TODO: transform into networkx.\n",
    "    labels = []\n",
    "    for graph in pyg_data.dataset.get_data():\n",
    "        row = graph.edge_index[0]\n",
    "        col = graph.edge_index[1]\n",
    "        graph.y\n",
    "        N = graph.x.shape[0]\n",
    "        dense_A = torch.zeros((N, N))\n",
    "        dense_A[row, col] = 1\n",
    "        A = dense_A.detach().numpy()\n",
    "        adjs.append(A)\n",
    "        labels.append(graph.y.item())\n",
    "    return graphs_statistics(adjs, labels)\n",
    "\n",
    "\n",
    "# print(node_feature_utils.node_cc_avg_feature(adj=dense_A.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2c9b56f82921>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcds_mutag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mutag_degree_dist.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcds_mutag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcds_mutag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcds_mutag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcds_mutag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "cds_mutag = np.load('mutag_degree_dist.npy').__iter__()\n",
    "print(cds_mutag.__next__().item())\n",
    "print(cds_mutag.__next__().item())\n",
    "print(cds_mutag.__next__().item())\n",
    "print(cds_mutag.__next__().item())\n",
    "print(cds_mutag.__next__().item())\n",
    "print(cds_mutag.__next__().item())\n",
    "print(cds_mutag.__next__().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# generate node degree feature:\n",
    "import dataset_utils.node_feature_utils as nfu\n",
    "# TODO: check shuffle func:\n",
    "\n",
    "def shuffle2(data, data_name):\n",
    "    node_num_total = 0\n",
    "    node_index = {}\n",
    "    start_id = 0\n",
    "    copy_degree_sequence = []\n",
    "    for i, d in enumerate(data):\n",
    "        node_num = d.x.shape[0]\n",
    "        node_num_total += node_num\n",
    "        for j in range(node_num):\n",
    "            node_index[start_id] = (i, j)\n",
    "            start_id += 1\n",
    "            copy_degree_sequence.append(d.x[j].item())\n",
    "    \n",
    "    # dump copy_degree_sequece:\n",
    "    cds = np.array(copy_degree_sequence)\n",
    "    print('cds shape:', cds.shape, cds[:100])\n",
    "    print('max 10000 csd:', np.max(cds))\n",
    "    np.save(f'{data_name}_degree_dist.npy', cds)\n",
    "    print(f'dumped {data_name}_degree_dist.npy!!!')\n",
    "    \n",
    "    np.random.shuffle(copy_degree_sequence)\n",
    "    cds_shuffle = np.array(copy_degree_sequence)\n",
    "    print('cds_shuffle shape:', cds_shuffle.shape, cds_shuffle[:100])\n",
    "    print('cds_shuffle max 10000 csd:', np.max(cds_shuffle))\n",
    "\n",
    "    np.save(f'{data_name}_degree_dist_shuffled.npy', cds_shuffle)\n",
    "    print(f'dumped {data_name}_degree_dist_shuffled.npy!!!')\n",
    "    \n",
    "    shuf_idx = list(np.arange(node_num_total))\n",
    "    pre_value = data[0].x\n",
    "    print('pre_value: ', pre_value)\n",
    "    sample_ids = [s for s in np.random.choice(shuf_idx, size=node_num_total, replace=True)].__iter__()\n",
    "    # sample_ids = np.random.randint(1, int(4), size=len(shuf_idx)).__iter__()\n",
    "    \n",
    "    for d in data:\n",
    "        new_x = []\n",
    "        N = d.x.shape[0]\n",
    "        for i in range(N):\n",
    "            new_x.append(copy_degree_sequence[sample_ids.__next__().item()])\n",
    "            \n",
    "        d.x = np.array(new_x).reshape(N, 1)\n",
    "        \n",
    "    print('replaced value:', data[0].x)\n",
    "    print(data[0].x - pre_value)\n",
    "\n",
    "def shuffle(data):\n",
    "    node_num_total = 0\n",
    "    node_index = {}\n",
    "    start_id = 0\n",
    "    for i, d in enumerate(data):\n",
    "        node_num = d.x.shape[0]\n",
    "        node_num_total += node_num\n",
    "        for j in range(node_num):\n",
    "            node_index[start_id] = (i, j)\n",
    "            start_id += 1\n",
    "            \n",
    "    shuf_idx = list(np.arange(node_num_total))\n",
    "    np.random.shuffle(shuf_idx)\n",
    "    np.random.shuffle(shuf_idx)\n",
    "    np.random.shuffle(shuf_idx)\n",
    "    # construct pairs\n",
    "    pairs = []\n",
    "    for i in range(0, len(shuf_idx), 2):\n",
    "        if i + 1 < len(shuf_idx):\n",
    "            pairs.append((shuf_idx[i], shuf_idx[i+1]))\n",
    "\n",
    "    print(f'shuffle feature!, total len: {node_num_total}, pair len: {len(pairs)}')\n",
    "    # reconstruct:\n",
    "    for (p1, p2) in pairs:\n",
    "        # swich p1 p2 in place\n",
    "        p1_node, p1_x_id = node_index[p1]\n",
    "        p2_node, p2_x_id = node_index[p2]\n",
    "        tmp = data[p1_node].x[p1_x_id]\n",
    "        data[p1_node].x[p1_x_id] = data[p2_node].x[p2_x_id]\n",
    "        data[p2_node].x[p2_x_id] = tmp\n",
    "        \n",
    "        if p1_node == 3 or p2_node == 3:\n",
    "            print('node 1:', p1_node, p1_x_id, ' to node2:', p2_node, p2_x_id)\n",
    "        \n",
    "        \n",
    "def plot_st(cur_fea):\n",
    "    \n",
    "    max_dd = [s[0] for s in cur_fea]\n",
    "    min_dd = [s[1] for s in cur_fea]\n",
    "    mean_dd = [s[2] for s in cur_fea]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(max_dd)\n",
    "    plt.plot(min_dd)\n",
    "    plt.plot(mean_dd)\n",
    "    plt.ylim(0, 3.1)\n",
    "    plt.show()\n",
    "   \n",
    "\n",
    "# normalize:\n",
    "# print(data[0].x)\n",
    "# node_degree_fea = my_utils.normalize(\n",
    "#             node_degree_fea, along_axis=-1, same_data_shape=False)\n",
    "\n",
    "# node_randid_fea = my_utils.normalize(\n",
    "#             node_randid_fea, along_axis=-1, same_data_shape=False)\n",
    "\n",
    "# node_guass_fea = my_utils.normalize(\n",
    "#             node_guass_fea, along_axis=-1, same_data_shape=False)\n",
    "\n",
    "\n",
    "\n",
    "# # plot original degree dist:\n",
    "# dd = [(np.max(n),np.min(n), np.mean(n)) for n in node_degree_fea]\n",
    "# plot_st(dd)\n",
    "\n",
    "# # plot shuffled degree dist:\n",
    "# # # # get shuffle feature:\n",
    "# node_degree_shuffle = [d.x for d in data]\n",
    "# dd_shuf = [(np.max(n),np.min(n), np.mean(n)) for n in node_degree_shuffle]\n",
    "# plot_st(dd_shuf)\n",
    "\n",
    "# # plot rand id dist:\n",
    "# randfea = [(np.max(n),np.min(n), np.mean(n)) for n in node_randid_fea]\n",
    "# plot_st(randfea)\n",
    "\n",
    "# # plot guass dist:\n",
    "# gaussfea = [(np.max(n),np.min(n), np.mean(n)) for n in node_guass_fea]\n",
    "# plot_st(gaussfea)\n",
    "\n",
    "# sort:\n",
    "\n",
    "# dd = sorted(dd, key=lambda x:x[0])\n",
    "\n",
    "# d_fea = np.concatenate(node_degree_fea, axis=0)\n",
    "\n",
    "# print(d_fea.shape)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(d_fea[:, 0], 100, density=False, facecolor='g', alpha=0.75)\n",
    "# plt.xlabel('degree')\n",
    "# plt.ylabel('node amount')\n",
    "# plt.show()\n",
    "\n",
    "# TODO: assign node feature from samples from shuffled original degree set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load node feauture: imdb_degree_dist_shuffled.npy\n",
      "\n",
      "cds shape: (43471,) [3. 3. 3. 5. 6. 3. 3. 4. 5. 6. 3. 3. 3. 4. 4. 3. 4. 3. 4. 8. 3. 3. 4. 5.\n",
      " 3. 3. 3. 3. 3. 3. 3. 6. 4. 5. 4. 4. 3. 3. 4. 4. 3. 6. 3. 3. 4. 4. 3. 3.\n",
      " 3. 4. 4. 4. 3. 3. 3. 3. 4. 4. 3. 3. 3. 3. 3. 3. 3. 4. 5. 4. 3. 3. 3. 4.\n",
      " 3. 3. 5. 4. 3. 3. 3. 3. 4. 4. 6. 3. 3. 4. 4. 3. 7. 4. 6. 3. 6. 4. 3. 2.\n",
      " 3. 3. 4. 2.]\n",
      "max 10000 csd: 25.0\n",
      "dumped proteins_degree_dist.npy!!!\n",
      "cds_shuffle shape: (43471,) [3. 4. 6. 1. 6. 6. 4. 3. 3. 6. 5. 3. 3. 3. 6. 5. 3. 3. 2. 3. 2. 3. 5. 6.\n",
      " 4. 3. 4. 5. 5. 3. 4. 3. 3. 3. 3. 3. 3. 4. 4. 6. 4. 3. 3. 3. 3. 5. 5. 5.\n",
      " 5. 5. 2. 3. 3. 4. 3. 4. 3. 5. 4. 3. 2. 3. 4. 3. 4. 4. 5. 4. 4. 3. 2. 5.\n",
      " 3. 4. 3. 3. 4. 4. 4. 5. 3. 4. 3. 5. 5. 3. 4. 3. 3. 3. 4. 3. 4. 3. 3. 3.\n",
      " 4. 3. 3. 4.]\n",
      "cds_shuffle max 10000 csd: 25.0\n",
      "dumped proteins_degree_dist_shuffled.npy!!!\n",
      "pre_value:  [[3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [5.]\n",
      " [6.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [5.]\n",
      " [6.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [8.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [5.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [6.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [6.]]\n",
      "replaced value: [[3.]\n",
      " [3.]\n",
      " [7.]\n",
      " [5.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [5.]\n",
      " [3.]\n",
      " [4.]\n",
      " [5.]\n",
      " [6.]\n",
      " [3.]\n",
      " [4.]\n",
      " [6.]\n",
      " [2.]\n",
      " [3.]\n",
      " [6.]\n",
      " [4.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [5.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [5.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [5.]\n",
      " [3.]\n",
      " [4.]\n",
      " [5.]\n",
      " [3.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 4.]\n",
      " [ 0.]\n",
      " [-3.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [-5.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [ 3.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [-2.]\n",
      " [ 2.]\n",
      " [-1.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [-2.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [-3.]]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(nfu)\n",
    "\n",
    "\n",
    "node_degree_fea = []\n",
    "node_randid_fea = []\n",
    "data = datasets_obj['PROTEINS'].dataset.get_data()\n",
    "node_guass_fea = []\n",
    "# data = datasets_obj['IMDB-BINARY'].dataset.get_data()\n",
    "\n",
    "for g in data:\n",
    "    adj = g.to_numpy_array()\n",
    "    g.x = nfu.node_degree_feature(adj=adj, checkpoint=False)\n",
    "\n",
    "\n",
    "shuffle2(data, data_name='proteins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load node feauture: imdb_degree_dist_shuffled.npy\n",
      "\n",
      "cds shape: (334925,) [9. 7. 6. 6. 7. 4. 6. 6. 5. 6. 5. 8. 7. 4. 6. 6. 6. 7. 6. 7. 7. 6. 6. 7.\n",
      " 6. 4. 6. 5. 7. 5. 9. 6. 7. 8. 6. 5. 5. 5. 8. 6. 4. 7. 4. 6. 4. 5. 5. 5.\n",
      " 6. 4. 3. 5. 8. 3. 8. 7. 5. 5. 7. 6. 6. 7. 8. 6. 8. 6. 7. 5. 6. 6. 7. 7.\n",
      " 7. 7. 8. 5. 6. 6. 7. 5. 7. 9. 2. 3. 7. 4. 4. 2. 2. 5. 6. 2. 5. 7. 4. 3.\n",
      " 6. 4. 7. 5.]\n",
      "max 10000 csd: 19.0\n",
      "dumped dd_degree_dist.npy!!!\n",
      "cds_shuffle shape: (334925,) [7. 8. 6. 4. 8. 8. 2. 7. 5. 6. 5. 4. 4. 2. 3. 3. 6. 7. 4. 5. 2. 5. 5. 5.\n",
      " 8. 5. 7. 5. 5. 5. 6. 4. 4. 4. 6. 4. 8. 3. 6. 4. 4. 5. 4. 3. 6. 4. 3. 4.\n",
      " 4. 7. 4. 5. 6. 2. 5. 5. 4. 2. 6. 6. 4. 9. 6. 5. 2. 5. 4. 3. 4. 5. 5. 3.\n",
      " 6. 3. 3. 9. 7. 4. 3. 6. 7. 4. 5. 7. 5. 3. 6. 3. 5. 4. 6. 5. 3. 6. 4. 5.\n",
      " 6. 5. 4. 5.]\n",
      "cds_shuffle max 10000 csd: 19.0\n",
      "dumped dd_degree_dist_shuffled.npy!!!\n",
      "pre_value:  [[ 9.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 9.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 8.]\n",
      " [ 3.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 2.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [10.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 2.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 8.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 2.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 9.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [11.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 2.]\n",
      " [ 6.]\n",
      " [ 9.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 2.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 3.]]\n",
      "replaced value: [[ 5.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 9.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 9.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 2.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 7.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [ 7.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 9.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 9.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 9.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 2.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 2.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 2.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 2.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 3.]\n",
      " [ 3.]\n",
      " [ 7.]\n",
      " [ 2.]\n",
      " [ 5.]\n",
      " [ 2.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 2.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 2.]\n",
      " [ 7.]\n",
      " [ 6.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 7.]\n",
      " [ 8.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 7.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 4.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 7.]\n",
      " [ 3.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 5.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 3.]\n",
      " [ 8.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 4.]\n",
      " [ 6.]\n",
      " [ 4.]\n",
      " [ 6.]]\n",
      "[[-4.]\n",
      " [-4.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [-3.]\n",
      " [ 0.]\n",
      " [-3.]\n",
      " [-1.]\n",
      " [ 4.]\n",
      " [-2.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [-2.]\n",
      " [ 3.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [-2.]\n",
      " [ 1.]\n",
      " [-3.]\n",
      " [-1.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-3.]\n",
      " [-1.]\n",
      " [-2.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-2.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [-3.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [ 2.]\n",
      " [-2.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [-2.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [-3.]\n",
      " [-4.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [-3.]\n",
      " [-2.]\n",
      " [ 0.]\n",
      " [-4.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [-3.]\n",
      " [-2.]\n",
      " [-4.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-4.]\n",
      " [-2.]\n",
      " [-5.]\n",
      " [-2.]\n",
      " [-4.]\n",
      " [-1.]\n",
      " [-2.]\n",
      " [-3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [-4.]\n",
      " [-5.]\n",
      " [ 3.]\n",
      " [ 1.]\n",
      " [-3.]\n",
      " [-1.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [-2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 4.]\n",
      " [-3.]\n",
      " [ 0.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-3.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-3.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [ 4.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 1.]\n",
      " [ 5.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [ 2.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 2.]\n",
      " [ 5.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-2.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [-4.]\n",
      " [-3.]\n",
      " [ 5.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 2.]\n",
      " [-4.]\n",
      " [ 0.]\n",
      " [ 4.]\n",
      " [-4.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [-4.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [-4.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-4.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [ 2.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [ 3.]\n",
      " [-2.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [-3.]\n",
      " [-2.]\n",
      " [-7.]\n",
      " [ 2.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [-3.]\n",
      " [ 1.]\n",
      " [-2.]\n",
      " [-6.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [-1.]\n",
      " [-3.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [-4.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [-4.]\n",
      " [-1.]\n",
      " [-3.]\n",
      " [-1.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [ 4.]\n",
      " [ 1.]\n",
      " [ 4.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-3.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 3.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-2.]\n",
      " [-3.]\n",
      " [-2.]\n",
      " [-4.]\n",
      " [-2.]\n",
      " [ 2.]\n",
      " [-2.]\n",
      " [ 0.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-4.]\n",
      " [-1.]\n",
      " [ 2.]\n",
      " [-4.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 3.]\n",
      " [-3.]\n",
      " [-5.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [-3.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [-2.]\n",
      " [ 1.]\n",
      " [-3.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [-3.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " [-2.]\n",
      " [ 4.]\n",
      " [ 2.]\n",
      " [-3.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-3.]\n",
      " [ 0.]\n",
      " [-2.]\n",
      " [ 0.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [-1.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [-3.]\n",
      " [ 1.]\n",
      " [-2.]\n",
      " [ 2.]\n",
      " [ 5.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [-1.]\n",
      " [-3.]\n",
      " [ 0.]\n",
      " [ 3.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [-2.]\n",
      " [-2.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [-2.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [ 3.]]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(nfu)\n",
    "\n",
    "\n",
    "node_degree_fea = []\n",
    "node_randid_fea = []\n",
    "data = datasets_obj['DD'].dataset.get_data()\n",
    "node_guass_fea = []\n",
    "# data = datasets_obj['IMDB-BINARY'].dataset.get_data()\n",
    "\n",
    "for g in data:\n",
    "    adj = g.to_numpy_array()\n",
    "    g.x = nfu.node_degree_feature(adj=adj, checkpoint=False)\n",
    "\n",
    "\n",
    "shuffle2(data, data_name='dd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot as the previous sequence:\n",
    "# generate node degree feature:\n",
    "import dataset_utils.node_feature_utils as nfu\n",
    "\n",
    "node_degree_fea = [g.x for g in data]\n",
    "\n",
    "dd = []\n",
    "for n in node_degree_fea:\n",
    "    dd.append((np.max(n),np.min(n)))\n",
    "# sort:\n",
    "sdd = sorted(dd, key=lambda x:x[0])\n",
    "max_dd = [s[0] for s in sdd]\n",
    "min_dd = [s[1] for s in sdd]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(max_dd)\n",
    "plt.plot(min_dd)\n",
    "plt.show()\n",
    "\n",
    "# conclusion: shuffle works ok !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: show ego network in IMDB-B\n",
    "adj = datasets_obj['IMDB-BINARY'].dataset.get_data()[555].to_numpy_array()\n",
    "print(adj.shape)\n",
    "# meaningless.\n",
    "# all are complete graph.\n",
    "g = nx.from_numpy_array(adj)\n",
    "nx.draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot on one figure:\n",
    "datasets_stats = {}\n",
    "for k, v in datasets_obj.items():\n",
    "    datasets_stats[k] = get_pyg_dataset_stats(v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize MUTAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_node_colors(node_labels_onehot):\n",
    "    idx = torch.argmax(node_labels_onehot, dim=1)\n",
    "    color = MyColor()\n",
    "    colors = [color.get_color(i) for i in idx]\n",
    "    return colors\n",
    "\n",
    "# def relabel_nodes(g, node_labels_onehot, ):\n",
    "def plot_sample(sample):\n",
    "    \n",
    "    adj = sample.to_numpy_array()\n",
    "    y = sample.y.item()\n",
    "    g = nx.from_numpy_array(adj)\n",
    "    node_labels = sample.x\n",
    "    print(node_labels.shape)\n",
    "    \n",
    "    # nx.draw(g)\n",
    "    plt.figure()\n",
    "    plt.title(f'class: {y}')\n",
    "    # relabel:\n",
    "    # mapping = {0: \"a\", 1: \"b\", 2: \"c\"}\n",
    "    # H = nx.relabel_nodes(G, mapping)\n",
    "    # sorted(H)\n",
    "    # ['a', 'b', 'c']\n",
    "\n",
    "    pos = nx.nx_pydot.graphviz_layout(g)\n",
    "    nx.draw_networkx(g, pos, node_color=generate_node_colors(node_labels), with_labels=False)\n",
    "\n",
    "    # nx.draw(g, node_color=generate_node_colors(node_labels))\n",
    "    \n",
    "def plot_mutag_samples(samples):\n",
    "    total = len(samples)\n",
    "    nrows = int(total/3) + (0 if total%3 == 0 else 1)\n",
    "    print('nrows:', nrows, 'total', total)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, 3, figsize=(10, 10), dpi=300)\n",
    "    \n",
    "    for idx, s in enumerate(samples):\n",
    "        axe = axes[int(idx/3)][idx%3]\n",
    "         \n",
    "        adj = s.to_numpy_array()\n",
    "        y = s.y.item()\n",
    "        g = nx.from_numpy_array(adj)\n",
    "        node_labels = s.x\n",
    "        pos = nx.nx_pydot.graphviz_layout(g)\n",
    "        nx.draw_networkx(g, pos, ax=axe, node_color=generate_node_colors(node_labels), with_labels=False)\n",
    "    \n",
    "    if total%3 > 0:\n",
    "        for d in range(3-total%3):\n",
    "            fig.delaxes(axes[-1][-d-1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_samples = defaultdict(list)\n",
    "mutag_sample = datasets_obj['MUTAG'].dataset.get_data()\n",
    "_ = [label_samples[int(s.y.item())].append(s) for s in datasets_obj['MUTAG'].dataset.get_data()]\n",
    "print('total sample num:', len(mutag_sample), f' pos num: {len(label_samples[1])}, neg num: {len(label_samples[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neg_samples = label_samples[0][20:29]\n",
    "plot_mutag_samples(neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot samples in one figure:\n",
    "\n",
    "\n",
    "pos_samples = label_samples[1][20:29]\n",
    "plot_mutag_samples(pos_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(label_samples[0][2])\n",
    "plot_sample(label_samples[0][10])\n",
    "plot_sample(label_samples[1][2])\n",
    "plot_sample(label_samples[1][10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "import pandas as pd\n",
    "\n",
    "data_stats = {}\n",
    "K = 11\n",
    "tuple_label = ['TotalD','N', 'AvgCC', 'AvgD', 'AvgD/N', 'tris']\n",
    "[tuple_label.append(f'cyc={k}') for k in range(3, K)]\n",
    "tuple_label.append('y')\n",
    "tuple_label.append('MinD')\n",
    "tuple_label.append('MaxD')\n",
    "\n",
    "\n",
    "print('tuple_label:', tuple_label)\n",
    "\n",
    "normed_stats = {}\n",
    "for name, st in datasets_stats.items():\n",
    "    print(f'dataset {name}, len: {len(st)}')\n",
    "    stats_tuples = []\n",
    "    \n",
    "    for i in range(len(st)):\n",
    "        Ns = st[i][0]\n",
    "        cc = st[i][1]\n",
    "        degree = st[i][2]\n",
    "        tris= st[i][3]\n",
    "        \n",
    "        y = st[i][-3]\n",
    "        cycles = st[i][-4]\n",
    "        \n",
    "        total_degree = Ns * degree\n",
    "        avgDN = degree/Ns\n",
    "        \n",
    "        minD = st[i][-2]\n",
    "        maxD = st[i][-1]\n",
    "        \n",
    "        \n",
    "        counter_cur = defaultdict(int)\n",
    "        for c in cycles:\n",
    "            if len(c) < K:\n",
    "                counter_cur[len(c)] += 1\n",
    "        cycle_num = [0]\n",
    "        for k in range(3, K):\n",
    "            if k in counter_cur:\n",
    "                cycle_num.append(counter_cur[k])\n",
    "            else:\n",
    "                cycle_num.append(0)\n",
    "                \n",
    "        cycle_num.pop(0)\n",
    "        cycle_num = tuple(cycle_num)\n",
    "        \n",
    "        stats_tuples.append((total_degree, Ns, cc, degree, avgDN, tris, *cycle_num, y, minD, maxD))\n",
    "    \n",
    "    data_array = pd.DataFrame(stats_tuples).values\n",
    "    # TODO: normalize:\n",
    "    data_array = utils.normalize(data_array, along_axis=-1, ignore_norm=[-2, -1])\n",
    "    print(data_array.shape)\n",
    "    normed_stats[name] = data_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: for testing:\n",
    "\n",
    "test_g = nx.circulant_graph(11, [1, 3])\n",
    "nx.draw_circular(test_g)\n",
    "\n",
    "cycles = nx.cycle_basis(test_g)\n",
    "# collect all len 4 sets.\n",
    "node_fea = np.zeros((11, 1))\n",
    "k=4\n",
    "print(cycles)\n",
    "# nodes = \n",
    "for c in cycles:\n",
    "    if len(c) == k:\n",
    "        for id in c:\n",
    "            node_fea[id] += 1\n",
    "print(node_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: def histogram\n",
    "\n",
    "\n",
    "def plot_histogram(data_states=None):\n",
    "\n",
    "    # Fixing random state for reproducibility\n",
    "\n",
    "    # mu, sigma = 100, 15\n",
    "    # x = mu + sigma * np.random.randn(10000)\n",
    "\n",
    "    # the histogram of the data\n",
    "    \n",
    "    # n, bins, patches = plt.hist(x, 50, density=True, facecolor='g', alpha=0.75)\n",
    "    \n",
    "    total = len(data_states.keys())\n",
    "    nrows = int(total/3) + (0 if total%3 == 0 else 1)\n",
    "    print('nrows:', nrows, 'total', total)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, 3, figsize=(10, 8), dpi=300)\n",
    "    \n",
    "    for idx, (name, normed_stat) in enumerate(data_states.items()):\n",
    "        axe = axes[int(idx/3)][idx%3]\n",
    "        axe.hist(normed_stat[:,0], 100, density=False, facecolor='g', alpha=0.75)\n",
    "        axe.set_title(name)\n",
    "    \n",
    "    if total%3 > 0:\n",
    "        for d in range(3-total%3):\n",
    "            fig.delaxes(axes[-1][-d-1])\n",
    "            \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_histogram(normed_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stats(cur_data_stats:dict, show_idx=None):\n",
    "    total = len(cur_data_stats.keys())\n",
    "    nrows = int(total/3) + (0 if total%3 == 0 else 1)\n",
    "    print('nrows:', nrows, 'total', total)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, 3, figsize=(10, 8), dpi=300)\n",
    "    for idx, (name, normed_stat) in enumerate(cur_data_stats.items()):\n",
    "        plot_graphs_statistics(name, normed_stat, tuple_label, axe=axes[int(idx/3)][idx%3],\n",
    "                               sort_idx=1, show_idx=show_idx)\n",
    "    \n",
    "    if total%3 > 0:\n",
    "        for d in range(3-total%3):\n",
    "            fig.delaxes(axes[-1][-d-1])\n",
    "            \n",
    "    \n",
    "    handlers, labels = axes[0][0].get_legend_handles_labels()\n",
    "    \n",
    "    fig.legend(handlers, labels, loc='lower center', prop={'size':10})\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# TODO: correlation of each amount of cycle and degree and label.\n",
    "\n",
    "def plot_corr_stats(cur_data_stats:dict, show_idx=None, anchor=-1, corrs_type='MIC'):\n",
    "    total = len(cur_data_stats.keys())\n",
    "    nrows = int(total/3) + (0 if total%3 == 0 else 1)\n",
    "    print('nrows:', nrows, 'total', total)\n",
    "    print('anchor: ', tuple_label[anchor])\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, 3, figsize=(10, 8), dpi=300)\n",
    "    for idx, (name, normed_stat) in enumerate(cur_data_stats.items()):\n",
    "        plot_cyc_degree_corr(name, normed_stat, tuple_label, axe=axes[int(idx/3)][idx%3],\n",
    "                               sort_idx=1, show_idx=show_idx, anchor=anchor, corrs_type=corrs_type)\n",
    "    \n",
    "    if total%3 > 0:\n",
    "        for d in range(3-total%3):\n",
    "            fig.delaxes(axes[-1][-d-1])\n",
    "            \n",
    "    \n",
    "    handlers, labels = axes[0][0].get_legend_handles_labels()\n",
    "    \n",
    "    fig.legend(handlers, labels, loc='lower center', prop={'size':10})\n",
    "    fig.suptitle('corr anchor:'+tuple_label[anchor])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k, v in normed_stats.items():\n",
    "    print('name:', k)\n",
    "    print(v[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "\n",
    "# ['TotalD', 'N', 'AvgCC', 'AvgD', 'AvgD/N', 'tris', 'cyc=3', 'cyc=4',\n",
    "#  'cyc=5', 'cyc=6', 'cyc=7', 'cyc=8', 'cyc=9', 'cyc=10', 'y', 'minD', 'maxD']\n",
    "print(normed_stats['CSL'][0, :])\n",
    "plot_stats(normed_stats, show_idx=[15, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normed_stats['IMDB-BINARY'].shape)\n",
    "\n",
    "cur_stat = normed_stats['IMDB-BINARY']\n",
    "name = 'IMDB-BINARY'\n",
    "show_idx = [3, 4, -1]\n",
    "plot_graphs_statistics(name, cur_stat, tuple_label, sort_idx=1,\n",
    "                       show_idx=show_idx, need_filter=False)\n",
    "\n",
    "\n",
    "show_idx = [1,2,3,4,5]\n",
    "plot_cyc_degree_corr(name, cur_stat, tuple_label,\n",
    "                        sort_idx=1, show_idx=show_idx, anchor=-1, corrs_type='pearson', need_filter=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: correlation of each amount of cycle and degree and label.\n",
    "\n",
    "def plot_CCA_stats(cur_data_stats:dict, show_idx=None, anchor=-1, corrs_type='MIC'):\n",
    "    total = len(cur_data_stats.keys())\n",
    "    nrows = int(total/3) + (0 if total%3 == 0 else 1)\n",
    "    print('nrows:', nrows, 'total', total)\n",
    "    print('anchor: ', tuple_label[anchor])\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, 3, figsize=(10, 8), dpi=300)\n",
    "    for idx, (name, normed_stat) in enumerate(cur_data_stats.items()):\n",
    "        plot_cyc_degree_corr(name, normed_stat, tuple_label, axe=axes[int(idx/3)][idx%3],\n",
    "                               sort_idx=1, show_idx=show_idx, anchor=anchor, corrs_type=corrs_type)\n",
    "    \n",
    "    if total%3 > 0:\n",
    "        for d in range(3-total%3):\n",
    "            fig.delaxes(axes[-1][-d-1])\n",
    "            \n",
    "    \n",
    "    handlers, labels = axes[0][0].get_legend_handles_labels()\n",
    "    \n",
    "    fig.legend(handlers, labels, loc='lower center', prop={'size':10})\n",
    "    fig.suptitle('corr anchor:'+tuple_label[anchor])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple_label: ['TotalD', 'N', 'AvgCC', 'AvgD', 'tris', 'cyc<=4', 'cyc<=5', 'cyc<=6', 'cyc<=7', 'cyc<=8', 'cyc<=9', 'cyc<=10', 'y']\n",
    "\n",
    "importlib.reload(utils)\n",
    "\n",
    "plot_corr_stats(normed_stats, show_idx=[0, 1, 2, 3,4,5,6,7,8,9, 10, 11, 12], anchor=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple_label: ['TotalD', 'N', 'AvgCC', 'AvgD', 'tris', 'cyc<=4', 'cyc<=5', 'cyc<=6', 'cyc<=7', 'cyc<=8', 'cyc<=9', 'cyc<=10', 'y']\n",
    "\n",
    "importlib.reload(utils)\n",
    "\n",
    "plot_corr_stats(normed_stats, show_idx=[0, 1, 2, 3,4,5,6,7,8,9, 10, 11, 12], anchor=-1,corrs_type='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "\n",
    "plot_corr_stats(normed_stats, show_idx=[3, 4,5,6,7,8, 9], anchor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(7)\n",
    "negative_data = [-1,0,-3,0,-6,-2,-8]\n",
    "positive_data = [4,2,3,1,4,6,7,]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(x, negative_data, width=1, color='r')\n",
    "ax.bar(x, positive_data, width=1, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot train val loss, 2022.10.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load files.\n",
    "import os\n",
    "\n",
    "\n",
    "res_dir = './result_1009'\n",
    "for root, dirs, files in os.walk(res_dir, topdown=True):\n",
    "    print(dirs)\n",
    "    for d in dirs:\n",
    "        if 'pre' in d:\n",
    "            continue\n",
    "        sub_res_dir = os.path.join(root, d)\n",
    "        for sub_root, sub_dirs, _ in os.walk(sub_res_dir,topdown=True):\n",
    "            for conf_dir in sub_dirs:\n",
    "                # for \n",
    "                with open(os.path.join(sub_root, conf_dir, 'experiment.log'), 'r') as f:\n",
    "                    for line in f.readlines():\n",
    "                        if 'TR loss' not in line:\n",
    "                            continue\n",
    "                        print(len(line.split()), line.split())\n",
    "                        \n",
    "            break\n",
    "            \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot spectrum of cycle graph:\n",
    "\n",
    "c_g = nx.cycle_graph(10)\n",
    "nx.draw_circular(c_g)\n",
    "s = nx.adjacency_spectrum(c_g)\n",
    "print(s)\n",
    "s = sorted(s)\n",
    "print(s)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

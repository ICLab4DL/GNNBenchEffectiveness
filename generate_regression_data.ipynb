{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets:\n",
    "\n",
    "import importlib\n",
    "import random\n",
    "import argparse\n",
    "import configparser\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_sparse\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.utils import negative_sampling, to_networkx\n",
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptPairTensor, Adj, OptTensor, Size\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "\n",
    "from dataset_utils import node_feature_utils\n",
    "from dataset_utils.node_feature_utils import *\n",
    "import my_utils as utils\n",
    "import sys,os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate and save regression datasets:\n",
    "- small: MUTAG, NCI1, DD, CIFAR10, MNIST, SYN_CC\n",
    "- middle: ogbg-molhiv, ogbg-molbace, ogbg-moltox21\n",
    "\n",
    "# TODO:\n",
    "```\n",
    "    'REDDIT-BINARY': RedditBinary,\n",
    "    'REDDIT-MULTI-5K': Reddit5K,\n",
    "    'COLLAB': Collab,\n",
    "    'IMDB-BINARY': IMDBBinary,\n",
    "    'IMDB-MULTI': IMDBMulti,\n",
    "    'ENZYMES': Enzymes,\n",
    "    'PROTEINS': Proteins,\n",
    "    'NCI1': NCI1,\n",
    "    'DD': DD,\n",
    "    \"MUTAG\": Mutag,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load specific dataset:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from PrepareDatasets import DATASETS\n",
    "import my_utils\n",
    "import dataset_utils\n",
    "\n",
    "\n",
    "print(DATASETS.keys())\n",
    "\"\"\"\n",
    "    'REDDIT-BINARY': RedditBinary,\n",
    "    'REDDIT-MULTI-5K': Reddit5K,\n",
    "    'COLLAB': Collab,\n",
    "    'IMDB-BINARY': IMDBBinary,\n",
    "    'IMDB-MULTI': IMDBMulti,\n",
    "    'ENZYMES': Enzymes,\n",
    "    'PROTEINS': Proteins,\n",
    "    'NCI1': NCI1,\n",
    "    'DD': DD,\n",
    "    \"MUTAG\": Mutag,\n",
    "    'CSL': CSL\n",
    "\"\"\"\n",
    "\n",
    "data_names = ['PROTEINS']\n",
    "data_names = ['DD']\n",
    "data_names = ['ENZYMES']\n",
    "data_names = ['NCI1']\n",
    "data_names = ['IMDB-MULTI']\n",
    "data_names = ['REDDIT-BINARY']\n",
    "data_names = ['CIFAR10']\n",
    "data_names = ['ogbg_molhiv']\n",
    "\n",
    "# NOTE:new kernel:\n",
    "data_names = ['DD', 'PROTEINS', 'ENZYMES']\n",
    "\n",
    "data_names = ['ogbg_moltox21','ogbg-molbace']\n",
    "\n",
    "data_names = ['MUTAG']\n",
    "data_names = []\n",
    "datasets_obj = {}\n",
    "for k, v in DATASETS.items():\n",
    "    if k not in data_names:\n",
    "        continue\n",
    "    print('loaded dataset, name:', k)\n",
    "    dat = v(use_node_attrs=True)\n",
    "    datasets_obj[k] = dat\n",
    "    # print(type(dat.dataset.get_data()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features: mean, std of: avg, pooling, cc, tri_num, cycle4_num, ..., kernel features\n",
    "\n",
    "import dataset_utils.node_feature_utils as nfu\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# TODO: load each fold logs to construct y:\n",
    "import json\n",
    "\n",
    "# MUTAG:\n",
    "# GIN_degree_log_path: [result_GIN_0403_GIN_degree_MUTAG]\n",
    "# MLP_log_path: [result_GIN_0403_GIN_degree_MUTAG]\n",
    "# GIN_degree_log_path: [result_GIN_0403_GIN_degree_MUTAG]\n",
    "\"\"\"\n",
    "{\"best_config\": {\"config\": {\"model\": \"GIN\", \"device\": \"cuda:1\", \"batch_size\": 64, \"learning_rate\": 0.0001, \"classifier_epochs\": 200, \"hidden_units\": [64, 64, 64, 64], \"layer_num\": 5, \"optimizer\": \"Adam\", \"scheduler\": {\"class\": \"StepLR\", \"args\": {\"step_size\": 50, \"gamma\": 0.5}}, \"loss\": \"MulticlassClassificationLoss\", \"train_eps\": false, \"l2\": 0.0, \"aggregation\": \"sum\", \"gradient_clipping\": null, \"dropout\": 0.5, \"early_stopper\": {\"class\": \"Patience\", \"args\": {\"patience\": 50, \"use_loss\": false}}, \"shuffle\": true, \"resume\": false, \"additional_features\": \"degree\", \"node_attribute\": false, \"shuffle_feature\": false, \"roc_auc\": false, \"mol_split\": false, \"dataset\": \"syn_cc\", \"config_file\": \"gnn_comparison/config_GIN_lzd_degree.yml\", \"experiment\": \"endtoend\", \"result_folder\": \"results/result_0422_GIN_lzd_degree_syn_cc_0.1\", \"dataset_name\": \"syn_cc\", \"dataset_para\": \"0.1\", \"outer_folds\": 10, \"outer_processes\": 2, \"inner_folds\": 5, \"inner_processes\": 1, \"debug\": true, \"ogb_evl\": false}, \"TR_score\": 16.183574925298277, \"VL_score\": 21.505376272304083, \"TR_roc_auc\": -1, \"VL_roc_auc\": -1}, \"OUTER_TR\": 14.774557204254199, \"OUTER_TS\": 11.003236511378612, \"OUTER_TR_ROCAUC\": -1, \"OUTER_TE_ROCAUC\": -1}\n",
    "\"\"\"\n",
    "\n",
    "_OUTER_RESULTS_FILENAME = 'outer_results.json'\n",
    "\n",
    "def get_test_acc(data_root_path, fold=10):\n",
    "    if data_root_path is None:\n",
    "        return [None for _ in range(fold)]\n",
    "    \n",
    "    outer_TR_scores,outer_TS_scores,outer_TR_ROCAUC,outer_TE_ROCAUC = [],[],[],[]\n",
    "    for i in range(1, fold+1):\n",
    "        config_filename = os.path.join(data_root_path, f'OUTER_FOLD_{i}', _OUTER_RESULTS_FILENAME)\n",
    "\n",
    "        with open(config_filename, 'r') as fp:\n",
    "            outer_fold_scores = json.load(fp)\n",
    "\n",
    "            outer_TR_scores.append(outer_fold_scores['OUTER_TR'])\n",
    "            outer_TS_scores.append(outer_fold_scores['OUTER_TS'])\n",
    "            \n",
    "            if 'OUTER_TR_ROCAUC' in outer_fold_scores:\n",
    "                outer_TR_ROCAUC.append(outer_fold_scores['OUTER_TR_ROCAUC'])\n",
    "                outer_TE_ROCAUC.append(outer_fold_scores['OUTER_TE_ROCAUC'])\n",
    "\n",
    "    return outer_TS_scores\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(adjs, labels):\n",
    "    \n",
    "    def get_mean_std_corr(features, labels):\n",
    "        \n",
    "        mean = np.array(np.mean(features))\n",
    "        std = np.array(np.std(features))\n",
    "        x = np.array(features).reshape(-1)\n",
    "        # NOTE: if multilabel, use the average of all labels:\n",
    "        if len(labels[0].shape) > 1:\n",
    "            corrs = []\n",
    "            y = np.concatenate(labels, axis=0)\n",
    "            for i in range(y.shape[1]):\n",
    "                # ignore nan in y[:, i]\n",
    "                not_nan = ~np.isnan(y[:, i])\n",
    "                x_i = x[not_nan]\n",
    "                y_i = y[not_nan]\n",
    "                corr, _ = pearsonr(x_i, y_i[:, i].squeeze())\n",
    "                if np.isnan(corr):\n",
    "                    corr = np.array([0])\n",
    "                corrs.append(corr)\n",
    "            corr = np.mean(corrs)\n",
    "        else:\n",
    "            y = np.array(labels)\n",
    "            # NOTE: \n",
    "            not_nan = ~np.isnan(y)\n",
    "            x_nn = x[not_nan]\n",
    "            y_nn = y[not_nan]\n",
    "            \n",
    "            corr, _ = pearsonr(x_nn, y_nn)\n",
    "            if np.isnan(corr):\n",
    "                corr = np.array([0])\n",
    "            \n",
    "            if not isinstance(corr, np.ndarray):\n",
    "                corr = np.array([corr])\n",
    "                \n",
    "        return np.array([mean.item(), std.item(), corr.item()])\n",
    "\n",
    "    \n",
    "    # F1: avgD:\n",
    "    avg_d = [nfu.graph_avg_degree(adj=adj) for adj in adjs]\n",
    "    f_avgD = get_mean_std_corr(avg_d, labels)\n",
    "    # F2: avgCC:\n",
    "    avg_cc = [nfu.node_cc_avg_feature(adj=adj) for adj in adjs]\n",
    "    f_avgCC = get_mean_std_corr(avg_cc, labels)\n",
    "    \n",
    "    # F3: avgD/N:\n",
    "    avg_DN = [nfu.graph_avgDN_feature(adj=adj) for adj in adjs]\n",
    "    f_avgDN = get_mean_std_corr(avg_DN, labels)\n",
    "    \n",
    "    # F4: node num N:\n",
    "    avg_N = [adj.shape[0] for adj in adjs]\n",
    "    f_avgN = get_mean_std_corr(avg_N, labels)\n",
    "    \n",
    "    # F5: labels\n",
    "    # calculate each dimension of labels:\n",
    "    print('labels[0]: ', labels[0].shape)\n",
    "    if labels[0].shape[1] > 1:\n",
    "        f_Ys = []\n",
    "        Y = np.concatenate(labels, axis=0)\n",
    "        for i in range(labels[0].shape[0]):\n",
    "            f_Ys.append(get_mean_std_corr(Y[:, i], Y[:, i])[:2])\n",
    "        f_Y = np.concatenate(f_Ys)\n",
    "        f_Y = np.mean(f_Ys, axis=0)\n",
    "    else:\n",
    "        f_Y = get_mean_std_corr(labels, labels)[:2]\n",
    "    \n",
    "    # F6: cycles:\n",
    "    avg_cyc = [nfu.graph_cycle_feature(adj=adj,k='4-5-6-7') for adj in adjs]\n",
    "    f_cyc4 = get_mean_std_corr([c[0] for c in avg_cyc], labels)\n",
    "    f_cyc5 = get_mean_std_corr([c[1] for c in avg_cyc], labels)\n",
    "    f_cyc6 = get_mean_std_corr([c[2] for c in avg_cyc], labels)\n",
    "    f_cyc7 = get_mean_std_corr([c[3] for c in avg_cyc], labels)\n",
    "    \n",
    "        \n",
    "    feas = np.concatenate([f_avgD, f_avgCC, f_avgDN, f_avgN, f_Y, f_cyc4, f_cyc5, f_cyc6, f_cyc7], axis=0)\n",
    "    return feas\n",
    "\n",
    "# construct E of each fold, and plot\n",
    "\n",
    "# Effectiveness \n",
    "\n",
    "def get_E(Acc_MLP_avg_degree, Acc_GNN_degree, Acc_MLP_attr, Acc_GNN_attr):\n",
    "    factor = 0.5\n",
    "    if Acc_MLP_avg_degree is None:\n",
    "        E_struct = 0\n",
    "        factor = 1\n",
    "    else:\n",
    "        E_struct = (abs(Acc_GNN_degree - Acc_MLP_avg_degree) / Acc_MLP_avg_degree) * (100 - min(Acc_GNN_degree, Acc_MLP_avg_degree))\n",
    "    \n",
    "    if Acc_MLP_attr is None:\n",
    "        E_attribute = 0\n",
    "        factor = 1\n",
    "    else:\n",
    "        E_attribute = (abs(Acc_GNN_attr - Acc_MLP_attr) / Acc_MLP_attr) * (100 - min(Acc_GNN_attr, Acc_MLP_attr))\n",
    "    return (E_struct+E_attribute) * factor\n",
    "\n",
    "# NOTE: get E for each dataset:\n",
    "\n",
    "def plot_E(es, ax=None):\n",
    "    e_res = sorted(es, key=lambda x:x[0])\n",
    "    labels = [e[1] for e in e_res]\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(dpi=100)\n",
    "        \n",
    "    for e in e_res:\n",
    "        bars = ax.bar(e[1], e[0], label=e[1], hatch='\\\\', edgecolor='black', linewidth=0.5)\n",
    "\n",
    "    ax.set_xticks(range(len(labels)))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='center')\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(linestyle='dashed',zorder=0)\n",
    "    ax.set_title('E=(E_struct+E_attr)/2')\n",
    "\n",
    "# load splits as datasets:\n",
    "import torch_geometric.utils as torch_utils\n",
    "    \n",
    "\"\"\"\n",
    "the ixj th sample : (D_i_split_j, E_i_j)\n",
    "\"\"\"\n",
    "\n",
    "# Check mutag\n",
    "# construct each E with each fold and\n",
    "def is_pyg_dataset(d_name:str):\n",
    "    return d_name.startswith('ogb') or d_name.startswith('syn')\n",
    "\n",
    "def E_datasets(dataset, \n",
    "               MLP_log_path_struct=None, GNN_log_path_struct=None,\n",
    "               MLP_log_path_attr=None, GNN_log_path_attr=None, fold=10):\n",
    "    \n",
    "    \n",
    "    GNN_test_acc_struct = get_test_acc(GNN_log_path_struct, fold=fold)\n",
    "    MLP_test_acc_struct = get_test_acc(MLP_log_path_struct, fold=fold)\n",
    "    GNN_test_acc_attr = get_test_acc(GNN_log_path_attr, fold=fold)\n",
    "    MLP_test_acc_attr = get_test_acc(MLP_log_path_attr, fold=fold)\n",
    "    \n",
    "    def get_dense_adjs(dataset):\n",
    "        adjs = []\n",
    "\n",
    "        if is_pyg_dataset(dataset.name):\n",
    "            for d in dataset:\n",
    "                if d.edge_index.numel() < 1:\n",
    "                    N = d.x.shape[0]\n",
    "                    adj = np.ones(shape=(N, N))\n",
    "                else:\n",
    "                    adj = torch_utils.to_dense_adj(d.edge_index).numpy()[0]\n",
    "                adjs.append(adj)\n",
    "        else:\n",
    "            adjs = [d.to_numpy_array() for d in dataset.data]\n",
    "            \n",
    "        return adjs\n",
    "    \n",
    "    mutag_splits = []\n",
    "    for i in range(fold):\n",
    "        train_loader, val_loader = dataset.get_model_selection_fold(outer_idx=i, inner_idx=0, batch_size=1, shuffle=False)\n",
    "        adjs = get_dense_adjs(train_loader.dataset) + get_dense_adjs(val_loader.dataset)\n",
    "        labels = [d.y for d in train_loader.dataset] + [d.y for d in val_loader.dataset]\n",
    "        feas = extract_features(adjs=adjs, labels=labels)\n",
    "        e = get_E(MLP_test_acc_struct[i], GNN_test_acc_struct[i],  MLP_test_acc_attr[i], GNN_test_acc_attr[i])\n",
    "            \n",
    "        mutag_splits.append((feas, e))\n",
    "        \n",
    "    return mutag_splits\n",
    "\n",
    "\n",
    "# save datasets\n",
    "import pickle as pk\n",
    "\n",
    "def save_datasets(datasets, file_name):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pk.dump(datasets, f)\n",
    "\n",
    "def load_datasets(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        datasets = pk.load(f)\n",
    "    return datasets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syn_cc datasets:\n",
    "\n",
    "syn_cc_GNN_test_acc = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "    data_root_path = f'./results/result_0422_GIN_lzd_degree_syn_cc_{i/10}/GIN_syn_cc_assessment/10_NESTED_CV'\n",
    "    syn_cc_GNN_test_acc.append(get_test_acc(data_root_path))\n",
    "    \n",
    "\n",
    "syn_cc_MLP_test_acc = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "    data_root_path = f'./results/result_0422_Baseline_lzd_mlp_syn_cc_{i/10}/MolecularGraphMLP_syn_cc_assessment/10_NESTED_CV'\n",
    "    syn_cc_MLP_test_acc.append(get_test_acc(data_root_path))  \n",
    "    \n",
    "    \n",
    "sy_es = []\n",
    "for i in range(len(syn_cc_GNN_test_acc)):\n",
    "    # cc_MLP_avg_degree, Acc_GNN_degree, Acc_MLP_attr, Acc_GNN_att\n",
    "    sy_es.append((get_E(np.mean(syn_cc_MLP_test_acc[i]), np.mean(syn_cc_GNN_test_acc[i]),\n",
    "                       None, None), f'cc_corr:{(i+1)/10}'))\n",
    "# \n",
    "plot_E(sy_es)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUTAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUTAG\n",
    "del datasets_obj\n",
    "\n",
    "# DD:\n",
    "\n",
    "data_names = ['MUTAG']\n",
    "              \n",
    "datasets_obj = {}\n",
    "for k, v in DATASETS.items():\n",
    "    if k not in data_names:\n",
    "        continue\n",
    "    print('loaded dataset, name:', k)\n",
    "    dat = v(use_node_attrs=True)\n",
    "    datasets_obj[k] = dat\n",
    "    # print(type(dat.dataset.get_data()))\n",
    "\n",
    "GNN_attr_log_path = f'./results/result_GIN_0404_GIN_attr_MUTAG/GIN_MUTAG_assessment/10_NESTED_CV'\n",
    "MLP_attr_log_path = f'./results/result_GIN_0327_finger_mlp_attr_multicrossen_MUTAG/MolecularFingerprint_MUTAG_assessment/10_NESTED_CV'\n",
    "dataset = datasets_obj['MUTAG']\n",
    "mutag_datasets = E_datasets(dataset, MLP_attr_log_path, GNN_attr_log_path, None, None)\n",
    "\n",
    "save_datasets(mutag_datasets, 'mutag_datasets.pkl')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DD\n",
    "\"\"\"\n",
    "result_GIN_0308_DD_degree_attribute\n",
    "result_GIN_0309_DD_both_degree_attribute\n",
    "result_GIN_0310_DD_mix\n",
    "result_GIN_0311_DD_mix\n",
    "result_GIN_0312_DD_mix\n",
    "result_GIN_0318_decouple_attr_degree_DD\n",
    "result_GIN_0319_new_alpha_decouple_attr_degree_DD\n",
    "result_GIN_0327_finger_mlp_attr_crossen_DD\n",
    "result_GIN_0327_finger_mlp_attr_multicrossen_DD\n",
    "\"\"\"\n",
    "\n",
    "del datasets_obj\n",
    "\n",
    "# DD:\n",
    "\n",
    "data_names = ['DD']\n",
    "              \n",
    "datasets_obj = {}\n",
    "for k, v in DATASETS.items():\n",
    "    if k not in data_names:\n",
    "        continue\n",
    "    print('loaded dataset, name:', k)\n",
    "    dat = v(use_node_attrs=True)\n",
    "    datasets_obj[k] = dat\n",
    "    # print(type(dat.dataset.get_data()))\n",
    "\n",
    "GNN_attr_log_path = f'./results/result_GIN_0308_DD_degree_attribute/Adapter_DD_assessment/10_NESTED_CV'\n",
    "MLP_attr_log_path = f'./results/result_GIN_0327_finger_mlp_attr_multicrossen_DD/MolecularFingerprint_DD_assessment/10_NESTED_CV'\n",
    "dataset = datasets_obj['DD']\n",
    "dd_datasets = E_datasets(dataset, None, None, GNN_attr_log_path, MLP_attr_log_path)\n",
    "\n",
    "save_datasets(dd_datasets, 'dd_datasets.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 only has on fold\n",
    "\"\"\"\n",
    "result_GIN_0317_decouple_degree_attr_CIFAR10\n",
    "result_GIN_0317_mix_degree_attr_CIFAR10\n",
    "result_GIN_0317_only_attr_CIFAR10\n",
    "result_GIN_0317_only_degree_CIFAR10\n",
    "result_GIN_0318_decouple_degree_attr_CIFAR10\n",
    "result_GIN_0327_finger_mlp_attr_multicrossen_CIFAR10\n",
    "result_GIN_0401_GIN_degree_CIFAR10\n",
    "result_GIN_0403_GIN_degree_CIFAR10\n",
    "\"\"\"\n",
    "\n",
    "del datasets_obj\n",
    "\n",
    "# DD:\n",
    "\n",
    "data_names = ['CIFAR10']\n",
    "              \n",
    "datasets_obj = {}\n",
    "for k, v in DATASETS.items():\n",
    "    if k not in data_names:\n",
    "        continue\n",
    "    print('loaded dataset, name:', k)\n",
    "    dat = v(use_node_attrs=True)\n",
    "    datasets_obj[k] = dat\n",
    "    # print(type(dat.dataset.get_data()))\n",
    "    \n",
    "MLP_log_path_degree = f'./results/result_GIN_0401_graph_mlp_avgDegree_CIFAR10/MolecularGraphMLP_CIFAR10_assessment/1_NESTED_CV'\n",
    "GNN_log_path_degree = f'./results/result_GIN_0317_only_degree_CIFAR10/GIN_CIFAR10_assessment/1_NESTED_CV'\n",
    "\n",
    "MLP_log_path_attr = f'./results/result_GIN_0327_finger_mlp_attr_multicrossen_CIFAR10/MolecularFingerprint_CIFAR10_assessment/10_NESTED_CV'\n",
    "GNN_log_path_attr = f'./results/result_GIN_0317_only_attr_CIFAR10/GIN_CIFAR10_assessment/1_NESTED_CV'\n",
    "\n",
    "dataset = datasets_obj['CIFAR10']\n",
    "cifar10_datasets = E_datasets(dataset, MLP_log_path_degree, GNN_log_path_degree, MLP_log_path_attr, GNN_log_path_attr, fold=1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCI1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get NCI1\n",
    "\n",
    "# 'NCI1', 'IMDB-MULTI', 'REDDIT-BINARY', 'CIFAR10',\n",
    "# #               'ogbg_molhiv', 'ogbg_moltox21', 'ogbg-molbace', 'MUTAG']\n",
    "\n",
    "\"\"\"\n",
    "result_GIN_0312_attr_degree_NCI1\n",
    "result_GIN_0312_decouple_attr_degree_NCI1\n",
    "result_GIN_0312_only_attribute_NCI\n",
    "result_GIN_0312_only_degree_NCI\n",
    "result_GIN_0313_degree_shuffle_NCI1\n",
    "result_GIN_0313_pagerank_NCI1\n",
    "result_GIN_0318_decouple_attr_degree_NCI1\n",
    "result_GIN_0319_new_alpha_decouple_attr_degree_NCI1\n",
    "result_GIN_0327_finger_mlp_attr_crossen_NCI1\n",
    "result_GIN_0327_finger_mlp_attr_multicrossen_NCI1\n",
    "result_GIN_0403_GIN_attr_NCI1\n",
    "result_GIN_0403_GIN_degree_NCI1\n",
    "result_GIN_0404_GIN_attr_NCI1\n",
    "\"\"\"\n",
    "del datasets_obj\n",
    "\n",
    "data_names = ['NCI1']\n",
    "              \n",
    "datasets_obj = {}\n",
    "for k, v in DATASETS.items():\n",
    "    if k not in data_names:\n",
    "        continue\n",
    "    print('loaded dataset, name:', k)\n",
    "    dat = v(use_node_attrs=True)\n",
    "    datasets_obj[k] = dat\n",
    "\n",
    "MLP_log_path_degree = f'./results/result_GIN_0401_graph_mlp_avgDegree_CIFAR10/MolecularGraphMLP_CIFAR10_assessment/1_NESTED_CV'\n",
    "GNN_log_path_degree = f'./results/result_GIN_0317_only_degree_CIFAR10/GIN_CIFAR10_assessment/1_NESTED_CV'\n",
    "\n",
    "MLP_log_path_attr = f'./results/result_GIN_0327_finger_mlp_attr_multicrossen_NCI1/MolecularFingerprint_NCI1_assessment/10_NESTED_CV'\n",
    "GNN_log_path_attr = f'./results/result_GIN_0404_GIN_attr_NCI1/GIN_NCI1_assessment/1_NESTED_CV'\n",
    "\n",
    "dataset = datasets_obj['NCI1']\n",
    "nci1_datasets = E_datasets(dataset, MLP_log_path_degree, GNN_log_path_degree, MLP_log_path_attr, GNN_log_path_attr, fold=1)\n",
    "\n",
    "save_datasets(nci1_datasets, 'nci1_datasets.pkl')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ogbg_molhiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get NCI1\n",
    "\n",
    "# 'NCI1', 'IMDB-MULTI', 'REDDIT-BINARY', 'CIFAR10',\n",
    "# #               'ogbg_molhiv', 'ogbg_moltox21', 'ogbg-molbace', 'MUTAG']\n",
    "\n",
    "del datasets_obj\n",
    "\n",
    "data_names = ['ogbg_molhiv']\n",
    "              \n",
    "datasets_obj = {}\n",
    "for k, v in DATASETS.items():\n",
    "    if k not in data_names:\n",
    "        continue\n",
    "    print('loaded dataset, name:', k)\n",
    "    dat = v(use_node_attrs=True)\n",
    "    datasets_obj[k] = dat\n",
    "\n",
    "MLP_log_path_degree = f'./results/result_GIN_0329_graph_mlp_avgDegree_ogbg_molhiv/MolecularGraphMLP_ogbg_molhiv_assessment/1_NESTED_CV'\n",
    "GNN_log_path_degree = f'./results/result_0323_GIN_only_degreeogbg_molhiv/GIN_ogbg_molhiv_assessment/10_NESTED_CV'\n",
    "\n",
    "MLP_log_path_attr = f'./results/result_GIN_0326_mlp_single_attr_ogbg_molhiv/MolecularFingerprint_ogbg_molhiv_assessment/1_NESTED_CV'\n",
    "GNN_log_path_attr = f'./results/result_GIN_0323_EGNN_only_attr_ogbg_molhiv/EGIN_ogbg_molhiv_assessment/1_NESTED_CV'\n",
    "\n",
    "dataset = datasets_obj['ogbg_molhiv']\n",
    "ogbg_molhiv_datasets = E_datasets(dataset, MLP_log_path_degree, GNN_log_path_degree, MLP_log_path_attr, GNN_log_path_attr, fold=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ogbg_moltox21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get NCI1\n",
    "\n",
    "# 'NCI1', 'IMDB-MULTI', 'REDDIT-BINARY', 'CIFAR10',\n",
    "# #               'ogbg_molhiv', 'ogbg_moltox21', 'ogbg-molbace', 'MUTAG']\n",
    "\n",
    "\n",
    "data_names = ['ogbg_moltox21']\n",
    "              \n",
    "datasets_obj = {}\n",
    "for k, v in DATASETS.items():\n",
    "    if k not in data_names:\n",
    "        continue\n",
    "    print('loaded dataset, name:', k)\n",
    "    dat = v(use_node_attrs=True)\n",
    "    datasets_obj[k] = dat\n",
    "\n",
    "\n",
    "MLP_log_path_degree = f'./results/result_0424_Baseline_lzd_mlp_mol_ogbg_moltox21/MolecularGraphMLP_ogbg_moltox21_assessment/1_NESTED_CV'\n",
    "GNN_log_path_degree = f'./results/result_GIN_0410_GIN_lzd_degree_ogbg_moltox21/GIN_ogbg_moltox21_assessment/1_NESTED_CV'\n",
    "\n",
    "MLP_log_path_attr = f'./results/result_GIN_0411_atomencoder_attr_ogbg_moltox21/AtomMLP_ogbg_moltox21_assessment/1_NESTED_CV'\n",
    "GNN_log_path_attr = f'./results/result_GIN_0409_EGNN_lzd_attr_ogbg_moltox21/EGNN_ogbg_moltox21_assessment/1_NESTED_CV'\n",
    "\n",
    "dataset = datasets_obj['ogbg_moltox21']\n",
    "ogbg_moltox21_datasets = E_datasets(dataset, MLP_log_path_degree, GNN_log_path_degree, MLP_log_path_attr, GNN_log_path_attr, fold=1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ogbg-molbace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get NCI1\n",
    "\n",
    "# 'NCI1', 'IMDB-MULTI', 'REDDIT-BINARY', 'CIFAR10',\n",
    "# #               'ogbg_molhiv', 'ogbg_moltox21', 'ogbg-molbace', 'MUTAG']\n",
    "\n",
    "\n",
    "data_names = ['ogbg-molbace']\n",
    "              \n",
    "datasets_obj = {}\n",
    "for k, v in DATASETS.items():\n",
    "    if k not in data_names:\n",
    "        continue\n",
    "    print('loaded dataset, name:', k)\n",
    "    dat = v(use_node_attrs=True)\n",
    "    datasets_obj[k] = dat\n",
    "\n",
    "\n",
    "MLP_log_path_degree = f'./results/result_0424_Baseline_lzd_mlp_mol_ogbg-molbace/MolecularGraphMLP_ogbg-molbace_assessment/1_NESTED_CV'\n",
    "GNN_log_path_degree = f'./results/result_GIN_0410_GIN_lzd_degree_ogbg-molbace/GIN_ogbg-molbace_assessment/1_NESTED_CV'\n",
    "\n",
    "MLP_log_path_attr = f'./results/result_GIN_0411_atomencoder_attr_ogbg-molbace/AtomMLP_ogbg-molbace_assessment/1_NESTED_CV'\n",
    "GNN_log_path_attr = f'./results/result_GIN_0408_EGNN_lzd_attr_ogbg-molbace/EGIN_ogbg-molbace_assessment/1_NESTED_CV'\n",
    "\n",
    "dataset = datasets_obj['ogbg-molbace']\n",
    "ogbg_molbace_datasets = E_datasets(dataset, MLP_log_path_degree, GNN_log_path_degree, MLP_log_path_attr, GNN_log_path_attr, fold=1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get NCI1\n",
    "\n",
    "# 'NCI1', 'IMDB-MULTI', 'REDDIT-BINARY', 'CIFAR10',\n",
    "# #               'ogbg_molhiv', 'ogbg_moltox21', 'ogbg-molbace', 'MUTAG']\n",
    "\n",
    "# MNIST\n",
    "data_names = ['MNIST']\n",
    "              \n",
    "datasets_obj = {}\n",
    "for k, v in DATASETS.items():\n",
    "    if k not in data_names:\n",
    "        continue\n",
    "    print('loaded dataset, name:', k)\n",
    "    dat = v(use_node_attrs=True)\n",
    "    datasets_obj[k] = dat\n",
    "\n",
    "\n",
    "MLP_log_path_degree = f'./results/result_GIN_0329_graph_mlp_avgDegree_MNIST/MolecularGraphMLP_MNIST_assessment/1_NESTED_CV'\n",
    "GNN_log_path_degree = f'./results/result_GIN_0329_GIN_degree_MNIST/GIN_MNIST_assessment/1_NESTED_CV'\n",
    "\n",
    "MLP_log_path_attr = f'./results/tobedone/AtomMLP_ogbg-molbace_assessment/1_NESTED_CV'\n",
    "GNN_log_path_attr = f'./results/result_GIN_0329_GIN_attr_MNIST/GIN_MNIST_assessment/1_NESTED_CV'\n",
    "\n",
    "dataset = datasets_obj['ogbg-molbace']\n",
    "ogbg_molbace_datasets = E_datasets(dataset, MLP_log_path_degree, GNN_log_path_degree, MLP_log_path_attr, GNN_log_path_attr, fold=1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYN_CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SynCC\n",
    "data_names = ['syn_cc']\n",
    "\n",
    "\n",
    "syn_datasets = []\n",
    "for i in range(1, 10):\n",
    "    v = DATASETS['syn_cc']\n",
    "    config = {'dataset_para':f'{i/10}'}\n",
    "    dat = v(use_node_attrs=True, config=config)\n",
    "\n",
    "    gnn_data_root_path = f'./results/result_0422_GIN_lzd_degree_syn_cc_{i/10}/GIN_syn_cc_assessment/10_NESTED_CV'\n",
    "    mlp_data_root_path = f'./results/result_0422_Baseline_lzd_mlp_syn_cc_{i/10}/MolecularGraphMLP_syn_cc_assessment/10_NESTED_CV'\n",
    "    e_dataset_10_folds = E_datasets(dat, mlp_data_root_path, gnn_data_root_path, None, None)\n",
    "    syn_datasets.extend(e_dataset_10_folds)\n",
    "\n",
    "save_datasets(syn_datasets, 'syn_datasets.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor\n",
    "1. load datasets\n",
    "1. sample from datasets\n",
    "1. construct features\n",
    "1. construct labels (load from logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.6.\n"
     ]
    }
   ],
   "source": [
    "# load datasets:\n",
    "import importlib\n",
    "import random\n",
    "import argparse\n",
    "import configparser\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_sparse\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from torch_geometric.utils import negative_sampling, to_networkx\n",
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptPairTensor, Adj, OptTensor, Size\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "\n",
    "from dataset_utils import node_feature_utils\n",
    "from dataset_utils.node_feature_utils import *\n",
    "import my_utils as utils\n",
    "import sys,os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "\n",
    "importlib.reload(utils)\n",
    "\n",
    "# save datasets\n",
    "import pickle as pk\n",
    "\n",
    "def save_datasets(datasets, file_name):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pk.dump(datasets, f)\n",
    "\n",
    "def load_datasets(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        datasets = pk.load(f)\n",
    "    return datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load regressor datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- small: MUTAG, NCI1, DD, CIFAR10, MNIST, imdb_b, ogbg-molhiv, ogbg-molbace, ogbg-moltox21\n",
    "- middle: ogbg-ppa, (ogbg-molpcba, ogbg-code2, to be done)\n",
    "10-fold: MUTAG, NCI1, DD, CIFAR10, MNIST, imdb_b, SynCC\n",
    "one split: ogbg-molhiv, ogbg-molbace, ogbg-moltox21, ogbg-ppa\n",
    "\n",
    "use 10-fold to trian, use one split to test\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Medium\togbg-molpcba\t>=1.2.2\t437,929\t26.0\t28.1\t128\tScaffold\tBinary classification\tAP\n",
    "Medium\togbg-ppa\t>=1.1.1\t158,100\t243.4\t2,266.1\t1\tSpecies\tMulti-class classification\tAccuracy\n",
    "Medium\togbg-code2\n",
    "\"\"\"\n",
    "\n",
    "# small scale: < 10k\n",
    "train_datasets_names = ['mutag', 'nci1', 'dd', 'imdb_b', 'imdb_m', 'mnist', 'cifar10']\n",
    "test_datasets_names = ['ogbg_molhiv', 'ogbg_moltox21', 'ogbg_molbace']\n",
    "\n",
    "train_datasets = []\n",
    "for k in train_datasets_names:\n",
    "    train_datasets.append((load_datasets(f'{k}_datasets.pkl'), k))\n",
    "\n",
    "test_datasets = []\n",
    "    \n",
    "for k in test_datasets_names:\n",
    "    test_datasets.append((load_datasets(f'{k}_datasets.pkl'),k))\n",
    "    \n",
    "# SynCC\n",
    "syn_cc_datasets = load_datasets('syn_datasets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "7\n",
      "3\n",
      "train:\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "1\n",
      "1\n",
      "test:\n",
      "10\n",
      "1\n",
      "10\n",
      "total real data len: 73\n"
     ]
    }
   ],
   "source": [
    "print(len(syn_cc_datasets))\n",
    "print(len(train_datasets))\n",
    "print(len(test_datasets))\n",
    "print('train:')\n",
    "a = [print(len(d[0])) for d in train_datasets]\n",
    "print('test:')\n",
    "a = [print(len(d[0])) for d in test_datasets]\n",
    "# extend each dataset:\n",
    "\n",
    "# construct label for each dataset:\n",
    "all_datasets = []\n",
    "\n",
    "id_to_name = {}\n",
    "\n",
    "i = 0\n",
    "for d in train_datasets + test_datasets:\n",
    "    for fold_id, dd in enumerate(d[0]):\n",
    "        name = f'{d[1]}_{fold_id}'\n",
    "        id_to_name[i] = name\n",
    "        i += 1\n",
    "        all_datasets.append(dd)\n",
    "\n",
    "print('total real data len:', len(all_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72])\n",
      "imdb_m_4\n"
     ]
    }
   ],
   "source": [
    "# check id_to_name:\n",
    "print(id_to_name.keys())\n",
    "print(id_to_name[44]) # 44 is the id of ogbg_molhiv_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all datasets:\n",
    "    # F1: avgD:\n",
    "    # F2: avgCC:\n",
    "    # F3: avgD/N:\n",
    "    # F4: node num N:\n",
    "    # F5: labels\n",
    "    # calculate each dimension of labels:\n",
    "    # F6: cycles:\n",
    "real_datasets = []\n",
    "\n",
    "train_datasets_pairs, test_datasets_pairs = [],[]\n",
    "\n",
    "# for i, d in enumerate(syn_cc_datasets):\n",
    "#     if int(i//10) == 1 or int(i//10) == 8:\n",
    "#         train_datasets_paris.append(((d[0], d[1]), f'syn_cc:{str(round((((int(i/10)+1))/10.0), 1))}_{(i%10+1)}'))\n",
    "    \n",
    "# for i, d in enumerate(syn_cc_datasets):\n",
    "#     all_datasets_paris.append((d, f'syn_cc:{str(round((((int(i/10)+1))/10.0), 1))}_{(i%10+1)}'))\n",
    "\n",
    "for k, d in enumerate(train_datasets):\n",
    "    train_datasets_pairs.extend([(fold, f'small_:{train_datasets_names[k]}_{i}') for i, fold in enumerate(d)])\n",
    "\n",
    "for k, d in enumerate(test_datasets):\n",
    "    test_datasets_pairs.extend([(fold, f'middle:{test_datasets_names[k]}_{i}') for i, fold in enumerate(d)])\n",
    "\n",
    "train_name_id_dict = {i:d[1] for i, d in enumerate(train_datasets_pairs)}\n",
    "test_name_id_dict = {i:d[1] for i, d in enumerate(test_datasets_pairs)}\n",
    "\n",
    "def belong_to_which_datasets(idx, name_id_dict):\n",
    "    return name_id_dict[idx]\n",
    "\n",
    "print(len(train_name_id_dict), len(test_name_id_dict))\n",
    "\n",
    "new_train_datasets = [d[0] for d in train_datasets_pairs]\n",
    "new_test_datasets = [d[0] for d in test_datasets_pairs]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def plot_bars(preds, Y, show_data, regressor_name):\n",
    "    # es = []\n",
    "    # for i in range(data_block.shape[0]):\n",
    "    #     d= data_block[i]\n",
    "    #     es.append((get_E(d[1, 0], d[3, 0], d[0, 0], d[4, 0]), show_data[i]))\n",
    "\n",
    "    sorted_indices = np.argsort(Y)\n",
    "    predictions_sorted = preds[sorted_indices]\n",
    "    ground_truth_sorted = Y[sorted_indices]\n",
    "\n",
    "    bar_width = 0.3\n",
    "    bar_positions = np.arange(len(show_data)) * 1.5\n",
    "    x_label_positions = bar_positions + bar_width / 2\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(len(show_data)/3, 3), dpi=300)\n",
    "    print('bar_positions shape: ', bar_positions.shape)\n",
    "    print('predictions_sorted: ', predictions_sorted.shape)\n",
    "    \n",
    "    ax.bar(bar_positions.squeeze(), predictions_sorted.squeeze(), width=bar_width, color='blue', hatch='/', label='Predictions')\n",
    "    ax.bar(bar_positions + bar_width, ground_truth_sorted, width=bar_width, color='orange', hatch='-', label='Ground Truth')\n",
    "    ax.set_xticks(x_label_positions)\n",
    "    ax.set_xticklabels(show_data, rotation=45, ha='right')\n",
    "    ax.set_ylabel('Effectiveness', fontsize=16)\n",
    "    ax.set_xlabel('Dataset ID', fontsize=16)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(linestyle='dashed',zorder=0)\n",
    "    ax.legend( fontsize=16, title_fontsize=16)\n",
    "    ax.set_title(f'Predictions by {regressor_name}', fontsize=16)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def mean_norm(x):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(x), scaler\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.X = torch.tensor([t[0] for t in data], dtype=torch.float32)\n",
    "        self.Y = torch.tensor([t[1] for t in data], dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_data(num_samples):\n",
    "    features = np.random.rand(num_samples, 26)\n",
    "    labels = np.random.rand(num_samples, 1)\n",
    "    return [(features[i], labels[i]) for i in range(num_samples)]\n",
    "\n",
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, input_dim=26):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            # nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    \n",
    "def evaluate(loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    preds = []\n",
    "    Y = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.view(-1, 1))\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "            preds.append(outputs.cpu().numpy())\n",
    "            Y.append(labels.cpu().numpy())\n",
    "            \n",
    "    \n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    Y = np.concatenate(Y, axis=0).ravel()\n",
    "    \n",
    "    mae = mean_absolute_error(Y, preds)\n",
    "    mse = mean_squared_error(Y, preds)\n",
    "    rmse = math.sqrt(mse)\n",
    "    r2 = r2_score(Y, preds)\n",
    "    \n",
    "    results = (mae, mse, rmse, r2)\n",
    "    return mse, results, preds, Y\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def mlp_regressor(input_dim, train_loader, val_loader, test_loader, scaler_x, scaler_y, show_data=None):\n",
    "\n",
    "    model = MLPRegressor(input_dim).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    # criterion = nn.L1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    num_epochs = 500\n",
    "    train_losses, val_losses = [], []\n",
    "    min_val_loss = float(\"inf\") # initialize with a large value\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss, _, _, _ = evaluate(train_loader, model, criterion, device)\n",
    "        val_loss, _,_,_ = evaluate(val_loader, model, criterion, device)\n",
    "        \n",
    "        if val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_mlp_regressor_model.pth\")\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_mlp_regressor_model.pth\"))\n",
    "    test_loss, test_results, test_preds, test_Y = evaluate(test_loader, model, criterion, device)\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f'MLPs: {round(test_results[0], 2)} & {round(test_results[1], 2)} & {round(test_results[2], 2)} & {round(test_results[3], 2)}')\n",
    "\n",
    "    plot_bars(scaler_y.inverse_transform(test_preds), scaler_y.inverse_transform(test_Y), show_data,  \"MLP Regressor\")\n",
    "\n",
    "    # Plot train and validation loss curves\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Train and Validation Loss Curves\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 26) (73, 1)\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = np.array([t[0] for t in all_datasets])\n",
    "Y = np.array([t[1] for t in all_datasets])\n",
    "\n",
    "normalized_x, scaler_x = mean_norm(X)\n",
    "normalized_y, scaler_y = mean_norm(Y.reshape(-1, 1))\n",
    "\n",
    "print(normalized_x.shape, normalized_y.shape)\n",
    "\n",
    "print(len(normalized_x))\n",
    "normed_combined_data = [(normalized_x[i], normalized_y[i]) for i in range(normalized_x.shape[0])]\n",
    "\n",
    "dataset = CustomDataset(normed_combined_data)\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.0 * len(dataset))\n",
    "\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "test_data_names = [id_to_name[i] for i in test_data.indices]\n",
    "# print(len(train_loader.dataset), len(val_loader.dataset), len(test_loader.dataset))\n",
    "# print(len(dataset_ids))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use 10-fold to predict one fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train = np.array([t[0] for t in new_train_datasets])\n",
    "# Y_train = np.array([t[1] for t in new_train_datasets])\n",
    "\n",
    "# X_test = np.array([t[0] for t in new_test_datasets])\n",
    "# Y_test = np.array([t[1] for t in new_test_datasets])\n",
    "\n",
    "# normalized_x_train, scaler_x_train = mean_norm(X_train)\n",
    "# normalized_y_train, scaler_y_train = mean_norm(Y_train.reshape(-1, 1))\n",
    "\n",
    "# normalized_x_test = scaler_x_train.transform(X_test)\n",
    "\n",
    "\n",
    "# # print(normalized_x.shape, normalized_y.shape)\n",
    "\n",
    "# # print(len(normalized_x))\n",
    "\n",
    "# normed_combined_data_train = [(normalized_x_train[i], normalized_y_train[i]) for i in range(normalized_x_train.shape[0])]\n",
    "# # normed_combined_data_train = [(normalized_x_train[i], Y_train[i]) for i in range(normalized_x_train.shape[0])]\n",
    "# dataset = CustomDataset(normed_combined_data_train)\n",
    "\n",
    "# train_size = int(0.7 * len(dataset))\n",
    "# val_size = len(dataset) - train_size\n",
    "\n",
    "# train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# normed_combined_data_test = [(normalized_x_test[i], Y_test[i]) for i in range(normalized_x_test.shape[0])]\n",
    "# dataset_test = CustomDataset(normed_combined_data_test)\n",
    "# test_loader = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "\n",
    "# dataset_ids = [belong_to_which_datasets(i, test_name_id_dict) for i in range(len(dataset_test))]\n",
    "# print(len(dataset_ids))\n",
    "\n",
    "# print(len(train_loader.dataset), len(val_loader.dataset), len(test_loader.dataset))\n",
    "# # dataset_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold to predict one-fold dataset:\n",
    "mlp_regressor(26, train_loader, val_loader, test_loader, scaler_x_train, scaler_y_train, show_data=dataset_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-db9d36aca444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# all_datasets mixed:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlp_regressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-df982235b13f>\u001b[0m in \u001b[0;36mmlp_regressor\u001b[0;34m(input_dim, train_loader, val_loader, test_loader, scaler_x, scaler_y, show_data)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_val_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-df982235b13f>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(loader, model, criterion, device)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "# all_datasets mixed:\n",
    "mlp_regressor(26, train_loader, val_loader, test_loader, scaler_x, scaler_y, show_data=[i for i in range(len(test_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regressor(loader, regressor):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for inputs, labels in loader:\n",
    "        X.extend(inputs.cpu().numpy())\n",
    "        Y.extend(labels.cpu().numpy())\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y).ravel()\n",
    "\n",
    "    regressor.fit(X, Y)\n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "\n",
    "def regressor_evaluate(loader, regressor):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        X.extend(inputs.cpu().numpy())\n",
    "        Y.extend(labels.cpu().numpy())\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y).ravel()\n",
    "\n",
    "    preds = regressor.predict(X)\n",
    "    mae = mean_absolute_error(Y, preds)\n",
    "    mse = mean_squared_error(Y, preds)\n",
    "    rmse = math.sqrt(mse)\n",
    "    r2 = r2_score(Y, preds)\n",
    "    \n",
    "    results = (mae, mse, rmse, r2)\n",
    "    return mse, results, preds, Y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline regressors:\n",
    "- random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Y shape: (22, 1) (22, 1)\n",
      "bar_positions shape:  (22,)\n",
      "predictions_sorted:  (22, 1, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, regressor \u001b[39min\u001b[39;00m regressors\u001b[39m.\u001b[39mitems():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     results\u001b[39m.\u001b[39mappend(run_regressor(regressor, k))\n",
      "\u001b[1;32m/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb Cell 17\u001b[0m in \u001b[0;36mrun_regressor\u001b[0;34m(regressor, regressor_name)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# decide which test dataset belong to:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# dataset_ids = [belong_to_which_datasets(i) for i in test_data.indices]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtest_Y shape:\u001b[39m\u001b[39m'\u001b[39m, test_Y\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape, test_preds\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m plot_bars(scaler_y\u001b[39m.\u001b[39;49minverse_transform(test_preds\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m            scaler_y\u001b[39m.\u001b[39;49minverse_transform(test_Y\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)), test_data_names, regressor_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# print(f\"regressor_name: {regressor_name}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Test Loss: {test_loss:.4f} \\\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m#       (mse, rmse, r^2): {test_reuslts}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mregressor_name\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(test_reuslts[\u001b[39m0\u001b[39m], \u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m & \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(test_reuslts[\u001b[39m1\u001b[39m], \u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m & \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(test_reuslts[\u001b[39m2\u001b[39m], \u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m & \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mround\u001b[39m(test_reuslts[\u001b[39m3\u001b[39m], \u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb Cell 17\u001b[0m in \u001b[0;36mplot_bars\u001b[0;34m(preds, Y, show_data, regressor_name)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mpredictions_sorted: \u001b[39m\u001b[39m'\u001b[39m, predictions_sorted\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m ax\u001b[39m.\u001b[39mbar(bar_positions\u001b[39m.\u001b[39msqueeze(), predictions_sorted\u001b[39m.\u001b[39msqueeze(), width\u001b[39m=\u001b[39mbar_width, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m'\u001b[39m, hatch\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPredictions\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m ax\u001b[39m.\u001b[39;49mbar(bar_positions \u001b[39m+\u001b[39;49m bar_width, ground_truth_sorted, width\u001b[39m=\u001b[39;49mbar_width, color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39morange\u001b[39;49m\u001b[39m'\u001b[39;49m, hatch\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m'\u001b[39;49m, label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mGround Truth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m ax\u001b[39m.\u001b[39mset_xticks(x_label_positions)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lizhengdao/src/github/GenerativeGNN/regressor.ipynb#X23sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m ax\u001b[39m.\u001b[39mset_xticklabels(show_data, rotation\u001b[39m=\u001b[39m\u001b[39m45\u001b[39m, ha\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/__init__.py:1414\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1412\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1413\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1414\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1416\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1417\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1418\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/axes/_axes.py:2398\u001b[0m, in \u001b[0;36mAxes.bar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2395\u001b[0m args \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(left, bottom, width, height, color, edgecolor, linewidth,\n\u001b[1;32m   2396\u001b[0m            hatch)\n\u001b[1;32m   2397\u001b[0m \u001b[39mfor\u001b[39;00m l, b, w, h, c, e, lw, htch \u001b[39min\u001b[39;00m args:\n\u001b[0;32m-> 2398\u001b[0m     r \u001b[39m=\u001b[39m mpatches\u001b[39m.\u001b[39;49mRectangle(\n\u001b[1;32m   2399\u001b[0m         xy\u001b[39m=\u001b[39;49m(l, b), width\u001b[39m=\u001b[39;49mw, height\u001b[39m=\u001b[39;49mh,\n\u001b[1;32m   2400\u001b[0m         facecolor\u001b[39m=\u001b[39;49mc,\n\u001b[1;32m   2401\u001b[0m         edgecolor\u001b[39m=\u001b[39;49me,\n\u001b[1;32m   2402\u001b[0m         linewidth\u001b[39m=\u001b[39;49mlw,\n\u001b[1;32m   2403\u001b[0m         label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m_nolegend_\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m   2404\u001b[0m         hatch\u001b[39m=\u001b[39;49mhtch,\n\u001b[1;32m   2405\u001b[0m         )\n\u001b[1;32m   2406\u001b[0m     r\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   2407\u001b[0m     r\u001b[39m.\u001b[39mget_path()\u001b[39m.\u001b[39m_interpolation_steps \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/patches.py:733\u001b[0m, in \u001b[0;36mRectangle.__init__\u001b[0;34m(self, xy, width, height, angle, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[39m@docstring\u001b[39m\u001b[39m.\u001b[39mdedent_interpd\n\u001b[1;32m    715\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, xy, width, height, angle\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    716\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[39m    ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39m        %(Patch:kwdoc)s\u001b[39;00m\n\u001b[1;32m    732\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    734\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_x0 \u001b[39m=\u001b[39m xy[\u001b[39m0\u001b[39m]\n\u001b[1;32m    735\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y0 \u001b[39m=\u001b[39m xy[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/patches.py:106\u001b[0m, in \u001b[0;36mPatch.__init__\u001b[0;34m(self, edgecolor, facecolor, color, linewidth, linestyle, antialiased, hatch, fill, capstyle, joinstyle, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_fill(fill)\n\u001b[1;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_linestyle(linestyle)\n\u001b[0;32m--> 106\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_linewidth(linewidth)\n\u001b[1;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_antialiased(antialiased)\n\u001b[1;32m    108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_hatch(hatch)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/patches.py:411\u001b[0m, in \u001b[0;36mPatch.set_linewidth\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[39mif\u001b[39;00m w \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    409\u001b[0m         w \u001b[39m=\u001b[39m mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39maxes.linewidth\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 411\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_linewidth \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(w)\n\u001b[1;32m    412\u001b[0m \u001b[39m# scale the dash pattern by the linewidth\u001b[39;00m\n\u001b[1;32m    413\u001b[0m offset, ls \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_us_dashes\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAB0QAAAMqCAYAAAASPvKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAC4jAAAuIwF4pT92AAB1cUlEQVR4nOz9e7SsWV0fen8nNs2lm6hcWqS5NDaKoALe4AS8gKIYLwFzgomXJGrURI+vMR5FzeWgxqioO5GMIScejxE96quSRMFrRAVUMNGoqC+IR0AQaJWLgIDd0MB8/1hry9pP771WVa1aq+Zv1uczxh6M51lVT81eg1Vz/n7fqme23nsAAAAAAAAAZnS7XQ8AAAAAAAAA4KwIRAEAAAAAAIBpCUQBAAAAAACAaQlEAQAAAAAAgGkJRAEAAAAAAIBpCUQBAAAAAACAaQlEAQAAAAAAgGkJRAEAAAAAAIBpCUQBAAAAAACAaQlEAQAAAAAAgGkJRAEAAAAAAIBpCUQBAAAAAACAaQlEAQAAAAAAgGkJRAEAAAAAAIBpCUQBAAAAAACAaQlEAQAAAAAAgGkJRAEAAAAAAIBpCUQBAAAAAACAaQlEAQAAAAAAgGkJRAEAAAAAAIBpCUQBAAAAAACAaQlEAQAAAAAAgGkJRAEAAAAAAIBpCUQBAAAAAACAaQlEAQAAAAAAgGkJRAEAAAAAAIBpXbXrAXB+WmvvneTjj5x6VZJ37Gg4AAAAAAAA7Ierk9znyPHzeu9vPq8XF4jul49P8sxdDwIAAAAAAIC99vgkzzqvF3PLXAAAAAAAAGBaAlEAAAAAAABgWm6Zu19edfTgJ3/yJ/OABzxgV2MBAAAAAABgD7z0pS/NE57whKOnXnWFh54Jgeh+ecfRgwc84AH5kA/5kF2NBQAAAAAAgP30jpMfsj1umQsAAAAAAABMSyAKAAAAAAAATEsgCgAAAAAAAExLIAoAAAAAAABMSyAKAAAAAAAATEsgCgAAAAAAAExLIAoAAAAAAABMSyAKAAAAAAAATEsgCgAAAAAAAExLIAoAAAAAAABMSyAKAAAAAAAATEsgCgAAAAAAAExLIAoAAAAAAABMSyAKAAAAAAAATEsgCgAAAAAAAExLIAoAAAAAAABMSyAKAAAAAAAATEsgCgAAAAAAAExLIAoAAAAAAABMSyAKAAAAAAAATEsgCgAAAAAAAExLIAoAAAAAAABMSyAKAAAAAAAATEsgCgAAAAAAAExLIAoAAAAAAABMSyAKAAAAAAAATEsgCgAAAAAAAExLIAoAAAAAAABMSyAKAAAAAAAATEsgCitqbfN/+8Lv6GR+Rydb/3dzIa21tD36Jfn/0cn8jlbjd3Qyv6OT+R2dzHvSyY7O55f+u+B3dMj/j07md3Qyv6PVHP+7uPL71T7x/6OT+R2dzO/oZN63T+Z3dDK/o5OtU3/s6+9oBgJRAAq7kOSrdz0IAODULjeff2eS//28BwJwjCvVH96vgNHs14c0YDvM57MTiAJQlDAUAOalGQGMRhgKVKFfAuszn+8DgSgABVncA8C8NCOA0QhDgSr0S2Az5vN9IBAFoJjjmhEAQG3CBWA0wlCgCmEowHEEogAUohkBAPMynwOjUX8AVQhDAU4iEAWgCM0IoIoLux4AFGQ+B0aj/gCqEIYCrEIgCkABmhFAFZoRsBnzOTAS9QdQhW2FAFYlEAVgcJoRQBXCUACYg/oDqEC/BGAdAlEABmZxD1QhDAWAeak/gNHolwCsSyAKwKAs7oEqhKEAMC/1BzAa/RKATQhEARiQxT1QhTAUAOal/gBGo18CsCmBKACDsbgHqjju/QoAqE39AYxGvwTgNASiAAzG4h6oQDMCqOLCrgcABZnPgdGoPwBOSyAKwOAs7oHRaEYAVbitN2zGfA6MRP0BsA0CUQAGZnEPjEYzAqhCGAoA9ak/ALZFIArAoCzugdFoRgBVCEMBYA7qD4BtEYjCmbNnD6zP4h4YjTAUqEIYCgDzUn8AbEogCmdKMwLWZ3EPjEYYClSh/gCAeak/AE5DIApnRjMCNmNxD4xEGApUcdz7FQBQm/oD4LQEonAmhKEAMAdhKFCBD28AwLzM5wDbIBCFrROGAsC8NCOA0QhDgSou7HoAUJD5HGBbBKKwVcJQAJiXZgQwGmEoUIV+CWzGfA6wLQJR2Bp79gDAvIQLwGiEoUAVwlAAYPcEorAVmhEAMC/zOTAa9QdQhTAUABiDQBROTTMCqMKePbA+8zkwGvUHUIUwFAAYh0AUTkUzAqhCMwI2Yz4HRqL+AKpQfwAAYxGIwsY0I4AqNCMAoD71B1DFce9XAAC7IRCFjWhGAFUIQwFgDuoPoAL9EqAK2wrBvhGIwtos7oEqhKEAMC/1BzAa/RKgCv0S2EcCUViLxT1QhcU9AMxL/QGMRr8EqEK/BPaVQBRWZnEPVGHPHgCYl/oDGI1+CVCFMBT2mUAUVmZxD1SgGQEA8zKfA6NRfwBVCENh3wlEYWMW98BoNCOAKi7segBQkPkcGI36A6hCGAoIRGFDFvfAaDQjgCo0I2Az5nNgJOoPoArbCgEHBKKwNot7YDSaEUAVwlAAmIP6A6hAvwR4D4EorMVkCYzG4h6oQhgKAPNSfwCj0S8BLiUQhZWZLIHRWNwDVQhDAWBe6g9gNPolwG1dtesBXE5rrSW5IcmHJbl3kvdJ8vYkb0zyR0l+s/d+y67Gd1Fr7aokj0jyoUnuluRdSf40yW/13l+0y7FxFkyWwEgs7oEqhKEAMC/1BzAa/RLg8oYJRFtr75vkCUk+JcknJLn7MQ+/tbX2M0m+q/f+vHMY3iVaa9cm+bokX5rkrld4zB8meUqSp/fe+zkOD4DpWdwDVRz3fgUA1Kb+AEajXwJc2RC3zG2tfXeSP0vyn5J8Vo4PQ5Pk9jkIT5/bWvuB1trfONsRvkdr7cOS/F6Sf5krhKGHHpiD/56fa62993mMDYB9YXEPVKAZAVRxYdcDgILM58Bo1B/A8YYIRHNw29mrL3P+XUleneS3chBCvvkyj/mHSZ59+K3NM9Vae2CSX05y/8WP3pqD8f1RklsXP3tcDkLRO571+ADYVxb3wGg0I4Aq3NYbNmM+B0ai/gBONkogetSbkjwtyacled/e+3167x/Ve39oDvbpfEySX1085+FJnn6WgzrcL/QZufTbq3+R5B8luWvv/aG99w9Kcs8k/zbJu4887m8m+fazHB8A+8riHhiNZgRQhTAUAOpTfwCrGSkQfUWSL0pyr977/9Z7/9ne+1uOPqD3/q7e+3NzEIr+X4vn/6+ttcec4fi+MMmHHTl+Y5KP7b3/YO/9r78V2nv/i977v0ryDxbP/9LW2gee4fgA2DsW98BoNCOAKoShADAH9QewmlEC0ScneWDv/ft67zef9ODe+7uSfFmS/7n40RedxeBaa1cn+VeL01/de3/xlZ7Te/+RJD905NRVSb5h+6ODGdizB9ZncQ+MRhgKVCEMBYB5qT+AyxsiEO29/0zv/R1rPuddue1taB+3vVHd5rr3OXL8iiTfv8LzviFJP3L8xNbae29vWDADzQhYn8U9MBphKFCF+gMA5qX+AK5siED0FJZ7id6ttXbnM3idxy+Ov7/33i/7yCN67y9L8rwjp26f5FO3OTCoTTMCNmNxD4xEGApUcdz7FQBQm/oDOF71QPSNlzl3Ft/A/LTF8S+s8dxnL44//ZRjgUkIQwFgDsJQoAIf3gCAeZnPgZNVD0Svv8y5N2zzBVpr75fknkdOvT3Jb69xiecvjh922jFBfcJQAJiXZgQwGmEoUMWFXQ8ACjKfA6upHoh+7OL4levuRbqCBy2OX7rma7x4cfyA1tpVpxwTFCYMBYB5aUYAoxGGAlXol8BmzOfAaqoHol+4OP7ZM3iNBy6OX7XOk3vvr0tyy5FTVye5/2kHBTXZswcA5iVcAEYjDAWqEIYCwFkr+03F1tqnJvm4xemnn8FLXbc4fvUG17gpyQcsrvlHG48oSWvtuiT3WPNpN57mNeF0NCMAYF7mc2A06g+gCmEoAJyHkoFoa+2uSb5ncfone++/cQYvd+3i+G0bXGP5nOU1N/FlSZ68hevAOdCMAKq4EO9LsC7zOTAa9QdQhTAUAM5LuVvmttZul+SHktz7yOk3J/mKM3rJZXh5y2UfdbybT7gmTEwzAqhCMwI2Yz4HRqL+AKpQfwDAeSoXiCb5jiR/a3Hun/Te19rbcw13XBy/Y4NrvH1xfKcNxwLFaEYAVWhGAEB96g+giuPerwCAs1Dqlrmtta9I8lWL09/ee/+xM3zZ5TdCr97gGnc44ZqbeFqSZ6z5nBuTPHMLrw0r0IwAqhCGAsAc1B9ABfolQBW2FWIuZQLR1trnJPmuxemnJ/m6M37pty6Ol98YXcXyG6HLa66t9/7aJK9d5zmttdO+LKzI4h6oQhgKAPNSfwCj0S8Bqrj4fuW9iXmUuGVua+3Tk/xAkqOJ3n9N8kW9937GL78ML6/Z4BrL55w6EIVxWdwDVQhDAWBe6g9gNPolQBX6Jcxp+EC0tfaYHNwa9ui3WZ+d5LN77+86hyEsv4V57w2uca8TrgmTsLgHqrBnDwDMS/0BjEa/BKhCGMq8hg5EW2uPSPKsXHqb2hck+cze+zvOaRh/uDi+7zpPbq1dl0vH/44kLz/toGBMFvdABZoRQBUXdj0AKMh8DoxG/QFUIQxlbsMGoq21hyT5uSTXHjn9O0k+tff+tnMcyksWxze21q5e4/kPWhy/rPf+zlOOCYqwuAdGoxkBVKEZAesznwOjUX8AVag/mN+QgWhr7YE5uC3u+x45/QdJHtd7f/N5jqX3/mdJ/uzIqTsk+cg1LvGoxfELTzsmqMHiHhiNZgRQhWYEbMZ8DoxE/QFUYVsh9sNwgWhr7X5JfjHJdUdO/3GST+q9v243o8rPLI4/aY3nLh/7U6ccCxRgcQ+MRjMCqEIYCgBzUH8AFeiXsD+GCkRba++f5JeS3PvI6dck+cTe+2t2M6okB/uYHvUFrbV20pNaazcm+fgjp25N8rPbHBiMx2QJjMbiHqhCGAoA81J/AKPRL2G/DBOIttbumoPb5N545PTrcvDN0D/ezaj+2n9L8uojxzck+YIVnvcNSY4Gp//lvG/5C+fLZAmMxuIeqEIYCgDzUn8Ao9EvYf8MEYi21u6S5OeTfMiR029K8sm99z/Y8mvd0Frri383HPec3vvbk/zbxenvbK09+JjX+Zwkn3fk1LuSPHnTcUMNJktgJBb3QBX27AGAeak/gNHol7Cfrtr1AA49K8lHL879uyR3b609ds1r/Vbv/Y3bGdYlvi/Jl+c9oe37JvnV1to/T/Ijvfd3Jn/9Tdd/nuRfLJ7/Pb33//cMxgUA3IbFPVCF9ysAmJf5HBiN+oP9NUog+ujLnPumDa/1mCTP3XgkV9B7v7W19sQkv5bkroen75rkB5J8d2vtZUnulOT+SW6/ePpvxP2vAOAcWdwDFWhGAFVciPclWJf5HBiN+oP9NsQtc6s4vH3vJyR55eJH1yZ5aJIPym3D0F9M8rje+81nP0IA4PIs7oHRaEYAVdjjGDZjPgdGov4Ageiaeu+/m+TDknxrkuNuzftHSb44B/ugvukchgYAXJbFPTAazQigCmEoANSn/oBkkFvm9t7bOb7WK5Kc6vV6729J8i9aa09O8ogkH5rkbkneleRPk/x27/33TzlUAODULO6B0WhGAFUIQwFgDuoPSAYJRKvqvd+agz1Ff23XYwFmZ88eWJ/FPTAaYShQhTAUAOal/mA/uWUuwPA0I2B9FvfAaIShQBXqDwCYl/qD/SUQBRiaZgRsxuIeGIkwFKjiuPcrAKA29Qf7TSAKMCxhKADMQRgKVODDGwAwL/M5CEQBhiQMBYB5aUYAoxGGAlVc2PUAoCDzOSQCUYABCUMBYF6aEcBohKFAFfolsBnzOSQCUYDB2LMHAOYlXABGIwwFqhCGAnA6AlGAYWhGAMC8zOfAaNQfQBXCUABOTyAKMATNCKAKe/bA+sznwGjUH0AVwlAAtkMgCrBzmhFAFZoRsBnzOTAS9QdQhfoDgO0RiALslGYEUIVmBADUp/4Aqjju/QoA1icQBdgZzQigCmEoAMxB/QFUoF8CVGFboUoEogA7YXEPVCEMBYB5qT+A0eiXAFXol1QjEAU4dxb3QBUW9wAwL/UHMBr9EqAK/ZKKBKIA58riHqjCnj0AMC/1BzAa/RKgCmFoVQJRgHNlcQ9UoBkBVGHPHlif+RwYjfoDqEIYWplAFGCnLO6B0WhGAFVoRsD6zOfAaNQfQBXqj+oEogA7Y3EPjEYzAqhCMwI2Yz4HRqL+AKqwrdAMBKIAO2FxD4xGMwKoQhgKAHNQfwAV6JfMQiAKcO5MlsBoLO6BKoShADAv9QcwGv2SmQhEAc6VyRIYjcU9UIUwFADmpf4ARqNfMhuBKMC5MlkCI7G4B6qwZw8AzEv9AYxGv2RGAlEAgL1lcQ9UoBkBAPMynwOjUX/MSiAKAMAhi3tgNJoRQBUXdj0AKMh8DoxG/TEzgSgAALG4B8ajGQFUYY9j2Iz5HBiJ+mN2AlEAgL1ncQ+MRjMCqEIYCgD1qT/2gUAUAGCvWdwDo9GMAKoQhgLAHNQf+0AgCsAk7NkD67O4B0YjDAWqEIYCwLzUHzMSiAIwAc0I2IzFPTASYShQhfoDAOal/piVQBSA4jQjAKA+YShQxXHvVwBAbeqPmQlEAShMGAoAcxCGAhX48AZQhW2FYH3m89kJRAEoShgKAPPSjABGIwwFqtAvgfWZz/eBQBSAgizuAWBemhHAaIShQBX6JbAZ8/k+EIgCUIw9ewBgXsIFYDTCUKAKYSjAcQSiABSiGQEA8zKfA6NRfwBVCEMBTiIQBaAIzQigigu7HgAUZD4HRqP+AKoQhgKsQiAKQAGaEUAVmhGwGfM5MBL1B1CFbYUAViUQBWBwmhFAFcJQAJiD+gOoQL8EYB0CUQAGZnEPVCEMBYB5qT+A0eiXAKxLIArAoCzugSqEoQAwL/UHMBr9EoBNCEQBGJDFPVCFMBQA5qX+AEajXwKwKYEoAIOxuAeqOO79CgCoTf0BjEa/BOA0BKIADMbiHqhAMwKo4sKuBwAFmc+B0ag/AE5LIArA4CzugdFoRgBVuK03bMZ8DoxE/QGwDQJRAAZmcQ+MRjMCqEIYCgD1qT8AtkUgCsCgLO6B0WhGAFUIQwFgDuoPgG0RiMKZs2cPrM/iHhiNMBSoQhgKAPNSfwBsSiAKZ0ozAtZncQ+MRhgKVKH+AIB5qT8ATkMgCmdGMwI2Y3EPjEQYClRx3PsVAFCb+gPgtASicCaEoQAwB2EoUIEPbwDAvMznANsgEIWtE4YCwLw0I4DRCEOBKi7segBQkPkcYFsEorBVwlAAmJdmBDAaYShQhX4JbMZ8DrAtAlHYGnv2AMC8hAvAaIShQBXCUABg9wSisBWaEQAwL/M5MBr1B1CFMBQAGINAFE5NMwKowp49sD7zOTAa9QdQhTAUABiHQBRORTMCqEIzAjZjPgdGov4AqlB/AABjEYjCxjQjgCo0IwCgPvUHUMVx71cAALshEIWNaEYAVQhDAWAO6g+gAv0SoArbCsG+EYjC2izugSqEoQAwL/UHMBr9EqAK/RLYRwJRWIvFPVCFxT0AzEv9AYxGvwSoQr8E9pVAFFZmcQ9UYc8eAJiX+gMYjX4JUIUwFPaZQBRWZnEPVKAZAQDzMp8Do1F/AFUIQ2HfCURhYxb3wGg0I4AqLux6AFCQ+RwYjfoDqEIYCghEYUMW98BoNCOAKjQjYDPmc2Ak6g+gCtsKAQcEorA2i3tgNJoRQBXCUACYg/oDqEC/BHgPgSisxWQJjMbiHqhCGAoA81J/AKPRLwEuJRCFlZksgdFY3ANVCEMBYF7qD2A0+iXAbQlEYWUmS2AkFvdAFcJQAJiX+gMYjX4JcHkCUQAox+IeqOK49ysAoDb1BzAa/RLgygSiAFCOxT1QgWYEUMWFXQ8ACjKfA6NRfwDHE4gCQHkW98BoNCOAKtzWGzZjPgdGov4ATiYQBYDSLO6B0WhGAFUIQwGgPvUHsBqBKACUZXEPjEYzAqhCGAoAc1B/AKsRiAIDsGcPrM/iHhiNMBSoQhgKAPNSfwCXJxAFdkwzAtZncQ+MRhgKVKH+AIB5qT+AKxOIAjukGQGbsbgHRiIMBao47v0KAKhN/QEcTyAK7IgwFADmIAwFKvDhDQCYl/kcOJlAFNgBYSgAzEszAhiNMBSo4sKuBwAFmc+B1QhEgXMmDAWAeWlGAKMRhgJV6JfAZsznwGoEosA5smcPAMxLuACMRhgKVCEMBYCzJhAFzolmBADMy3wOjEb9AVQhDAWA8yAQBc6BZgRQhT17YH3mc2A06g+gCmEoAJwXgShwxjQjgCo0I2Az5nNgJOoPoAr1BwCcJ4EocIY0I4AqNCMAoD71B1DFce9XAMBZEIgCZ0QzAqhCGAoAc1B/ABXolwBV2FaIuQhEgTNgcQ9UIQwFgHmpP4DR6JcAVeiXMB+BKLBlFvdAFRb3ADAv9QcwGv0SoAr9EuYkEAW2yOIeqMKePQAwL/UHMBr9EqAKYSjzEogCW2RxD1SgGQFUYc8eWJ/5HBiN+gOoQhjK3ASiwBmyuAdGoxkBVKEZAesznwOjUX8AVag/mJ9AFDgjFvfAaDQjgCo0I2Az5nNgJOoPoArbCrEfBKLAGbC4B0ajGQFUIQwFgDmoP4AK9EvYHwJRYMtMlsBoLO6BKoShADAv9QcwGv0S9otAFNgikyUwGot7oAphKADMS/0BjEa/hP0jEAW2yGQJjMTiHqjCnj0AMC/1BzAa/RL2k0AUAJiQxT1QhfcrAJiX+RwYjfqD/SUQBQAmZHEPVKAZAVRxYdcDgILM58Bo1B/sN4EoALAHLO6B0WhGAFXY4xg2Yz4HRqL+AIEoADA5i3tgNJoRQBXCUACoT/0BiUAUAJiaxT0wGs0IoAphKADMQf0BiUAUoAh79sD6LO6B0QhDgSqEoQAwL/UH+0kgCjA8zQhYn8U9MBphKFCF+gMA5qX+YH8JRAGGphkBm7G4B0YiDAWqOO79CgCoTf3BfhOIAgxLGAoAcxCGAhX48AYAzMt8DgJRgCEJQwFgXpoRwGiEoUAVF3Y9ACjIfA6JQBRgQMJQAJiXZgQwGmEoUIV+CWzGfA6JQBRgMPbsAYB5CReA0QhDgSqEoQCcjkAUYBiaEQAwL/M5MBr1B1CFMBSA0xOIAgxBMwKowp49sD7zOTAa9QdQhTAUgO0QiALsnGYEUIVmBGzGfA6MRP0BVKH+AGB7BKIAO6UZAVShGQEA9ak/gCqOe78CgPUJRAF2RjMCqEIYCgBzUH8AFeiXAFXYVqgSgSjATljcA1UIQwFgXuoPYDT6JUAV+iXVCEQBzp3FPVCFxT0AzEv9AYxGvwSoQr+kIoEowLmyuAeqsGcPAMxL/QGMRr8EqEIYWpVAFOBcWdwDFWhGAFXYswfWZz4HRqP+AKoQhlYmEAXYKYt7YDSaEUAVmhGwPvM5MBr1B1CF+qO6YQPR1tr1rbXPbK19W2vtl1trf9la60f+veKcx/Pcxeuv++/zz3O8QAUW98BoNCOAKjQjYDPmc2Ak6g+gCtsKzeCqXQ/gqNbao3Iw2z0iyb12PByAM2RxD4xGMwKoQhgKAHNQfwAV6JfMYqhANMlHJ/nMXQ8C4GyZLIHRWNwDVQhDAWBe6g9gNPolMxktED3OW5Ncu+tBHPFJaz7+RWcyCqAYkyUwGot7oAphKADMS/0BjEa/ZDajBqJvSfJbSX4zyW8c/u/9kzxnl4M6qvf+i7seA1CRyRIYicU9UIU9ewBgXuoPYDT6JTMaLRD9qSS/kOQlvfd3H/1Ba+3+uxkSAMCsLO6BCjQjAGBe5nNgNOqPWd1u1wM4qvf+st77i5dhKAAA58HiHhiNZgRQxYVdDwAKMp8Do1F/zGyoQBQAgF2xuAdGoxkBVGGPY9iM+RwYifpjdgJRAIC9Z3EPjEYzAqhCGAoA9ak/9oFAFABgr1ncA6PRjACqEIYCwBzUH/tAIHoKrbX3bq09pLX2ca21j2it3a+19l67HhfAfrJnD6zP4h4YjTAUqEIYCgDzUn/MSCC6odba7yT5iyS/m+R5SX4rySuSvKm19vOttS9urd1hh0ME2COaEbAZi3tgJMJQoAr1BwDMS/0xq6t2PYDCHnaF89cmedzhv29qrX1F7/0Z237x1tp1Se6x5tNu3PY4AHZPMwIA6hOGAlUc934FANSm/piZQPRs3TPJj7fWvrP3/jVbvvaXJXnylq8JUIwwFADmIAwFKvDhDaCKC/G+BOsyn8/OLXPXc0uSn8pBGPnIJNcluTrJXXLw7cvPS/IzSfrieV/dWvu6cxwnwB4QhgLAvDQjgNEIQ4Eq9EtgfebzfeAboqv7d0me33t/w2V+dmuStyZ5eZIfbq19TJIfTXL9kcd8S2vt53rvv3v2QwWYncU9AMxLMwIYjTAUqEK/BDZjPt8HAtEV9d6ftcZjf6219ugkv57k7oenW5JvTvIZWxrS05KsuzfpjUmeuaXXB9gRe/YAwLyEC8BohKFAFcJQgOMIRM9I7/2lrbWvSfL9R05/amvtrr33v9jC9V+b5LXrPKe1dtqXBdgxzQgAmJf5HBiN+gOoQhgKcBJ7iJ6tH0zyuiPHt0vy2B2NBaA4zQigigu7HgAUZD4HRqP+AKoQhgKsQiB6hnrv707y3MXpB+5gKADFaUYAVWhGwGbM58BI1B9AFbYVAliVQPTsvWpxfI+djAKgLM0IoAphKADMQf0BVKBfArAOgejZu3VxfPudjAKgJIt7oAphKADMS/0BjEa/BGBdAtGzd8/F8esu+ygAFizugSqEoQAwL/UHMBr9EoBNCETP3scsjpe30AXgNizugSqEoQAwL/UHMBr9EoBNCUTPUGvt45PcuDj9S7sYC0AdFvdAFce9XwEAtak/gNHolwCchkD0jLTWrknyHxanf7/3/vJdjAegDot7oALNCKCKC7seABRkPgdGo/4AOK29DERba33x79EnPP6prbV7rXH9uyd5VpKHLH705LUHC7D3LO6B0WhGAFW4rTdsxnwOjET9AbANV+16AEuttUcludNlfvTQxfEdW2uPvcJlbuq9v3iLw/qKJP+ktfZzSf5zkuf33l+xfFBr7T5J/n6Sr0pyz8WPf7L3/hNbHBPAHrC4B0ajGQFUIQwFgPrUHwDbMlwgmuSHk9xvhce9X5JnX+FnP5Dk87c1oEN3SPKEw39prf1lkj9N8uYktz8cz5W+RfqrST5ny+MBmJzFPTAazQigCmEoAMxB/QGwLXt5y9wt+RtJHpjk4Uk+PJcPQ9+d5NuTfGLv/eZzHBtDsWcPrM/iHhiNMBSoQhgKAPNSfwBsSiC6mi9J8qNJXrXi4/8syVOTPLD3/rW991vPbGQMTjMC1mdxD4xGGApUof4AgHmpPwBOY7hb5vbebziH12hrPv57k3xvkrTW7pbkQTm4re89klyT5F1J3pjk9Ul+p/f+8q0OmKI0I2AzFvfASIShQBXHvV8BALWpPwBOa7hAdHS99zck+bXDf3AFwlAAmIMwFKjAhzcAYF7mc4BtcMtc2DphKADMSzMCGI0wFKjiwq4HAAWZzwG2RSAKWyUMBYB5aUYAoxGGAlXol8BmzOcA2yIQha2xZw8AzEu4AIxGGApUIQwFAHZPIApboRkBAPMynwOjUX8AVQhDAYAxCETh1DQjgCrs2QPrM58Do1F/AFUIQwGAcQhE4VQ0I4AqNCNgM+ZzYCTqD6AK9QcAMBaBKGxMMwKoQjMCAOpTfwBVHPd+BQCwGwJR2IhmBFCFMBQA5qD+ACrQLwGqsK0Q7BuBKKzN4h6oQhgKAPNSfwCj0S8BqtAvgX0kEIW1WNwDVVjcA8C81B/AaPRLgCr0S2BfCURhZRb3QBX27AGAeak/gNHolwBVCENhnwlEYWUW90AFmhEAMC/zOTAa9QdQhTAU9p1AFDZmcQ+MRjMCqOLCrgcABZnPgdGoP4AqhKGAQBQ2ZHEPjEYzAqhCMwI2Yz4HRqL+AKqwrRBwQCAKa7O4B0ajGQFUIQwFgDmoP4AK9EuA9xCIwlpMlsBoLO6BKoShADAv9QcwGv0S4FICUViZyRIYjcU9UIUwFADmpf4ARqNfAtyWQBRWZrIERmJxD1QhDAWAeak/gNHolwCXJxAFgHIs7oEqjnu/AgBqU38Ao9EvAa5MIAoA5VjcAxVoRgBVXNj1AKAg8zkwGvUHcDyBKACUZ3EPjEYzAqjCbb1hM+ZzYCTqD+BkAlEAKM3iHhiNZgRQhTAUAOpTfwCrEYgCQFkW98BoNCOAKoShADAH9QewGoEoMAB79sD6LO6B0QhDgSqEoQAwL/UHcHkCUWDHNCNgfRb3wGiEoUAV6g8AmJf6A7gygSiwQ5oRsBmLe2AkwlCgiuPerwCA2tQfwPEEosCOCEMBYA7CUKACH94AgHmZz4GTCUSBHRCGAsC8NCOA0QhDgSou7HoAUJD5HFiNQBQ4Z8JQAJiXZgQwGmEoUIV+CWzGfA6sRiAKnCN79gDAvIQLwGiEoUAVwlAAOGsCUeCcaEYAwLzM58Bo1B9AFcJQADgPAlHgHGhGAFXYswfWZz4HRqP+AKoQhgLAeRGIAmdMMwKoQjMCNmM+B0ai/gCqUH8AwHkSiAJnSDMCqEIzAgDqU38AVRz3fgUAnAWBKHBGNCOAKoShADAH9QdQgX4JUIVthZiLQBQ4Axb3QBXCUACYl/oDGI1+CVCFfgnzEYgCW2ZxD1RhcQ8A81J/AKPRLwGq0C9hTgJRYIss7oEq7NkDAPNSfwCj0S8BqhCGMi+BKLBFFvdABZoRQBX27IH1mc+B0ag/gCqEocxNIAqcIYt7YDSaEUAVmhGwPvM5MBr1B1CF+oP5CUSBM2JxD4xGMwKoQjMCNmM+B0ai/gCqsK0Q+0EgCpwBi3tgNJoRQBXCUACYg/oDqEC/hP0hEAW2zGQJjMbiHqhCGAoA81J/AKPRL2G/CESBLTJZAqOxuAeqEIYCwLzUH8Bo9EvYPwJRYItMlsBILO6BKuzZAwDzUn8Ao9EvYT8JRAGACVncA1V4vwKAeZnPgdGoP9hfAlEAYEIW90AFmhFAFRd2PQAoyHwOjEb9wX4TiAIAe8DiHhiNZgRQhT2OYTPmc2Ak6g8QiAIAk7O4B0ajGQFUIQwFgPrUH5AIRAGAqVncA6PRjACqEIYCwBzUH5AIRAGKsGcPrM/iHhiNMBSoQhgKAPNSf7CfBKIAw9OMgPVZ3AOjEYYCVag/AGBe6g/2l0AUYGiaEbAZi3tgJMJQoIrj3q8AgNrUH+w3gSjAsIShADAHYShQgQ9vAMC8zOcgEAUYkjAUAOalGQGMRhgKVHFh1wOAgsznkAhEAQYkDAWAeWlGAKMRhgJV6JfAZsznkAhEAQZjzx4AmJdwARiNMBSoQhgKwOkIRAGGoRkBAPMynwOjUX8AVQhDATg9gSjAEDQjgCrs2QPrM58Do1F/AFUIQwHYDoEowM5pRgBVaEbAZsznwEjUH0AV6g8AtkcgCrBTmhFAFZoRAFCf+gOo4rj3KwBYn0AUYGc0I4AqhKEAMAf1B1CBfglQhW2FKhGIAuyExT1QhTAUAOal/gBGo18CVKFfUo1AFODcWdwDVVjcA8C81B/AaPRLgCr0SyoSiAKcK4t7oAp79gDAvNQfwGj0S4AqhKFVCUQBzpXFPVCBZgRQhT17YH3mc2A06g+gCmFoZQJRgJ2yuAdGoxkBVKEZAesznwOjUX8AVag/qhOIAuyMxT0wGs0IoArNCNiM+RwYifoDqMK2QjMQiALshMU9MBrNCKAKYSgAzEH9AVSgXzILgSjAuTNZAqOxuAeqEIYCwLzUH8Bo9EtmIhAFOFcmS2A0FvdAFcJQAJiX+gMYjX7JbASiAOfKZAmMxOIeqMKePQAwL/UHMBr9khkJRAEA9pbFPVCBZgQAzMt8DoxG/TErgSgAAIcs7oHRaEYAVVzY9QCgIPM5MBr1x8wEogAAxOIeGI9mBFCFPY5hM+ZzYCTqj9kJRAEA9p7FPTAazQigCmEoANSn/tgHAlEAgL1mcQ+MRjMCqEIYCgBzUH/sA4EoAJOwZw+sz+IeGI0wFKhCGAoA81J/zEggCsAENCNgMxb3wEiEoUAV6g8AmJf6Y1YCUQCK04wAgPqEoUAVx71fAQC1qT9mJhAFoDBhKADMQRgKVODDG0AVthWC9ZnPZycQBaAoYSgAzEszAhiNMBSoQr8E1mc+3wcCUQAKsrgHgHlpRgCjEYYCVeiXwGbM5/tAIApAMfbsAYB5CReA0QhDgSqEoQDHEYgCUIhmBADMy3wOjEb9AVQhDAU4iUAUgCI0I4AqLux6AFCQ+RwYjfoDqEIYCrAKgSgABWhGAFVoRsBmzOfASNQfQBW2FQJYlUAUgMFpRgBVCEMBYA7qD6AC/RKAdQhEARiYxT1QhTAUAOal/gBGo18CsC6BKACDsrgHqhCGAsC81B/AaPRLADYhEAVgQBb3QBXCUACYl/oDGI1+CcCmBKIADMbiHqjiuPcrAKA29QcwGv0SgNMQiAIwGIt7oALNCKCKC7seABRkPgdGo/4AOC2BKACDs7gHRqMZAVThtt6wGfM5MBL1B8A2CEQBGJjFPTAazQigCmEoANSn/gDYFoEoAIOyuAdGoxkBVCEMBYA5qD8AtkUgCmfOnj2wPot7YDTCUKAKYSgAzEv9AbApgSicKc0IWJ/FPTAaYShQhfoDAOal/gA4DYEonBnNCNiMxT0wEmEoUMVx71cAQG3qD4DTEojCmRCGAsAchKFABT68AQDzMp8DbINAFLZOGAoA89KMAEYjDAWquLDrAUBB5nOAbRGIwlYJQwFgXpoRwGiEoUAV+iWwGfM5wLYIRGFr7NkDAPMSLgCjEYYCVQhDAYDdE4jCVmhGAMC8zOfAaNQfQBXCUABgDAJRODXNCKAKe/bA+sznwGjUH0AVwlAAYBwCUTgVzQigCs0I2Iz5HBiJ+gOoQv0BAIxFIAob04wAqtCMAID61B9AFce9XwEA7IZAFDaiGQFUIQwFgDmoP4AK9EuAKmwrBPtGIAprs7gHqhCGAsC81B/AaPRLgCr0S2AfCURhLRb3QBUW9wAwL/UHMBr9EqAK/RLYVwJRWJnFPVCFPXsAYF7qD2A0+iVAFcJQ2GcCUViZxT1QgWYEAMzLfA6MRv0BVCEMhX0nEIWNWdwDo9GMAKq4sOsBQEHmc2A06g+gCmEoIBCFDVncA6PRjACq0IyAzZjPgZGoP4AqbCsEHLhq1wOorLXWknxEkoclue7w9J8n+d0kv9177zsaGmfK4h4YjWYEUIUwFADmoP4AKtAvAd5j2EC0tXZ9kocnecTh/35Ukrscecgre+837GBoaa3dPsk/S/KVSa6/wsNe3Vr7riT/ofd+6zkNjTNnsgRGY3EPVCEMBYB5qT+A0eiXAJcaKhBtrT0qB+9Gj0hyrx0P57Jaa/dJ8swkH37CQ++dg3fXz26tPb73/pozHxxnzGQJjMbiHqhCGAoA81J/AKPRLwFua7Q9RD86yWdm3DD0uiTPyW3D0JuTvCjJHyS5ZfGzj0zynNba3c9+hJwtkyUwEot7oAphKADMS/0BjEa/BLi80QLR47x11wNI8vQkNx45viUHt829e+/9Q3vvD05y9yRflUuD0Q9M8p/OaYwATM/iHqjiuPcrAKA29QcwGv0S4MpGDUTfkuS5Sb4jyROT3JDkM3Y4nrTWPjnJ3zpy6tYkj+u9P7X3/lcXT/be39Z7//dJPuXwMRd9RmvtMeczWgDmZnEPVKAZAVRxYdcDgILM58Bo1B/A8UYLRH8qyYckeZ/e+2N670/qvf/n3vsrdz2wJP9mcfxtvfdfudKDe+/PS/KUxelv3vqoAMDiHhiOZgRQhdt6w2bM58BI1B/AyYYKRHvvL+u9v7j3/u5dj+Wo1tqHJXn4kVNvy8G3V0/y7YePveiRrbUHbXNsAOw7i3tgNJoRQBXCUACoT/0BrGaoQHRgj18c/3jv/S0nPenwMc9YnH7CtgYFwL6zuAdGoxkBVCEMBYA5qD+A1QhEV/Npi+NfWOO5z14cf/opxwITsmcPrM/iHhiNMBSoQhgKAPNSfwCXJxA9QWutJXnI4vQL1rjE8xfHDz28JpBEMwI2YXEPjEYYClSh/gCAeak/gCsTiJ7sfknufOT4bb33P1n1yb33Vyb5qyOnrklyny2NDYrTjIDNWNwDIxGGAlUc934FANSm/gCOJxA92QMXx6/a4BrL5yyvCXtIGAoAcxCGAhX48AYAzMt8Dpzsql0PoIDrFsev3uAar8mlIejymmtrrV2X5B5rPu3G074ubIcwFADmpRkBjEYYClRxId6XYF3mc2A1AtGTXbs4ftsG11g+Z3nNTXxZkidv4TpwzoShADAvzQhgNMJQoIqL71fem2A9/maA1bhl7smW4eUtG1zj5hOuCXvCnj0AMC/hAjAaYShQhQ+PA8BZE4ie7I6L43dscI23L47vtOFYoDDNCACYl/kcGI36A6hCGAoA58Etc0+2/Ebo1Rtc4w4nXHMTT0vyjDWfc2OSZ27htWFNmhFAFfbsgfWZz4HRqD+AKoShAHBeBKIne+viePmN0VUsvxG6vObaeu+vTfLadZ7TWjvty8IGNCOAKuzZA5vxNwOMRP0BVCEMBYDz5Ja5J1uGl9dscI3lc04diEINmhFAFZoRAFCf+gOo4rj3KwDgLAhET7b8Fua9N7jG9SdcEyakGQFUIQwFgDmoP4AK9EuAKi7segCwVQLRk/3h4vg+G1xj+ZyXbDgWKMLiHqhCGAoA81J/AKPRLwGq0C9hPgLRk70yyc1Hjq9prd1v1ScfPvbOR069LcmrtjQ2GJDFPVCFxT0AzEv9AYxGvwSoQr+EOQlET9B770l+b3H6kWtc4lGL4987vCZMyOIeqMKePQAwL/UHMBr9EqAKYSjzEoiu5qcXx5+0xnOXj/2pU44FBmZxD1SgGQFUYc8eWJ/5HBiN+gOoQhjK3ASiq3nW4viJrbVrT3pSa+0uSZ64OP3MrY0KhmdxD4xGMwKoQjMC1mc+B0aj/gCqUH8wP4HoCnrvv5fkN4+cujbJk1Z46pOSXHPk+L/33l+8zbHBuCzugdFoRgBVaEbAZsznwEjUH0AVthViP+xlINpa64t/j17haf/H4vjrWmsfd8xrfHySr12c/lfrjRSqsrgHRqMZAVQhDAWAOag/gAr0S9gfV+16AEuttUcludNlfvTQxfEdW2uPvcJlbtr2NzF77z/fWvuFJJ98eOr2Sf5ba+3rknxv7/2vkqS1dk2SL07yrYePuehne++/tM0xwZhMlsBoLO6BKoShADAv9QcwGv0S9stwgWiSH05yvxUe935Jnn2Fn/1Aks/f1oCO+IdJfj3J/Q+P75jku5J8a2vt5Ulakg84PH/Uy85oPDAYkyUwGot7oAphKADMS/0BjEa/hP2zl7fM3VTv/c+TPCbJ7y5+dKckH5LkwbltGPrCJI/pvb/uzAcIO2eyBEZicQ9UYc8eAJiX+gMYjX4J+0kguqbe+yuTPDwH+4PedMxDb0rypCSP6L2/6jzGBgBcZHEPVOH9CgDmZT4HRqP+YH8Nd8vc3vsN5/Aa7ZTPf0eSb2+tfWeSj8zB/qbXHf74tTn4Vuhv997ffZrXAQA2ZXEPVKAZAVRxId6XYF3mc2A06g/223CBaCWHgedvHv4DAIZlcQ+MRjMCqOLi+5X3JliPvxlgJOoPcMtcAGByFvfAaDQjgCqu9H4FANSh/oBEIAoATM3iHhiNZgRQhTAUAOag/oBEIApQxIVdDwAKsrgHRiMMBaoQhgLAvNQf7CeBKMDwNCNgfRb3wGiEoUAV6g8AmJf6g/0lEAUYmmYEbMbiHhiJMBSo4rj3KwCgNvUH+00gCjAsYSgAzEEYClTgwxsAMC/zOQhEAYYkDAWAeWlGAKMRhgJVXNj1AKAg8zkkAlGAAQlDAWBemhHAaIShQBX6JbAZ8zkkAlGAwdizBwDmJVwARiMMBaoQhgJwOgJRgGFoRgDAvMznwGjUH0AVwlAATk8gCjAEzQigCnv2wPrM58Bo1B9AFcJQALZDIAqwc5oRQBWaEbAZ8zkwEvUHUIX6A4DtEYgC7JRmBFCFZgQA1Kf+AKo47v0KANYnEAXYGc0IoAphKADMQf0BVKBfAlRhW6FKBKIAO2FxD1QhDAWAeak/gNHolwBV6JdUIxAFOHcW90AVFvcAMC/1BzAa/RKgCv2SigSiAOfK4h6owp49ADAv9QcwGv0SoAphaFUCUYBzZXEPVKAZAVRhzx5Yn/kcGI36A6hCGFqZQBRgpyzugdFoRgBVaEbA+sznwGjUH0AV6o/qBKIAO2NxD4xGMwKoQjMCNmM+B0ai/gCqsK3QDASiADthcQ+MRjMCqEIYCgBzUH8AFeiXzEIgCnDuTJbAaCzugSqEoQAwL/UHMBr9kpkIRAHOlckSGI3FPVCFMBQA5qX+AEajXzIbgSjAuTJZAiOxuAeqsGcPAMxL/QGMRr9kRgJRAIC9ZXEPVKAZAQDzMp8Do1F/zEogCgDAIYt7YDSaEUAVF3Y9ACjIfA6MRv0xM4EoAACxuAfGoxkBVGGPY9iM+RwYifpjdgJRAIC9Z3EPjEYzAqhCGAoA9ak/9oFAFABgr1ncA6PRjACqEIYCwBzUH/tAIArAJOzZA+uzuAdGIwwFqhCGAsC81B8zEogCMAHNCNiMxT0wEmEoUIX6AwDmpf6YlUAUgOI0IwCgPmEoUMVx71cAQG3qj5kJRAEoTBgKAHMQhgIV+PAGUIVthWB95vPZCUQBKEoYCgDz0owARiMMBarQL4H1mc/3gUAUgIIs7gFgXpoRwGiEoUAV+iWwGfP5PhCIAlCMPXsAYF7CBWA0wlCgCmEowHEEogAUohkBAPMynwOjUX8AVQhDAU4iEAWgCM0IoIoLux4AFGQ+B0aj/gCqEIYCrEIgCkABmhFAFZoRsBnzOTAS9QdQhW2FAFYlEAVgcJoRQBXCUACYg/oDqEC/BGAdAlEABmZxD1QhDAWAeak/gNHolwCsSyAKwKAs7oEqhKEAMC/1BzAa/RKATQhEARiQxT1QhTAUAOal/gBGo18CsCmBKACDsbgHqjju/QoAqE39AYxGvwTgNASiAAzG4h6oQDMCqOLCrgcABZnPgdGoPwBOSyAKwOAs7oHRaEYAVbitN2zGfA6MRP0BsA0CUQAGZnEPjEYzAqhCGAoA9ak/ALZFIArAoCzugdFoRgBVCEMBYA7qD4BtEYjCmbNnD6zP4h4YjTAUqEIYCgDzUn8AbEogCmdKMwLWZ3EPjEYYClSh/gCAeak/AE5DIApnRjMCNmNxD4xEGApUcdz7FQBQm/oD4LQEonAmhKEAMAdhKFCBD28AwLzM5wDbIBCFrROGAsC8NCOA0QhDgSou7HoAUJD5HGBbBKKwVcJQAJiXZgQwGmEoUIV+CWzGfA6wLQJR2Bp79gDAvIQLwGiEoUAVwlAAYPcEorAVmhEAMC/zOTAa9QdQhTAUABiDQBROTTMCqMKePbA+8zkwGvUHUIUwFAAYh0AUTkUzAqhCMwI2Yz4HRqL+AKpQfwAAYxGIwsY0I4AqNCMAoD71B1DFce9XAAC7IRCFjWhGAFUIQwFgDuoPoAL9EqAK2wrBvhGIwtos7oEqhKEAMC/1BzAa/RKgCv0S2EcCUViLxT1QhcU9AMxL/QGMRr8EqEK/BPaVQBRWZnEPVGHPHgCYl/oDGI1+CVCFMBT2mUAUVmZxD1SgGQEA8zKfA6NRfwBVCENh3wlEYWMW98BoNCOAKi7segBQkPkcGI36A6hCGAoIRGFDFvfAaDQjgCo0I2Az5nNgJOoPoArbCgEHBKKwNot7YDSaEUAVwlAAmIP6A6hAvwR4D4EorMVkCYzG4h6oQhgKAPNSfwCj0S8BLiUQhZWZLIHRWNwDVQhDAWBe6g9gNPolwG0JRGFlJktgJBb3QBXCUACYl/oDGI1+CXB5AlEAKMfiHqjiuPcrAKA29QcwGv0S4MoEogBQjsU9UIFmBFDFhV0PAAoynwOjUX8AxxOIAkB5FvfAaDQjgCrc1hs2Yz4HRqL+AE4mEAWA0izugdFoRgBVCEMBoD71B7AagSgAlGVxD4xGMwKoQhgKAHNQfwCrEYgCA7BnD6zP4h4YjTAUqEIYCgDzUn8AlycQBXZMMwLWZ3EPjEYYClSh/gCAeak/gCsTiAI7pBkBm7G4B0YiDAWqOO79CgCoTf0BHE8gCuyIMBQA5iAMBSrw4Q0AmJf5HDiZQBTYAWEoAMxLMwIYjTAUqOLCrgcABZnPgdUIRIFzJgwFgHlpRgCjEYYCVeiXwGbM58BqBKLAObJnDwDMS7gAjEYYClQhDAWAsyYQBc6JZgQAzMt8DoxG/QFUIQwFgPMgEAXOgWYEUIU9e2B95nNgNOoPoAphKACcF4EocMY0I4AqNCNgM+ZzYCTqD6AK9QcAnCeBKHCGNCOAKjQjAKA+9QdQxXHvVwDAWRCIAmdEMwKoQhgKAHNQfwAV6JcAVdhWiLkIRIEzYHEPVCEMBYB5qT+A0eiXAFXolzAfgSiwZRb3QBUW9wAwL/UHMBr9EqAK/RLmJBAFtsjiHqjCnj0AMC/1BzAa/RKgCmEo8xKIAltkcQ9UoBkBVGHPHlif+RwYjfoDqEIYytwEosAZsrgHRqMZAVShGQHrM58Do1F/AFWoP5ifQBQ4Ixb3wGg0I4AqNCNgM+ZzYCTqD6AK2wqxHwSiwBmwuAdGoxkBVCEMBYA5qD+ACvRL2B8CUWDLTJbAaCzugSqEoQAwL/UHMBr9EvaLQBTYIpMlMBqLe6AKYSgAzEv9AYxGv4T9IxAFtshkCYzE4h6owp49ADAv9QcwGv0S9pNAFACYkMU9UIX3KwCYl/kcGI36g/0lEAUAJmRxD1SgGQFUcWHXA4CCzOfAaNQf7DeBKACwByzugdFoRgBV2OMYNmM+B0ai/gCBKAAwOYt7YDSaEUAVwlAAqE/9AYlAFACYmsU9MBrNCKAKYSgAzEH9AYlAFKAIe/bA+izugdEIQ4EqhKEAMC/1B/tJIAowPM0IWJ/FPTAaYShQhfoDAOal/mB/CUQBhqYZAZuxuAdGIgwFqjju/QoAqE39wX4TiAIMSxgKAHMQhgIV+PAGAMzLfA4CUYAhCUMBYF6aEcBohKFAFRd2PQAoyHwOiUAUYEDCUACYl2YEMBphKFCFfglsxnwOiUAUYDD27AGAeQkXgNEIQ4EqhKEAnI5AFGAYmhEAMC/zOTAa9QdQhTAUgNMTiAIMQTMCqMKePbA+8zkwGvUHUIUwFIDtEIgC7JxmBFCFZgRsxnwOjET9AVSh/gBgewSiADulGQFUoRkBAPWpP4Aqjnu/AoD1CUQBdkYzAqhCGAoAc1B/ABXolwBV2Faokqt2PYBVtNZuTPLwJPdOcnWSNyZ5SZIX9N5v2eXYADZjcQ9UIQwFgHmpP4DR6JcAVVx8v/LeVMXQgWhr7QlJ/nWSj7jCQ97aWnt6km/svb/+jMfy3CQff4pLfEHv/enbGQ1Qm8U9UIUwFADmpf4ARqNfAlShX1LRkLfMba3dobX2Q0l+IlcOQ5Pk2iRfnuTFrbWPO5fBAZyKxT1QhT17AGBe6g9gNPolQBXC0KqGC0Rba7dL8mNJPnfxo3cl+eMkL0zy5sXP7pHk51prf/PMBwhwKhb3QAWaEUAV9uyB9ZnPgdGoP4AqhKGVjXjL3K9J8vjFuf+Y5N/03m9K/jo0fXyS70py38PH3DnJj7fWPrT3vgxMz8Inrfn4F53JKIDiLO6B0WhGAFXYswfWZz4HRqP+AKoQhlY3VCDaWrtbkn+5OP31vfdvO3qi9/7uJD/RWvuNJL+W5IbDH907yVclefIZDzW9918869cAZmdxD4xGMwKoQjMCNmM+B0ai/gCqsK3QDEa7Ze6TktzlyPGvJHnKlR7ce39Nki9anP7nh8EqwMAs7oHRaEYAVQhDAWAO6g+gAv2SWQwTiB7eBvcLFqe/offej3te7/2XkvzqkVN3SfJZWx4ewBaZLIHRWNwDVQhDAWBe6g9gNPolMxkmEE3yyCT3OHL88iTPXfG537c4fsIWxgNwBkyWwGgs7oEqhKEAMC/1BzAa/ZLZjBSIftri+NknfTv06GMXx49urV2zhTEBbJnJEhiJxT1QhT17AGBe6g9gNPolMxopEH3Y4vgFqz6x935TklccOXV1kgeffkgAADOzuAcq0IwAgHmZz4HRqD9mNVIg+qDF8YvXfP7y8cvrbV1r7b1baw9prX1ca+0jWmv3a62911m/LgDA2bC4B0ajGQFUcWHXA4CCzOfAaNQfMxsiEG2t3SnJfRenX7XmZZaPf+DmIzpZa+13kvxFkt9N8rwkv5WDb6m+qbX28621L26t3eEsxwAAsD0W98BoNCOAKuxxDJsxnwMjUX/M7qpdD+DQ3ZO0I8e3Jnntmtd4zeL4ulON6GQPu8L5a5M87vDfN7XWvqL3/oxtv3hr7bok91jzaTduexwAwAws7oHRaEYAVQhDAaA+9cc+GCUQvXZx/Fe9977mNd52wjV34Z5Jfry19p2996/Z8rW/LMmTt3xNAGDvWNwDo9GMAKoQhgLAHNQf+2CIW+bmtuHlLRtc4+YTrrkNtyT5qRyEkY/MwbdQr05ylxx8+/LzkvxMkmWY+9Wtta87g/EA8Nfs2QPrs7gHRiMMBaoQhgLAvNQfMxrlG6J3XBy/Y4NrvH1xfKcNx3Il/y7J83vvb7jMz25N8tYkL0/yw621j0nyo0muP/KYb2mt/Vzv/Xe3PC4A/roZYaEC6/E3A4xEGApUIQwFgHmpP2Y1SiC6/Ebo1Rtc4w4nXPNUeu/PWuOxv9Zae3SSX8/B/qjJwR6p35zkM7Y0pKclWXdv0huTPHNLrw8wCM0IAKhPGApUcdz7FQBQm/pjZqMEom9dHC+/MbqK5TdCl9c8V733l7bWvibJ9x85/amttbv23v9iC9d/bZLXrvOc1tppXxZgMMJQAJiDMBSowIc3gCouxPsSrMt8PrtR9hBdhpd3buund9eccM1d+MEkrztyfLskj93RWAAmIwwFgHlpRgCjEYYCVeiXwPrM5/tglED09Un6kePbJ7luzWtcvzhe69uTZ6H3/u4kz12cfuAOhgIwGYt7AJiXZgQwGmEoUIV+CWzGfL4PhghEe+83J/mTxen7rnmZ5eNfsvmItupVi+N77GQUANOwZw8AzEu4AIxGGApUIQwFOM4QgeihZYD54DWf/6ATrrcrty6Ob7+TUQBMQTMCAOZlPgdGo/4AqhCGApxkpED0hYvjR676xNba+ye54cipW5O8+PRD2op7Lo5fd9lHAXACzQigigu7HgAUZD4HRqP+AKoQhgKsYqRA9KcXx49trbUVn/vJi+Pn9N7fuoUxbcPHLI6Xt9AF4ESaEUAVmhGwGfM5MBL1B1CFbYUAVjVSIPqCJK8/cvwBSR694nP/8eL4mdsY0Gm11j4+yY2L07+0i7EA1KUZAVQhDAWAOag/gAr0SwDWMUwg2nt/d5KnL04/+aRvibbWPjHJxx459ZYkP77d0a2vtXZNkv+wOP37vfeX72I8ADVZ3ANVCEMBYF7qD2A0+iUA6xomED30lCRHb3X78Um+9koPbq1dn+T/Xpx+au/99Zd7/JHn9cW/R5/w+Ke21u517MgvffzdkzwryUMWP3ryqtcAwOIeqEIYCgDzUn8Ao9EvAdjEUIHoYZD5LYvT39pae9rRQLK1drvW2hNycJvdG4489qYczAjb9hVJXt5a+4nW2ue21m643INaa/dprX1Nkt9P8gmLH/9k7/0nzmBsABOyuAeqEIYCwLzUH8Bo9EsANnXVrgdwGU9J8sgkn37k3Jcm+ZLW2iuTvDnJ/ZO8z+J5Nyf5rN77m85oXHdI8oTDf2mt/WWSPz0cz+2TvF+SK32L9FeTfM4ZjQtgMhb3QBXHvV8BALWpP4DR6JcAnMZQ3xBN/nov0Scm+dHFj94ryQck+fDcNgx9Q5JP7b0//8wH+B5/I8kDkzz8cEyXC0PfneTbk3xi7/3mcxwbQGEW90AFmhFAFWdxEyWYnfkcGI36A+C0hgtEk6T3fkvv/bOT/N0kLzzmoW9L8rQkD+69P/cMh/QlOQhoX7Xi4/8syVOTPLD3/rW991vPbGQA07O4B0ajGQFU4bbesBnzOTAS9QfANox4y9y/1nv/L0n+S2vtAUkekeT6JFcneVOSP0jy/N77LRtct635+O9N8r1J0lq7W5IHJblfknskuSbJu5K8Mcnrk/xO7/3l644JgMuxuAdGoxkBVCEMBYD61B8A2zJ0IHpR7/2lSV6663EkSe/9DUl+7fAfAGfG4h4YjWYEUIUwFADmoP4A2JYhb5kLc7FnD6zP4h4YjTAUqEIYCgDzUn8AbEogCmdKMwLWZ3EPjEYYClSh/gCAeak/AE5DIApnRjMCNmNxD4xEGApUcdz7FQBQm/oD4LQEonAmhKEAMAdhKFCBD28AwLzM5wDbIBCFrROGAsC8NCOA0QhDgSou7HoAUJD5HGBbBKKwVcJQAJiXZgQwGmEoUIV+CWzGfA6wLQJR2Bp79gDAvIQLwGiEoUAVwlAAYPcEorAVmhEAMC/zOTAa9QdQhTAUABiDQBROTTMCqMKePbA+8zkwGvUHUIUwFAAYh0AUTkUzAqhCMwI2Yz4HRqL+AKpQfwAAYxGIwsY0I4AqNCMAoD71B1DFce9XAAC7IRCFjWhGAFUIQwFgDuoPoAL9EqAK2wrBvhGIwtos7oEqhKEAMC/1BzAa/RKgCv0S2EcCUViLxT1QhcU9AMxL/QGMRr8EqEK/BPaVQBRWZnEPVGHPHgCYl/oDGI1+CVCFMBT2mUAUVmZxD1SgGQEA8zKfA6NRfwBVCENh3wlEYWMW98BoNCOAKi7segBQkPkcGI36A6hCGAoIRGFDFvfAaDQjgCo0I2Az5nNgJOoPoArbCgEHBKKwNot7YDSaEUAVwlAAmIP6A6hAvwR4D4EorMVkCYzG4h6oQhgKAPNSfwCj0S8BLiUQhZWZLIHRWNwDVQhDAWBe6g9gNPolwG0JRGFlJktgJBb3QBXCUACYl/oDGI1+CXB5AlEAKMfiHqjiuPcrAKA29QcwGv0S4MoEogBQjsU9UIFmBFDFhV0PAAoynwOjUX8AxxOIAkB5FvfAaDQjgCrc1hs2Yz4HRqL+AE4mEAWA0izugdFoRgBVCEMBoD71B7AagSgAlGVxD4xGMwKoQhgKAHNQfwCrEYgCA7BnD6zP4h4YjTAUqEIYCgDzUn8AlycQBXZMMwLWZ3EPjEYYClSh/gCAeak/gCsTiAI7pBkBm7G4B0YiDAWqOO79CgCoTf0BHE8gCuyIMBQA5iAMBSrw4Q0AmJf5HDiZQBTYAWEoAMxLMwIYjTAUqOLCrgcABZnPgdUIRIFzJgwFgHlpRgCjEYYCVeiXwGbM58BqBKLAObJnDwDMS7gAjEYYClQhDAWAsyYQBc6JZgQAzMt8DoxG/QFUIQwFgPMgEAXOgWYEUIU9e2B95nNgNOoPoAphKACcF4EocMY0I4AqNCNgM+ZzYCTqD6AK9QcAnCeBKHCGNCOAKjQjAKA+9QdQxXHvVwDAWRCIAmdEMwKoQhgKAHNQfwAV6JcAVdhWiLkIRIEzYHEPVCEMBYB5qT+A0eiXAFXolzAfgSiwZRb3QBUW9wAwL/UHMBr9EqAK/RLmJBAFtsjiHqjCnj0AMC/1BzAa/RKgCmEo8xKIAltkcQ9UoBkBVGHPHlif+RwYjfoDqEIYytwEosAZsrgHRqMZAVShGQHrM58Do1F/AFWoP5ifQBQ4Ixb3wGg0I4AqNCNgM+ZzYCTqD6AK2wqxHwSiwBmwuAdGoxkBVCEMBYA5qD+ACvRL2B8CUWDLTJbAaCzugSqEoQAwL/UHMBr9EvaLQBTYIpMlMBqLe6AKYSgAzEv9AYxGv4T9IxAFtshkCYzE4h6owp49ADAv9QcwGv0S9pNAFACYkMU9UIX3KwCYl/kcGI36g/0lEAUAJmRxD1SgGQFUcWHXA4CCzOfAaNQf7DeBKACwByzugdFoRgBV2OMYNmM+B0ai/gCBKAAwOYt7YDSaEUAVwlAAqE/9AYlAFACYmsU9MBrNCKAKYSgAzEH9AYlAFKAIe/bA+izugdEIQ4EqhKEAMC/1B/tJIAowPM0IWJ/FPTAaYShQhfoDAOal/mB/CUQBhqYZAZuxuAdGIgwFqjju/QoAqE39wX4TiAIMSxgKAHMQhgIV+PAGAMzLfA4CUYAhCUMBYF6aEcBohKFAFRd2PQAoyHwOiUAUYEDCUACYl2YEMBphKFCFfglsxnwOiUAUYDD27AGAeQkXgNEIQ4EqhKEAnI5AFGAYmhEAMC/zOTAa9QdQhTAUgNMTiAIMQTMCqMKePbA+8zkwGvUHUIUwFIDtEIgC7JxmBFCFZgRsxnwOjET9AVSh/gBgewSiADulGQFUoRkBAPWpP4Aqjnu/AoD1CUQBdkYzAqhCGAoAc1B/ABXolwBV2FaoEoEowE5Y3ANVCEMBYF7qD2A0+iVAFfol1QhEAc6dxT1QhcU9AMxL/QGMRr8EqEK/pCKBKMC5srgHqrBnDwDMS/0BjEa/BKhCGFqVQBTgXFncAxVoRgBV2LMH1mc+B0aj/gCqEIZWJhAF2CmLe2A0mhFAFZoRsD7zOTAa9QdQhfqjOoEowM5Y3AOj0YwAqtCMgM2Yz4GRqD+AKmwrNAOBKMBOWNwDo9GMAKoQhgLAHNQfQAX6JbMQiAKcO5MlMBqLe6AKYSgAzEv9AYxGv2QmAlGAc2WyBEZjcQ9UIQwFgHmpP4DR6JfMRiAKcK5MlsBILO6BKuzZAwDzUn8Ao9EvmZFAFABgb1ncAxVoRgDAvMznwGjUH7MSiAIAcMjiHhiNZgRQxYVdDwAKMp8Do1F/zEwgCgBALO6B8WhGAFXY4xg2Yz4HRqL+mJ1AFABg71ncA6PRjACqEIYCQH3qj30gEAUA2GsW98BoNCOAKoShADAH9cc+EIgCMAl79sD6LO6B0QhDgSqEoQAwL/XHjASiAExAMwI2Y3EPjEQYClSh/gCAeak/ZiUQBaA4zQgAqE8YClRx3PsVAFCb+mNmAlEAChOGAsAchKFABT68AVRhWyFYn/l8dgJRAIoShgLAvDQjgNEIQ4Eq9EtgfebzfSAQBaAgi3sAmJdmBDAaYShQhX4JbMZ8vg8EogAUY88eAJiXcAEYjTAUqEIYCnAcgSgAhWhGAMC8zOfAaNQfQBXCUICTCEQBKEIzAqjiwq4HAAWZz4HRqD+AKoShAKsQiAJQgGYEUIVmBGzGfA6MRP0BVGFbIYBVCUQBGJxmBFCFMBQA5qD+ACrQLwFYh0AUgIFZ3ANVCEMBYF7qD2A0+iUA6xKIAjAoi3ugCmEoAMxL/QGMRr8EYBMCUQAGZHEPVCEMBYB5qT+A0eiXAGxKIArAYCzugSqOe78CAGpTfwCj0S8BOA2BKACDsbgHKtCMAKq4sOsBQEHmc2A06g+A0xKIAjA4i3tgNJoRQBVu6w2bMZ8DI1F/AGyDQBSAgVncA6PRjACqEIYCQH3qD4BtEYgCMCiLe2A0mhFAFcJQAJiD+gNgWwSicObs2QPrs7gHRiMMBaoQhgLAvNQfAJsSiMKZ0oyA9VncA6MRhgJVqD8AYF7qD4DTEIjCmdGMgM1Y3AMjEYYCVRz3fgUA1Kb+ADgtgSicCWEoAMxBGApU4MMbADAv8znANghEYeuEoQAwL80IYDTCUKCKC7seABRkPgfYFoEobJUwFADmpRkBjEYYClShXwKbMZ8DbItAFLbGnj0AMC/hAjAaYShQhTAUANg9gShshWYEAMzLfA6MRv0BVCEMBQDGIBCFU9OMAKqwZw+sz3wOjEb9AVQhDAUAxiEQhVPRjACq0IyAzZjPgZGoP4Aq1B8AwFgEorAxzQigCs0IAKhP/QFUcdz7FQDAbghEYSOaEUAVwlAAmIP6A6hAvwSowrZCsG8EorA2i3ugCmEoAMxL/QGMRr8EqEK/BPaRQBTWYnEPVGFxDwDzUn8Ao9EvAarQL4F9JRCFlVncA1XYswcA5qX+AEajXwJUIQyFfXbVrgewitbajUkenuTeSa5O8sYkL0nygt77LTscV0vyEUkeluS6w9N/nuR3k/x2773vaGicCYt7oALNCACYl/kcGI36A6hCGAr7buhAtLX2hCT/Ogeh4+W8tbX29CTf2Ht//TmO6/ZJ/lmSr0xy/RUe9urW2ncl+Q+991vPaWicK4t7YDSaEUAVF+J9CdZlPgdGo/4AqhCGAoPeMre1dofW2g8l+YlcOQxNkmuTfHmSF7fWPu6cxnafJP8jyXfkymFocvBt1u9M8uutteMeR0kW98BoNCOAKjQjYDPmc2Ak6g+gCtsKAQeGC0Rba7dL8mNJPnfxo3cl+eMkL0zy5sXP7pHk51prf/OMx3Zdkuck+fDFj25O8qIkf5BkeQvfj0zynNba3c9ybJwni3tgNJoRQBXCUACYg/oDqEC/BHiP4QLRJF+T5PGLc/8xyX177x/Qe//wJHdN8neS/MmRx9w5yY+31t77DMf29CQ3Hjm+JQe3zb177/1De+8PTnL3JF+VS4PRD0zyn85wXJwbkyUwGot7oAphKADMS/0BjEa/BLjUUIFoa+1uSf7l4vTX996/tPd+08UTvfd3995/Iskjk7ziyGPvnYMw8izG9slJ/taRU7cmeVzv/am99786Mra39d7/fZJPOXzMRZ/RWnvMWYyN82KyBEZjcQ9UIQwFgHmpP4DR6JcAtzVUIJrkSUnucuT4V5I85UoP7r2/JskXLU7/88Ngddv+zeL423rvv3KlB/fen5fbjv2btz4qzpHJEhiJxT1QhTAUAOal/gBGo18CXN4wgejh3qFfsDj9Db33ftzzeu+/lORXj5y6S5LP2vLYPizJw4+celuS71jhqd9++NiLHtlae9A2xwbAPrK4B6o47v0KAKhN/QGMRr8EuLJhAtEc3P72HkeOX57kuSs+9/sWx0/YwniOWu5p+uO997ec9KTDxzxjcfoJ2xoUAPvK4h6oQDMCqOLCrgcABZnPgdGoP4DjjRSIftri+NknfTv06GMXx49urV2zhTFdtBzbL6zx3OXYPv2UYwGABYt7YDSaEUAVbusNmzGfAyNRfwAnGykQfdji+AWrPrH3flOSVxw5dXWSB59+SElrrSV5yOL0ymNL8vzF8UMPrwkAW2BxD4xGMwKoQhgKAPWpP4DVjBSILvfWfPGaz18+flt7dd4vyZ2PHL+t9/4nqz659/7KJH915NQ1Se6zpbEBsNcs7oHRaEYAVQhDAWAO6g9gNUMEoq21OyW57+L0q9a8zPLxD9x8RMdeZ91xXe452xobTMKePbA+i3tgNMJQoAphKADMS/0BXN5Vux7AobsnOXob2VuTvHbNa7xmcXzdqUZ05eu8eoNrvCaXhqCnHltr7bok91jzaR989OClL33paYfBil70ol2PYGRPT/KdedGLPmXXAxme/x+dbH9+R1+d5FOSrP8fvD+/o835HZ3M7+hk+/c7enoOGg9LV36/2r/f0Wb8nk7md3Qyv6Ojnp7LvV+9yC/pRH5FJ/M7Opnf0cn8jk7md7Sa/fw9rdcv2c/f0Xr8jk7md7S6y2RSV5/n67fe+3m+3uUH0dqDcuktb9/ce3+fNa/xVbn0a2Y/2nv/7C2M7UuTPO3IqWf23p+w5jWeleQzjpz6p7337znluL4hyZNPcw0AAAAAAADYgcf33p91Xi82xC1zk1y7OL5lg2vcfMI1NzXy2AAAAAAAAIBjjBKI3nFx/I4NrvH2xfGdNhzL0shjAwAAAAAAAI4xyh6iy29dbnLf4DuccM1NjTq2pyV5xprPuTbJRyX5yyRvTvKqbBbw8h43JnnmkePHJ3nZjsYCnI6/Z5iHv2eYg79lmIe/Z5iHv2eYg79lduHqJPc5cvy883zxUQLRty6Ol9/KXMXyW5fLa25qyLH13l+b5LUbPPV/nPa1eY/W2vLUy3rvtlGGgvw9wzz8PcMc/C3DPPw9wzz8PcMc/C2zQ7+zqxce5Za5y4Dwzu0yf5EnuOaEa25qeZ3l66zirMYGAAAAAAAAHGOUQPT1SfqR49snuW7Na1y/ON7k25OXs7zOvTe4xlmNDQAAAAAAADjGEIFo7/3mJH+yOH3fNS+zfPxLNh/RJf5wcXyfyz7qeMvnbGtsAAAAAAAAwDGGCEQPLUPCB6/5/AedcL1NvTLJzUeOr2mt3W/VJx8+9s5HTr0tyau2NDYAAAAAAADgGCMFoi9cHD9y1Se21t4/yQ1HTt2a5MWnH1LSe+9Jfm9xeuWxJXnU4vj3Dq8JAAAAAAAAnLGRAtGfXhw/trXWVnzuJy+On9N7f+sWxnTRcmyftMZzl4/9qVOOBQAAAAAAAFjRSIHoC5K8/sjxByR59IrP/ceL42duY0BHPGtx/MTW2rUnPam1dpckT1yc3vbYAAAAAAAAgCsYJhDtvb87ydMXp5980rdEW2ufmORjj5x6S5If3/LYfi/Jbx45dW2SJ63w1CcluebI8X/vvW/lVr4AAAAAAADAyYYJRA89JcnRW91+fJKvvdKDW2vXJ/m/F6ef2nt//eUef+R5ffHv0SuM7f9YHH9da+3jjnmNy439X63wOgAAAAAAAMCWDBWIHgaZ37I4/a2ttae11u518URr7XattSfk4Da7Nxx57E1JLpzR2H4+yS8cOXX7JP+ttfbPWmt3PjK2a1prX5nk5w8fc9HP9t5/6SzGBgAAAAAAAFzeUIHooack+enFuS9N8iettZe11n47yRuS/ESS+x55zM1JPqv3/qYzHNs/TPLHR47vmOS7kry+tfb/a629KAf7oP77w59d9LIkn3+G4wIAAAAAAAAu46pdD2Cp9/7u1toTk3x/kr9/5EfvleQDrvC0NyT5u73355/x2P68tfaYJM9M8tAjP7pTkg+5wtNemORv995fd5ZjY2del+QbF8dATf6eYR7+nmEO/pZhHv6eYR7+nmEO/pbZO633vusxXFFr7X/Nwb6bD7vCQ96W5AeSfGPv/bVrXHf5H/2Y3vtz13j+1Um+Msk/S3KvKzzsphx8e/Spvfd3rHptAAAAAAAAYHuGDkQvaq09IMkjklyf5Ookb0ryB0me33u/ZYfjul2Sj8zBt0WvOzz92hx8K/S3e+/v3tHQAAAAAAAAgBQJRAEAAAAAAAA2cbtdDwAAAAAAAADgrAhEAQAAAAAAgGkJRAEAAAAAAIBpCUQBAAAAAACAaQlEAQAAAAAAgGkJRAEAAAAAAIBpCUQBAAAAAACAaQlEAQAAAAAAgGkJRAEAAAAAAIBpCUQBAAAAAACAaQlEAQAAAAAAgGldtesBQGWttRuTPDzJvZNcneSNSV6S5AW991t2OTYA4GSttTsmeWSSD07yvknekeTVSf5H7/3luxwbAIygtdaS3JDkw3JQ+75PkrfnoP79oyS/ue36t7V2lySPSvJBSf5GkpuTvDIHtfZN23wt2Be7+FsGzkZr7eoc1LA3JLk+yV2S3D7JXyZ5Q5LfS/IHvfd3ben1rkryiCQfmuRuSd6V5E+T/Fbv/UXbeA04D633vusxQDmttSck+ddJPuIKD3lrkqcn+cbe++vPaVgAUF5r7focfNjoEYf/+1E5KO4uemXv/YYtvM49kjw5yecnueYKD/utJP+m9/7M074eAFTSWnvfJE9I8ilJPiHJ3Y95+K1JfibJd/Xen3fK171/km9K8lk5+NDxUk/yvCRP7r3/ymleC/bBef0tt9ZuSPLHm43yQO+9neb5MLvW2t9N8tgcfGDog3Pyl93enOT/m+SpvfeXbPia1yb5uiRfmuSuV3jYHyZ5SpKnd2ETgxOIwhpaa3dI8n1JPnfFp7wuyd9VqMEYWmvfkIMAZFM/0Hv//O2MBriotfaoJP97DkLQe53w8FMHoq21Ryd5Ro5vCB31g0m+uPf+jtO8LuyTs/xwQ2vttEXs/XvvrzjlNWBarbXvTvJFuXwgeZIfTPL/6b3/5Qav+1lJvj/JnVd4eE/y7Um+XvMVLu88/5YFonD2WmuvzsG3Qdd1a5JvycEXd1aeM1trH5bkmUnuv+JT/luSv9d7f/P6Q4Tz4Za5sKLW2u2S/FiSxy9+9K4kf5KDT93cP8l7H/nZPZL8XGvtsb33Xz+XgQJAPR+d5DPP44Vaax+T5GeT3GnxozfloInzvknuk+S9jvzsHya5trX2dzVd4crW/HADMK5H5PIBysXb4/15Dm7Ld79cWv8mB3PmB7fWPrH3/tZVX7C19sQcfIvldosfvS7Jq5Jcl4Mm8MXApCX52iR3SPLPV30d2DPn/rcMnLtb8p6+9O1y8KHf++Y982Vy8Hf+5BzUuf94lYu21h6Y5Jdz2w8RvzXJy3NQT99weO2LHpeDPvgnuP02o1ouNIEr+5rcNgz9j0nu23v/gN77h+fg1gF/JwcT0UV3TvLjrbXl4hIAONnWGjCHtwz7sVwahr4yB7cRu2vv/SN67/fPQWH3PYun/51ouMJJLn64QRgK83hTkqcl+bQk79t7v0/v/aN67w/NwR5ij0nyq4vnPDwHW8ispLV2Yw6+GXq0R/W7ST6h935d7/0je+/3SfKgJP918fSvbK39nTX+e2BfvSln/Le88AtJPmnNf8DJbkryvUn+QZIHJLmm9/7A3vvDD/+mb8jB3/SXJHn14rlf2Fr7gpNe4HC/0OUdlf4iyT/KQd380N77ByW5Z5J/m+TdRx73N3NwBwcYklvmwgpaa3fLwbdGjt7m6+t77992hcdfn+TXctBQveibeu+nuVUncEqXuWXuV+eg2bKqm3rvL97qoIC01r4yyb9P8pYc7Nv5m0l+4/B/75/kOUcefprbbH5Lkq8/cuqPk3xM7/2mKzz+X+SgwLvozTm41eYbN3l9mN2Rv+XLeWuSa48cb+uWub+Xg2+lruPXfGodrqy19j9z0Ez95iQ/0nu/+YTHv1cOgpYvWfzoE3rvz7nMU5bP/5Ekn33k1G8meezlbtXZWms5+GDy0dd6WZIP7r2/86TXgn1ynn/Ll7llru1mYMtaaw9J8vur3rXo8APBv5jkI46c/tMk9+69v/vyz0paa1+SSz8g/MYc1M2X7Ye11j4nyQ8fOfXOJA/uvf/RKuOE8yQQhRW01p6S5ElHTv1KkkcfNwG11j4xB5PORW/JQRP1DWczSuAklwlEH9N7f+5uRgNcdPjNkDskecmyMDvc7/PUgWhr7R45uLXP0UDmsb33XzrmOS3Jc5N83JHT39J7/5frvj7sg3P8cMPRNfjzeu+P3uQ6wOW11j4tybPX2Tv7MEj57znYL/iiH+m9f+4Jz/uQHHyw4eK3Q9+R5GG99z845jl3PHzOBx45/SW99+9ddbywD875b/mGCERhOK21ByV5US69he7H9d6X3wi/+Pirk7w0B7fXvegf997/0wmv8/8k+bwjp05834BdcMtcOMHh3qHL2wl8w0mfxjlssB6dXO6S5LO2PDwAKK/3/rLe+4uP+5TqFvz9XBqG/spxYejhuHqSb1yc/sLDoBS4rZ9K8iFJ3qf3/pje+5N67/+59/7KXQ8MWF3v/WfWCVAOn/Ou3PYWeY9b4alfmEt7Uz96XBh6+Fq3JFneremLVngt2Cvn/LcMDOhwTv2txekHHfOUx+XSMPQVObit/Um+IcnRXvkTbR/HiASicLJHJrnHkeOX5+DbIqv4vsXxE7YwHgBgfct9wJdz9JU8J5d+2v2eSf6XrYwIJnNOH24AxrX8tsndWmt3PuE5f3txvOr8/GNJ3nbk+KNba/Yvhu3Y5G8ZGNfLFsd3v+yjDizr5u9f5Ra9vfeXJXnekVO3T/Kpqw0Pzo9AFE72aYvjZ696r/Ykz14cP7q1ds0WxgQArKi1dm0uve1tkvzCKs89nPN/cXH607cxLgCYzOX22L7it0Naaw9M8oAjp96W5AWrvFDvffnYltvW7sBm1vpbBoZ3x8Xxm4557HIuXaluPrTsg6ubGY5AFE72sMXxSgVakvTeb8rBrQUuujrJg08/JABgDR+Sg0+oXvTHvfc/W+P5z18cP+zUIwKA+Vx/mXNvOObxD1sc/0bv/Z1rvJ75Gc7Gun/LwKAOt3v56MXp5S10Lz72/XJwR6SL3p7kt9d4OfMyw7tq1wOAApb3VX/xms9/cZIbFtf7zdMMCABYyzbm8uOuBwAkH7s4fuUJ+xean2FM6/4tX1Fr7T45CFjumOQvkry29/66U44PWN0XJjl6S/mXJPmNKzx2OY++dM2//eW8/IDW2lVrftgJzpRAFI7RWrtTkvsuTr9qzcssH//AzUcEbFtr7Q5JPiDJ3ZLcmoNPvt7Ue/+rnQ4M2Kbl3Hvaufx+rbU79t5vOcWYgC1qrb1/Dpo91+TgVn+v773/6W5HBXvnCxfHP3vC47c9P6u1YTvW/Vu+nE9urd2U5P2XP2itvSLJc5P8X733X9/g2sAKWmv/KMnTjpx6d5IvP2YruFPNy73317XWbsl7btF7dZL7J/mjda4DZ0kgCse7ew72Irno1iSvXfMar1kcX3eqEQHb9N05CEOX+ym8s7X2W0l+LsnTfIIVylvOva9e8/l/nuSdec/a+XY5+BDFco4Hzt+HtdZenoNmyyVaa3+W5HlJnt57//lzHxnskdbap+a2+3U//YSnnXZ+Xs7D91jz+cDChn/Ll3ObIPSIG5J8fpLPb639cpIv6L3/yQavAXuttfZBufSLPLdP8r5JPjTJ43Pptm3vSPIlvfdfOuaSp52Xk+SmHPTZjl5TIMowBKJwvGsXx391zKdoruRtJ1wT2J0r7el7VZJHHP772tbadyb5xt77u85tZMA2Lefe5dx8rN57b63dnOQux1wT2I27Hv67nHsm+XtJ/l5r7XeS/KPe+++f28hgT7TW7prkexanf7L3fqVb8l10qvn5Mo+/fWvtDr33t695HSCn+ls+jU9I8juttc/svf/KGb4OzOjLkvyzEx7Tk/x8kq/vvf/uCY897bx8ueeomxnK7XY9ABjc8k17k1vj3XzCNYGx3SnJv07yi601f79Qk/kc+PAk/6O19sRdDwRm0lq7XZIfSnLvI6ffnOQrVnj6aefn5dx8uWsCKzjl3/JRr07yfyZ5Yg72I3yfHHxr7e5JPjrJk5K8fPGcuyZ5Zmvtg9ceOHCSZyT5tyuEoYm6mT0gEIXjLW+juckm8stPp95pw7EA29GTvCDJv0zySTko+O6cg7/365N8Rg4+Fbtc+D06yY+21t7r3EYKbIv5HObz+hzcwu/zkjwkB83Ui7cJe2iSL0+ybPzcKckPtdaWtwIENvcdSf7W4tw/6b2vsu/Yaefny30T1PwMmznN33JyEJ7+7ST3671/We/9P/feX9J7f3Pv/Z299zf03v9n7/07knxQkm/MwX6GF71PDubodttLA6fwWUl+rbX2K621B5zwWHUz0xOIwvGWgcjVG1zjDidcEzg/v5Dkg3vvj+q9f0vv/Rd776/pvd/ce3977/2m3vtP997/aZIPTPL8xfM/LQe3JAFqMZ/DXD4vyfW99y/ovf9w7/33e+9vPGy4vqn3/nu99+/uvT8syT/NpY2Zq5P8SGtt2fAB1tRa+4okX7U4/e299x9b8RKnnZ+Xc/PlrgmcYAt/yzmch3+q9/7uFR77rt77N1zmNT8yyd9Z9TVh3/Xev7L33i7+y8GH/e+T5NOTfF8u/bbmxyb5zdbaRx1zSXUz0xOIwvHeujjepHGy/CTM8prAOem9v6D3/v+u+NhXJ3lskl9f/OhftdbuvPXBAWfJfA4TOQxBV/rEeu/9e5J8Ti79Fsr1Sf63sxgb7IvW2uck+a7F6acn+bo1LnPa+fly3zoxP8MatvS3vJHe+1OTPG9x+h+c9evCrA4/7P/q3vvP9N6/KAd3UXnhkYe8T5KfbK29zxUuoW5megJRON7yTfvOG9y+45oTrgkMqvd+S5J/mOSdR05fl+STdzMiYEPLuXc5Nx/rcO5X2EFRvff/muT/WZzWcIUNtdY+PckPJDlaG//XJF/Ue+9rXOpU8/NlHv/Ow/U7sIIt/i2fxoXF8Se01q46p9eGqfXeX5qDraKO3vr6+iRfc4WnnHZevtxz1M0MRSAKx3t9DvYbvOj2OQhD1nH94vi1pxoRcK4OF5DPWpwWiEIty7n33ms+//2SHG3MvDsHawSgjmXD9SGttffbyUigsNbaY5I8I5fOi89O8tm993etebnTzs/LWvt1az4f9taW/5ZP45dzad/tLkne/xxfH6bWe399kicvTn/+FR5+2nk5Se51wjVhpwSicIze+81J/mRx+r5rXmb5+JdsPiJgR35pcfzAnYwC2NQfLo5PO5e/0jdQoJbe++/n0oZMS/JBOxoOlNRae0QOPih49BZ6L0jymavexnph2/OzWhtWcAZ/yxvrvb8tyRsXp+9xnmOAPfATufSDB/dqrd3vMo871bzcWrsul76vvCPJy9e5Bpw1gSicbFlUPXjN5z/ohOsB43vV4liBBrWYy4EkefXi2HwOK2qtPSTJzyW59sjp30nyqYeBxibMz3DOzuhv+bRuXRzffiejgEn13t+U5C8Wp+95mYcu59EbW2tXr/FSy3n5Zb33d172kbAjAlE42QsXx49c9YmttfdPcsORU7cmefHphwScMwUa1PaiXPp3fMPhHL2qRy2OX3jqEQG7YD6HDbTWHpiDW2m+75HTf5Dkcb33N5/i0i9cHH/0mnsHmp9hDWf4t3yaMV2V5G6L025/DWdvuS5O7/3PkvzZkVN3SPKRa1zTvMzwBKJwsp9eHD+2tdYu+8jbWu4z+Jzeu82koZ7lJ+cUaFBI7/0tSX5lcfqTVnnu4Zz/2MXpn9rGuIBzZz6HNR3eUu8Xk1x35PQfJ/mk3vup/oZ67y9J8rIjp67Jih9Abq1dk+RvHr1cblu7A4fO8m/5lP6XXLqP6TtzaSADnFJr7S5J7ro4/edXePjPLI5Xqpuv8Fh1M8MRiMLJXpDk9UeOPyDJo1d87j9eHD9zGwMCzt3HLI6Xt9AFxves/3979x77bTnHAfx9SeUx8nhyGCXRAWEOk8whp2kjs6HIaYo5jM05ZCY2hyEjtWSL9IeEUY05jNKaWKGDkC1nKlE6kFLq44/r+2zf3/38jo/f6bmf12v7rb7Xfd/f+3r+uHff3/t9XZ9r8Hl4j57L05M8aOrz1UnOX5YeAaumtbZ7kuFaSe7nMI9JNYWzkuw+1XxFkmdW1RXLdJqtvT+/ODNLfv60qq5cni7BuKzStby1htf8j6vq32vSExivg5NMT+75e5Kr5th3eF8+YjETg1preyV56lTTbUm+tZROwmoQiMICquqOJF8YNB+90M2gtfbMJE+Zavpnkq8sb++AldZa25jkhYPms9agK8D/57Qk0+siHdhae8Z8B0zu9UcPmk+ePBsA25bhC9c/V9Xla9IT2Aa01jall9bca6r57+mzyX6/jKf6fPrszs0Oa60N1yAb9u0uSd49aP7cMvYJRmMVr+Ula609LckrBs1nrHpHYMRaaxuSfGDQ/M15ftN+N8lfpj7vmeSIRZzq/ZkZun5trUpxw3wEorA4H00yXer2qUneNdfOrbXdkpw0aD62qq6ZbX9gXTsmycapz7cm+fbadAXYWlX1tyTHD5pPaq3df57Djkpy4NTnG5J8fLn7BqysSbjy9kHzGWvQFdgmTErrfSfJw6ear09yUFVdtpznqqpfZObA4Z2SnNJa22WOvrUkn0qyz1Tz79KDVWDKal3LrbVntdaOWMoawJOBiV9PssNU81VJTlyufsGYtNY+1lrbf4nHbEqf8bnvVPPtST451zFV9Z8kHxo0H9Na22+e87w0ycsH5xgOLIZ1oVXVwnsBaa0dleTDg+bPJPng5tI8rbU7JXlekmOT7DG135VJHl5V169CV4FZtNbeneR7VfWzRe5/5/TBEG8bbPp0Vb15ufsH27vW2pOSbJhl06PSByZsdnVm/tiadmVV/Wqec2xK8svMXEfwj0nelOQbNXkwnpTWfG+S1w2+4p1VJRCFrTCZBfKDqaY/VtWeS/yOR6eXsf7sYsvpTY45MzOfzW9OsrfymjC71toPsuUyMe9L8uOt+LqfVdV1C5xv7ySXJLnrVPMlSd5SVedM7bdvko8kecHgK15UVV/dir7BqK3WtdxaOzzJyelleL+aHsBcOJwd1lrbIcnjkrwh/Xl+eqLOHUkOqarTt6JvMHqttYvTfxtfkOTLSc5O8suqum2wX0vykCSHpv/Ovdfgq46pqiMXONeOSS7KzMEU/0jy1iSnVtV/J/ttmrS9JzOv5xOq6o1L+ffBahGIwiJNws4zkzx3sOn29JepN6SvMbZxsP3m9FIk5610H4G5tdbOSZ/d/aP0UehnJfn15ge5qf3ukeQ5Sd6Z5NGDr/ltkgOq6tqV7i9sb1prf8iW6/st1SlVdfgC5zkwvQzQXQabrk/y+/T7+B6ZOVo96c8Azy8PzzCvlRzcMBWqXps+q+T0JD8ZVmGZvAh6RJLXJHltkp0HX/WWqjp2oX8LbK9aa8t5r3v6dKg5zzkPS3JqZpbbS3ppzz8luU/6+ofD7cdV1ZuWoZ8wOqt1LU8FokNXpIcoNyXZJf0Z+26z7FdJ3lxVxy1LT2GEpgLRabemX2fXT/7/7kkeMPnvbE5J8qrFLAEzqbDywySbBpv+lf5ubEP6e/AdB9svSPK0qrp5oXPAWlh0KQPY3lXVHa21Q9Mf8g6b2rRDkgfPcdi16SPchKGwfjxx8pck/2mt/SV9QMPtSXZNXx9htpLyf03ybGEobNuq6tzW2sHpo9enf9xtTPKYOQ47Nf2HozAUFvbFLG5ww33T1zSbzSlJDp/n2F3Tw87XJElr7eok1yT5Z/qL1t2S3HOOYz8hDIX1p6pOmwxm+FxmDqq49+RvNsekD2IE1qfdJn/zuSrJK6tqrmcCYG47pYeSC7kxfe3tExf7m7aqLpuUtj4zM5/t75Ytg9nNvp/kUGEo65k1RGEJquqWqnpJkkOSXDzPrjclOSHJfosZDQusmZ2T7JXksUn2Tx/cMNu98VtJHlVVl69i34AVUlVnJ9kvvfT9fGU3L0rywqp62WQtFWB9um96Sa8npM8MnS0MvTHJy6vqHavZMWDxqupL6dfwqUlum2fXc9NnnxxpsBKsC2enrxd4TvrgpIXckeTCJK9PL2EvDIWFvSTJu9JDxxsXsX8l+XmSI9Ovs88s9Z5ZVZckeWR6ufr5yt9fnj5Q8SDLxbHeKZkL/4fJWicHpI942ym9RMFlSc6rqlvWsGvAQGvtWenrDT0lyUOzZTnMoX8l+XaS46vq3BXuHrBGWmsb0meNPyx9lujmskPnV9Vv1rBrsE1ayfLXrbVdk7w6fR3Rx2fLEl6z+XWSzyc5aaF1DIH1o7W2S5InJ9knvfTfLemlc8+rqivWsm/A3CYzvfdKsnd66c6N6UtV3JQeqPw5yQVVtZhAB5jFZFm3fdKvsz3SS1LvmD4g4YYkf0hfx3fZrrPJuqIHpA9c2jW9ytpVk/NculzngZUmEAVgu9Nau2v67LA9k9wvveTHndIHNVyX5FdJLq2q29eoiwDAAlprD0x/GbRH+qzQDemhyXXpL2jOV+oeAACARCAKAAAAAAAAjJg1RAEAAAAAAIDREogCAAAAAAAAoyUQBQAAAAAAAEZLIAoAAAAAAACMlkAUAAAAAAAAGC2BKAAAAAAAADBaAlEAAAAAAABgtASiAAAAAAAAwGgJRAEAAAAAAIDREogCAAAAAAAAoyUQBQAAAAAAAEZLIAoAAAAAAACMlkAUAAAAAAAAGC2BKAAAAAAAADBaAlEAAAAAAABgtASiAAAAAAAAwGgJRAEAAAAAAIDREogCAAAAAAAAoyUQBQAAAAAAAEZLIAoAAAAAAACMlkAUAAAAAAAAGC2BKAAAAAAAADBaAlEAAAAAAABgtASiAAAAAAAAwGgJRAEAAAAAAIDREogCAAAAAAAAoyUQBQAAAAAAAEZLIAoAAAAAAACMlkAUAAAAAAAAGC2BKAAAAAAAADBaAlEAAAAAAABgtASiAAAAAAAAwGgJRAEAAAAAAIDREogCAAAAAAAAoyUQBQAAAAAAAEZLIAoAAAAAAACM1v8AcoANqBwYJtUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2200x900 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ax.legend()\n",
    "def run_regressor(regressor, regressor_name):\n",
    "        \n",
    "    # Choose a regressor\n",
    "    # regressor = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "    train_regressor(train_loader, regressor)\n",
    "\n",
    "    # train_loss, train_results, train_preds, train_Y = regressor_evaluate(train_loader, regressor)\n",
    "    # val_loss, val_results, val_preds, val_Y = regressor_evaluate(val_loader, regressor)\n",
    "    test_loss, test_reuslts, test_preds, test_Y = regressor_evaluate(test_loader, regressor)\n",
    "\n",
    "    # decide which test dataset belong to:\n",
    "    \n",
    "    # dataset_ids = [belong_to_which_datasets(i) for i in test_data.indices]\n",
    "    \n",
    "\n",
    "    print('test_Y shape:', test_Y.reshape(-1, 1).shape, test_preds.reshape(-1, 1).shape)\n",
    "    plot_bars(scaler_y.inverse_transform(test_preds.reshape(-1, 1)),\n",
    "               scaler_y.inverse_transform(test_Y.reshape(-1, 1)), test_data_names, regressor_name)\n",
    "    \n",
    "    # print(f\"regressor_name: {regressor_name}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Test Loss: {test_loss:.4f} \\\n",
    "    #       (mse, rmse, r^2): {test_reuslts}\")\n",
    "    \n",
    "    print(f'{regressor_name}: {round(test_reuslts[0], 2)} & {round(test_reuslts[1], 2)} & {round(test_reuslts[2], 2)} & {round(test_reuslts[3], 2)}')\n",
    "    plt.figure()\n",
    "    plt.plot(scaler_y.inverse_transform(test_preds), label=\"Predictions\")\n",
    "    plt.plot(scaler_y.inverse_transform(test_Y), label=\"True Labels\")\n",
    "    plt.title(regressor_name)\n",
    "    plt.legend(fontsize=16)\n",
    "    \n",
    "    return test_preds, test_Y\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Choose a regressor\n",
    "regressors = {'SVR': SVR(),'Ridge': Ridge(), \"RandomForestRegressor\": RandomForestRegressor(),  \n",
    "              \"LinearRegression\": LinearRegression()}\n",
    "\n",
    "# regressors = {\"RandomForestRegressor\": RandomForestRegressor()}\n",
    "\n",
    "results = []\n",
    "for k, regressor in regressors.items():\n",
    "    results.append(run_regressor(regressor, k))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check correlation of preds and GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-01350292a1c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mminepy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Assuming you have your linear regression model's predictions (y_pred) and ground truth Y (y_true)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(results))\n",
    "from scipy import stats\n",
    "from minepy import pstats, cstats\n",
    "\n",
    "# Assuming you have your linear regression model's predictions (y_pred) and ground truth Y (y_true)\n",
    "# Calculate Spearman correlation coefficient and p-value\n",
    "\n",
    "for pred_s, y_s in results:\n",
    "    # spearman correlation of pred and y:\n",
    "    \n",
    "    spearman_corr, p_value = stats.spearmanr(pred_s, y_s)\n",
    "    print(f\"Spearman correlation coefficient: {spearman_corr:.4f}\")\n",
    "    print(f\"P-value: {p_value:.6f}\")\n",
    "    \n",
    "    # # add pearson correlation of pred and y:\n",
    "    # pearson_corr, p_value = stats.pearsonr(pred_s, y_s)\n",
    "    # print(f\"Pearson correlation coefficient: {pearson_corr:.4f}\")\n",
    "    # print(f\"P-value: {p_value:.6f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "regressors = {'XG boost': xgb.XGBRegressor(objective ='reg:squarederror'),\n",
    "              'LGBMRegressor': lgb.LGBMRegressor()}\n",
    "\n",
    "for k, regressor in regressors.items():\n",
    "    run_regressor(regressor, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use test dataset to evaluate the model\n",
    "\n",
    "# average each datasets:\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "test_dataset_idx = [belong_to_which_datasets(i, store_each_len) for i in test_data.indices]\n",
    "print(Counter(test_dataset_idx))\n",
    "\n",
    "# Get predictions and true labels from the test dataset\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions.extend(outputs.squeeze().cpu().numpy())\n",
    "        true_labels.extend(labels.squeeze().cpu().numpy())\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(scaler_y.inverse_transform(predictions), label=\"Predictions\")\n",
    "plt.plot(scaler_y.inverse_transform(true_labels), label=\"True Labels\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot predictions of other real-world datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 only has on fold\n",
    "\"\"\"\n",
    "result_GIN_0317_decouple_degree_attr_CIFAR10\n",
    "result_GIN_0317_mix_degree_attr_CIFAR10\n",
    "result_GIN_0317_only_attr_CIFAR10\n",
    "result_GIN_0317_only_degree_CIFAR10\n",
    "result_GIN_0318_decouple_degree_attr_CIFAR10\n",
    "result_GIN_0327_finger_mlp_attr_multicrossen_CIFAR10\n",
    "result_GIN_0401_GIN_degree_CIFAR10\n",
    "result_GIN_0403_GIN_degree_CIFAR10\n",
    "\"\"\"\n",
    "\n",
    "MLP_log_path_degree = f'./results/result_GIN_0401_graph_mlp_avgDegree_CIFAR10/MolecularGraphMLP_CIFAR10_assessment/1_NESTED_CV'\n",
    "GNN_log_path_degree = f'./results/result_GIN_0317_only_degree_CIFAR10/GIN_CIFAR10_assessment/1_NESTED_CV'\n",
    "\n",
    "MLP_log_path_attr = f'./results/result_GIN_0327_finger_mlp_attr_multicrossen_CIFAR10/MolecularFingerprint_CIFAR10_assessment/10_NESTED_CV'\n",
    "GNN_log_path_attr = f'./results/result_GIN_0317_only_attr_CIFAR10/GIN_CIFAR10_assessment/1_NESTED_CV'\n",
    "\n",
    "dataset = datasets_obj['CIFAR10']\n",
    "cifar10_datasets = E_datasets(dataset, MLP_log_path_degree, GNN_log_path_degree, MLP_log_path_attr, GNN_log_path_attr, fold=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

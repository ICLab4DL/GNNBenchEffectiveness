{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor\n",
    "1. load datasets\n",
    "1. sample from datasets\n",
    "1. construct features\n",
    "1. construct labels (load from logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.6.\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "# load datasets:\n",
    "import importlib\n",
    "import random\n",
    "import argparse\n",
    "import configparser\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_sparse\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from torch_geometric.utils import negative_sampling, to_networkx\n",
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptPairTensor, Adj, OptTensor, Size\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "\n",
    "from dataset_utils import node_feature_utils\n",
    "from dataset_utils.node_feature_utils import *\n",
    "import my_utils as utils\n",
    "import sys,os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "\n",
    "importlib.reload(utils)\n",
    "\n",
    "# save datasets\n",
    "import pickle as pk\n",
    "\n",
    "def save_datasets(datasets, file_name):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pk.dump(datasets, f)\n",
    "\n",
    "def load_datasets(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        datasets = pk.load(f)\n",
    "    return datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load regressor datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- small: MUTAG, NCI1, DD, CIFAR10, MNIST, imdb_b, ogbg-molhiv, ogbg-molbace, ogbg-moltox21\n",
    "- middle: ogbg-ppa, (ogbg-molpcba, ogbg-code2, to be done)\n",
    "10-fold: MUTAG, NCI1, DD, CIFAR10, MNIST, imdb_b, SynCC\n",
    "one split: ogbg-molhiv, ogbg-molbace, ogbg-moltox21, ogbg-ppa\n",
    "\n",
    "use 10-fold to trian, use one split to test\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Medium\togbg-molpcba\t>=1.2.2\t437,929\t26.0\t28.1\t128\tScaffold\tBinary classification\tAP\n",
    "Medium\togbg-ppa\t>=1.1.1\t158,100\t243.4\t2,266.1\t1\tSpecies\tMulti-class classification\tAccuracy\n",
    "Medium\togbg-code2\n",
    "\"\"\"\n",
    "\n",
    "# small scale: < 10k\n",
    "train_datasets_names = ['mutag', 'nci1', 'dd', 'imdb_b', 'imdb_m', 'mnist', 'cifar10']\n",
    "test_datasets_names = ['ogbg_molhiv', 'ogbg_moltox21', 'ogbg_molbace']\n",
    "\n",
    "train_datasets = []\n",
    "for k in train_datasets_names:\n",
    "    train_datasets.append((load_datasets(f'{k}_datasets.pkl'), k))\n",
    "\n",
    "test_datasets = []\n",
    "    \n",
    "for k in test_datasets_names:\n",
    "    test_datasets.append((load_datasets(f'{k}_datasets.pkl'),k))\n",
    "    \n",
    "# SynCC\n",
    "syn_cc_datasets = load_datasets('syn_datasets.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "7\n",
      "3\n",
      "train:\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "1\n",
      "1\n",
      "test:\n",
      "10\n",
      "1\n",
      "10\n",
      "total real data len: 73\n"
     ]
    }
   ],
   "source": [
    "print(len(syn_cc_datasets))\n",
    "print(len(train_datasets))\n",
    "print(len(test_datasets))\n",
    "print('train:')\n",
    "a = [print(len(d[0])) for d in train_datasets]\n",
    "print('test:')\n",
    "a = [print(len(d[0])) for d in test_datasets]\n",
    "# extend each dataset:\n",
    "\n",
    "# construct label for each dataset:\n",
    "all_datasets = []\n",
    "\n",
    "id_to_name = {}\n",
    "\n",
    "i = 0\n",
    "for d in train_datasets + test_datasets:\n",
    "    for fold_id, dd in enumerate(d[0]):\n",
    "        name = f'{d[1]}_{fold_id}'\n",
    "        id_to_name[i] = name\n",
    "        i += 1\n",
    "        all_datasets.append(dd)\n",
    "\n",
    "print('total real data len:', len(all_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check id_to_name:\n",
    "print(id_to_name.keys())\n",
    "print(id_to_name[44]) # 44 is the id of ogbg_molhiv_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all datasets:\n",
    "    # F1: avgD:\n",
    "    # F2: avgCC:\n",
    "    # F3: avgD/N:\n",
    "    # F4: node num N:\n",
    "    # F5: labels\n",
    "    # calculate each dimension of labels:\n",
    "    # F6: cycles:\n",
    "real_datasets = []\n",
    "\n",
    "train_datasets_pairs, test_datasets_pairs = [],[]\n",
    "\n",
    "# for i, d in enumerate(syn_cc_datasets):\n",
    "#     if int(i//10) == 1 or int(i//10) == 8:\n",
    "#         train_datasets_paris.append(((d[0], d[1]), f'syn_cc:{str(round((((int(i/10)+1))/10.0), 1))}_{(i%10+1)}'))\n",
    "    \n",
    "# for i, d in enumerate(syn_cc_datasets):\n",
    "#     all_datasets_paris.append((d, f'syn_cc:{str(round((((int(i/10)+1))/10.0), 1))}_{(i%10+1)}'))\n",
    "\n",
    "for k, d in enumerate(train_datasets):\n",
    "    train_datasets_pairs.extend([(fold, f'small_:{train_datasets_names[k]}_{i}') for i, fold in enumerate(d)])\n",
    "\n",
    "for k, d in enumerate(test_datasets):\n",
    "    test_datasets_pairs.extend([(fold, f'middle:{test_datasets_names[k]}_{i}') for i, fold in enumerate(d)])\n",
    "\n",
    "train_name_id_dict = {i:d[1] for i, d in enumerate(train_datasets_pairs)}\n",
    "test_name_id_dict = {i:d[1] for i, d in enumerate(test_datasets_pairs)}\n",
    "\n",
    "def belong_to_which_datasets(idx, name_id_dict):\n",
    "    return name_id_dict[idx]\n",
    "\n",
    "print(len(train_name_id_dict), len(test_name_id_dict))\n",
    "\n",
    "new_train_datasets = [d[0] for d in train_datasets_pairs]\n",
    "new_test_datasets = [d[0] for d in test_datasets_pairs]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def plot_bars(preds, Y, show_data, regressor_name):\n",
    "    # es = []\n",
    "    # for i in range(data_block.shape[0]):\n",
    "    #     d= data_block[i]\n",
    "    #     es.append((get_E(d[1, 0], d[3, 0], d[0, 0], d[4, 0]), show_data[i]))\n",
    "\n",
    "    sorted_indices = np.argsort(Y)\n",
    "    predictions_sorted = preds[sorted_indices]\n",
    "    ground_truth_sorted = Y[sorted_indices]\n",
    "\n",
    "    bar_width = 0.3\n",
    "    bar_positions = np.arange(len(show_data)) * 1.5\n",
    "    x_label_positions = bar_positions + bar_width / 2\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(len(show_data)/3, 3), dpi=100)\n",
    "    print('bar_positions shape: ', bar_positions.shape)\n",
    "    print('predictions_sorted: ', predictions_sorted.shape)\n",
    "    print('ground_truth_sorted: ', ground_truth_sorted.shape)\n",
    "    \n",
    "    ax.bar(bar_positions.squeeze(), predictions_sorted.squeeze(), width=bar_width, color='blue', hatch='/', label='Predictions')\n",
    "    ax.bar(bar_positions + bar_width, ground_truth_sorted.squeeze(), width=bar_width, color='orange', hatch='-', label='Ground Truth')\n",
    "    ax.set_xticks(x_label_positions)\n",
    "    ax.set_xticklabels(show_data, rotation=45, ha='right')\n",
    "    ax.set_ylabel('Effectiveness', fontsize=16)\n",
    "    ax.set_xlabel('Dataset ID', fontsize=16)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(linestyle='dashed',zorder=0)\n",
    "    ax.legend( fontsize=16, title_fontsize=16)\n",
    "    ax.set_title(f'Predictions by {regressor_name}', fontsize=16)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def mean_norm(x):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(x), scaler\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.X = torch.tensor([t[0] for t in data], dtype=torch.float32)\n",
    "        self.Y = torch.tensor([t[1] for t in data], dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_data(num_samples):\n",
    "    features = np.random.rand(num_samples, 26)\n",
    "    labels = np.random.rand(num_samples, 1)\n",
    "    return [(features[i], labels[i]) for i in range(num_samples)]\n",
    "\n",
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, input_dim=26):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            # nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    \n",
    "def evaluate(loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    preds = []\n",
    "    Y = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.view(-1, 1))\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "            preds.append(outputs.cpu().numpy())\n",
    "            Y.append(labels.cpu().numpy())\n",
    "            \n",
    "    \n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    Y = np.concatenate(Y, axis=0).ravel()\n",
    "    \n",
    "    mae = mean_absolute_error(Y, preds)\n",
    "    mse = mean_squared_error(Y, preds)\n",
    "    rmse = math.sqrt(mse)\n",
    "    r2 = r2_score(Y, preds)\n",
    "    \n",
    "    results = (mae, mse, rmse, r2)\n",
    "    return mse, results, preds, Y\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def mlp_regressor(input_dim, train_loader, val_loader, test_loader, scaler_x, scaler_y, show_data=None):\n",
    "\n",
    "    model = MLPRegressor(input_dim).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    # criterion = nn.L1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    num_epochs = 500\n",
    "    train_losses, val_losses = [], []\n",
    "    min_val_loss = float(\"inf\") # initialize with a large value\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.view(-1, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss, _, _, _ = evaluate(train_loader, model, criterion, device)\n",
    "        val_loss, _,_,_ = evaluate(val_loader, model, criterion, device)\n",
    "        \n",
    "        if val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_mlp_regressor_model.pth\")\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_mlp_regressor_model.pth\"))\n",
    "    test_loss, test_results, test_preds, test_Y = evaluate(test_loader, model, criterion, device)\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f'MLPs: {round(test_results[0], 2)} & {round(test_results[1], 2)} & {round(test_results[2], 2)} & {round(test_results[3], 2)}')\n",
    "\n",
    "    plot_bars(scaler_y.inverse_transform(test_preds), scaler_y.inverse_transform(test_Y), show_data,  \"MLP Regressor\")\n",
    "\n",
    "    # Plot train and validation loss curves\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Train and Validation Loss Curves\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def construct_regressor_loader(all_datasets, trian_val_ratio=[0.7, 0.0]):\n",
    "\n",
    "    X = np.array([t[0] for t in all_datasets])\n",
    "    Y = np.array([t[1] for t in all_datasets])\n",
    "\n",
    "    normalized_x, scaler_x = mean_norm(X)\n",
    "    normalized_y, scaler_y = mean_norm(Y.reshape(-1, 1))\n",
    "\n",
    "    normed_combined_data = [(normalized_x[i], normalized_y[i]) for i in range(normalized_x.shape[0])]\n",
    "\n",
    "    dataset = CustomDataset(normed_combined_data)\n",
    "\n",
    "    train_size = int(trian_val_ratio[0] * len(dataset))\n",
    "    val_size = int(trian_val_ratio[1] * len(dataset))\n",
    "\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    test_data_names = [id_to_name[i] for i in test_data.indices]\n",
    "    # print(len(train_loader.dataset), len(val_loader.dataset), len(test_loader.dataset))\n",
    "    # print(len(dataset_ids))\n",
    "    return train_loader, val_loader, test_loader, scaler_x, scaler_y, test_data_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use 10-fold to predict one fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train = np.array([t[0] for t in new_train_datasets])\n",
    "# Y_train = np.array([t[1] for t in new_train_datasets])\n",
    "\n",
    "# X_test = np.array([t[0] for t in new_test_datasets])\n",
    "# Y_test = np.array([t[1] for t in new_test_datasets])\n",
    "\n",
    "# normalized_x_train, scaler_x_train = mean_norm(X_train)\n",
    "# normalized_y_train, scaler_y_train = mean_norm(Y_train.reshape(-1, 1))\n",
    "\n",
    "# normalized_x_test = scaler_x_train.transform(X_test)\n",
    "\n",
    "\n",
    "# # print(normalized_x.shape, normalized_y.shape)\n",
    "\n",
    "# # print(len(normalized_x))\n",
    "\n",
    "# normed_combined_data_train = [(normalized_x_train[i], normalized_y_train[i]) for i in range(normalized_x_train.shape[0])]\n",
    "# # normed_combined_data_train = [(normalized_x_train[i], Y_train[i]) for i in range(normalized_x_train.shape[0])]\n",
    "# dataset = CustomDataset(normed_combined_data_train)\n",
    "\n",
    "# train_size = int(0.7 * len(dataset))\n",
    "# val_size = len(dataset) - train_size\n",
    "\n",
    "# train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# normed_combined_data_test = [(normalized_x_test[i], Y_test[i]) for i in range(normalized_x_test.shape[0])]\n",
    "# dataset_test = CustomDataset(normed_combined_data_test)\n",
    "# test_loader = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "\n",
    "# dataset_ids = [belong_to_which_datasets(i, test_name_id_dict) for i in range(len(dataset_test))]\n",
    "# print(len(dataset_ids))\n",
    "\n",
    "# print(len(train_loader.dataset), len(val_loader.dataset), len(test_loader.dataset))\n",
    "# # dataset_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold to predict one-fold dataset:\n",
    "mlp_regressor(26, train_loader, val_loader, test_loader, scaler_x_train, scaler_y_train, show_data=dataset_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_datasets mixed:\n",
    "mlp_regressor(26, train_loader, val_loader, test_loader, scaler_x, scaler_y, show_data=[i for i in range(len(test_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regressor(loader, regressor):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for inputs, labels in loader:\n",
    "        X.extend(inputs.cpu().numpy())\n",
    "        Y.extend(labels.cpu().numpy())\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y).ravel()\n",
    "\n",
    "    regressor.fit(X, Y)\n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "\n",
    "def regressor_evaluate(loader, regressor):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        X.extend(inputs.cpu().numpy())\n",
    "        Y.extend(labels.cpu().numpy())\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y).ravel()\n",
    "\n",
    "    preds = regressor.predict(X)\n",
    "    mae = mean_absolute_error(Y, preds)\n",
    "    mse = mean_squared_error(Y, preds)\n",
    "    rmse = math.sqrt(mse)\n",
    "    r2 = r2_score(Y, preds)\n",
    "    \n",
    "    results = (mae, mse, rmse, r2)\n",
    "    return mse, results, preds, Y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline regressors:\n",
    "- random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax.legend()\n",
    "\n",
    "\n",
    "def plot_regression(scaler_y, test_preds, test_Y, test_data_names, test_reuslts, regressor_name):\n",
    "    \n",
    "    # plot_bars(scaler_y.inverse_transform(test_preds),\n",
    "            #    scaler_y.inverse_transform(test_Y), test_data_names, regressor_name)\n",
    "    \n",
    "    # print(f\"regressor_name: {regressor_name}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Test Loss: {test_loss:.4f} \\\n",
    "    #       (mse, rmse, r^2): {test_reuslts}\")\n",
    "    \n",
    "    # print(f'{regressor_name}: {round(test_reuslts[0], 2)} & {round(test_reuslts[1], 2)} & {round(test_reuslts[2], 2)} & {round(test_reuslts[3], 2)}')\n",
    "    plt.figure()\n",
    "    test_preds = scaler_y.inverse_transform(test_preds)\n",
    "    test_Y = scaler_y.inverse_transform(test_Y)\n",
    "    \n",
    "    s_idx = np.argsort(test_Y)\n",
    "    test_preds = test_preds[s_idx]\n",
    "    test_Y = test_Y[s_idx]\n",
    "    \n",
    "    plt.plot(test_preds, label=\"Predictions\")\n",
    "    plt.plot(test_Y, label=\"The Ground Truth\")\n",
    "    plt.xlabel(\"Test Dataset ID\", fontsize=14)\n",
    "    plt.ylabel(\"Effectiveness Value\", fontsize=14)\n",
    "    plt.title(regressor_name)\n",
    "    plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "def run_regressor(train_loader, test_loader, scaler_y, test_data_names, regressor, regressor_name, plot=True):\n",
    "        \n",
    "    # Choose a regressor\n",
    "    # regressor = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "    train_regressor(train_loader, regressor)\n",
    "\n",
    "    # train_loss, train_results, train_preds, train_Y = regressor_evaluate(train_loader, regressor)\n",
    "    # val_loss, val_results, val_preds, val_Y = regressor_evaluate(val_loader, regressor)\n",
    "    test_loss, test_reuslts, test_preds, test_Y = regressor_evaluate(test_loader, regressor)\n",
    "\n",
    "    # decide which test dataset belong to:\n",
    "    \n",
    "    # dataset_ids = [belong_to_which_datasets(i) for i in test_data.indices]\n",
    "    if plot:\n",
    "        plot_regression(scaler_y, test_preds, test_Y, test_data_names, test_reuslts, regressor_name)\n",
    "    \n",
    "    return test_preds, test_Y\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "def get_regressors():\n",
    "    # regressors = {\"RandomForestRegressor\": RandomForestRegressor()}\n",
    "    return {'Support Vector': SVR(), 'Ridge': Ridge(), \"Random Forest\": RandomForestRegressor()}\n",
    "\n",
    "def regression_test(log_info=True, plot=True, plot_all=False):\n",
    "    # Choose a regressor\n",
    "\n",
    "    regressors = get_regressors()\n",
    "\n",
    "    #construct_regressor_loader:\n",
    "    train_val_ratio=[0.7, 0.0]\n",
    "    train_loader, val_loader, test_loader, scaler_x, scaler_y, test_data_names = construct_regressor_loader(all_datasets, train_val_ratio)\n",
    "    #  = construct_regressor_loader(all_datasets)\n",
    "    \n",
    "    results = []\n",
    "    for k, regressor in regressors.items():\n",
    "        results.append(run_regressor(train_loader, test_loader, scaler_y, test_data_names, regressor, k, plot=plot))\n",
    "    if plot_all:\n",
    "        plt.figure(figsize=(8, 7), dpi=200)\n",
    "        Y = scaler_y.inverse_transform(results[0][1])\n",
    "        sort_idx = np.argsort(Y)\n",
    "        Y = Y[sort_idx]\n",
    "        plt.plot(Y, label=\"The Ground Truth\", linewidth=2)\n",
    "        for i, k in enumerate(regressors.keys()):\n",
    "            test_preds = scaler_y.inverse_transform(results[i][0])\n",
    "            test_preds = test_preds[sort_idx]\n",
    "            # plot dashed lines:\n",
    "            plt.plot(test_preds, '--', label=k, linewidth=2)\n",
    "            # plt.plot(test_preds, '--', label=\"Predictions by \" + k, linewidth=3)\n",
    "            # plot each points, and set scater size to 10, and set color to be the same as the dashed line:\n",
    "            plt.scatter(np.arange(len(test_preds)), test_preds, s=14, c=plt.gca().lines[-1].get_color())\n",
    "            \n",
    "        # make xticks larger:\n",
    "        plt.xticks(fontsize=22)\n",
    "        plt.yticks(fontsize=22)\n",
    "      \n",
    "        plt.xlabel(\"Test Dataset ID\", fontsize=22)\n",
    "        plt.ylabel(\"Effectiveness Value\", fontsize=22)\n",
    "        plt.legend(fontsize=22, loc='upper left')\n",
    "        # plt.title(\"Predictions by Different Regressors\")\n",
    "\n",
    "    \n",
    "    from scipy import stats\n",
    "\n",
    "    # Assuming you have your linear regression model's predictions (y_pred) and ground truth Y (y_true)\n",
    "    # Calculate Spearman correlation coefficient and p-value\n",
    "    corr_results = []\n",
    "    for pred_s, y_s in results:\n",
    "        # spearman correlation of pred and y:\n",
    "        spearman_corr, p_value = stats.spearmanr(pred_s, y_s)\n",
    "        corr_results.append([spearman_corr, p_value])\n",
    "        if log_info:\n",
    "            print(f\"Spearman correlation coefficient: {spearman_corr:.4f}\")\n",
    "            print(f\"P-value: {p_value:.6f}\")\n",
    "        \n",
    "    return np.array(corr_results)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = []\n",
    "for i in range(20):\n",
    "    corrs.append(regression_test(log_info=False, plot=False, plot_all=True))\n",
    "\n",
    "corrs = np.stack(corrs)\n",
    "\n",
    "regressors = get_regressors()\n",
    "    \n",
    "mean_corrs = np.mean(corrs, axis=0)\n",
    "std_corrs = np.std(corrs, axis=0)\n",
    "    \n",
    "for i, k in enumerate(regressors.keys()):\n",
    "    print('regressor name:', k)\n",
    "    print(f'mean peasron: , {mean_corrs[i, 0]:.3f},  std: , {std_corrs[i, 0]:.3f}')\n",
    "    print(f'mean p-values: , {mean_corrs[i, 1]:.6f}, std: , {std_corrs[i, 1]:.6f}')\n",
    "    print('--------------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check correlation of preds and GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-01350292a1c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mminepy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Assuming you have your linear regression model's predictions (y_pred) and ground truth Y (y_true)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(results))\n",
    "from scipy import stats\n",
    "from minepy import pstats, cstats\n",
    "\n",
    "# Assuming you have your linear regression model's predictions (y_pred) and ground truth Y (y_true)\n",
    "# Calculate Spearman correlation coefficient and p-value\n",
    "\n",
    "for pred_s, y_s in results:\n",
    "    # spearman correlation of pred and y:\n",
    "    \n",
    "    spearman_corr, p_value = stats.spearmanr(pred_s, y_s)\n",
    "    print(f\"Spearman correlation coefficient: {spearman_corr:.4f}\")\n",
    "    print(f\"P-value: {p_value:.6f}\")\n",
    "    \n",
    "    # # add pearson correlation of pred and y:\n",
    "    # pearson_corr, p_value = stats.pearsonr(pred_s, y_s)\n",
    "    # print(f\"Pearson correlation coefficient: {pearson_corr:.4f}\")\n",
    "    # print(f\"P-value: {p_value:.6f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "regressors = {'XG boost': xgb.XGBRegressor(objective ='reg:squarederror'),\n",
    "              'LGBMRegressor': lgb.LGBMRegressor()}\n",
    "\n",
    "for k, regressor in regressors.items():\n",
    "    run_regressor(regressor, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use test dataset to evaluate the model\n",
    "\n",
    "# average each datasets:\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "test_dataset_idx = [belong_to_which_datasets(i, store_each_len) for i in test_data.indices]\n",
    "print(Counter(test_dataset_idx))\n",
    "\n",
    "# Get predictions and true labels from the test dataset\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions.extend(outputs.squeeze().cpu().numpy())\n",
    "        true_labels.extend(labels.squeeze().cpu().numpy())\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(scaler_y.inverse_transform(predictions), label=\"Predictions\")\n",
    "plt.plot(scaler_y.inverse_transform(true_labels), label=\"True Labels\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot predictions of other real-world datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10 only has on fold\n",
    "\"\"\"\n",
    "result_GIN_0317_decouple_degree_attr_CIFAR10\n",
    "result_GIN_0317_mix_degree_attr_CIFAR10\n",
    "result_GIN_0317_only_attr_CIFAR10\n",
    "result_GIN_0317_only_degree_CIFAR10\n",
    "result_GIN_0318_decouple_degree_attr_CIFAR10\n",
    "result_GIN_0327_finger_mlp_attr_multicrossen_CIFAR10\n",
    "result_GIN_0401_GIN_degree_CIFAR10\n",
    "result_GIN_0403_GIN_degree_CIFAR10\n",
    "\"\"\"\n",
    "\n",
    "MLP_log_path_degree = f'./results/result_GIN_0401_graph_mlp_avgDegree_CIFAR10/MolecularGraphMLP_CIFAR10_assessment/1_NESTED_CV'\n",
    "GNN_log_path_degree = f'./results/result_GIN_0317_only_degree_CIFAR10/GIN_CIFAR10_assessment/1_NESTED_CV'\n",
    "\n",
    "MLP_log_path_attr = f'./results/result_GIN_0327_finger_mlp_attr_multicrossen_CIFAR10/MolecularFingerprint_CIFAR10_assessment/10_NESTED_CV'\n",
    "GNN_log_path_attr = f'./results/result_GIN_0317_only_attr_CIFAR10/GIN_CIFAR10_assessment/1_NESTED_CV'\n",
    "\n",
    "dataset = datasets_obj['CIFAR10']\n",
    "cifar10_datasets = E_datasets(dataset, MLP_log_path_degree, GNN_log_path_degree, MLP_log_path_attr, GNN_log_path_attr, fold=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

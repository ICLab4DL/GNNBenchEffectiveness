{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load local dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The OGB package is out of date. Your version is 1.3.2, while the latest version is 1.3.5.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'my_utils' from '/li_zhengdao/github/GenerativeGNN/my_utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import random\n",
    "import argparse\n",
    "import configparser\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_sparse\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.utils import negative_sampling, to_networkx\n",
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptPairTensor, Adj, OptTensor, Size\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "\n",
    "from dataset_utils import node_feature_utils\n",
    "from dataset_utils.node_feature_utils import *\n",
    "import my_utils as utils\n",
    "\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['REDDIT-BINARY', 'REDDIT-MULTI-5K', 'COLLAB', 'IMDB-BINARY', 'IMDB-MULTI', 'NCI1', 'ENZYMES', 'PROTEINS', 'DD', 'MUTAG', 'CSL'])\n",
      "loaded dataset, name: MUTAG\n",
      "processed_dir:  gnn_comparison/DATA/MUTAG/processed\n",
      "load dataset !\n",
      "dataset len:  188\n",
      "load splits: gnn_comparison/DATA/MUTAG/processed/MUTAG_splits.json\n",
      "split counts: 10\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Load specific dataset:\n",
    "\n",
    "import sys,os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "\n",
    "from PrepareDatasets import DATASETS\n",
    "import my_utils\n",
    "import dataset_utils\n",
    "\n",
    "\n",
    "print(DATASETS.keys())\n",
    "\"\"\"\n",
    "    'REDDIT-BINARY': RedditBinary,\n",
    "    'REDDIT-MULTI-5K': Reddit5K,\n",
    "    'COLLAB': Collab,\n",
    "    'IMDB-BINARY': IMDBBinary,\n",
    "    'IMDB-MULTI': IMDBMulti,\n",
    "    'NCI1': NCI1,\n",
    "    'ENZYMES': Enzymes,\n",
    "    'PROTEINS': Proteins,\n",
    "    'DD': DD,\n",
    "    \"MUTAG\": Mutag,\n",
    "    'CSL': CSL\n",
    "\"\"\"\n",
    "\n",
    "data_names = ['MUTAG']\n",
    "datasets_obj = {}\n",
    "for k, v in DATASETS.items():\n",
    "    if k not in data_names:\n",
    "        continue\n",
    "    \n",
    "    print('loaded dataset, name:', k)\n",
    "    dat = v(use_node_attrs=True)\n",
    "    datasets_obj[k] = dat\n",
    "    print(type(dat.dataset.get_data()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = datasets_obj['MUTAG'].get_test_fold(1, batch_size=1, shuffle=True).dataset[0]\n",
    "\n",
    "from torch_geometric import utils as pyg_utils\n",
    "\n",
    "\n",
    "G = pyg_utils.to_networkx(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_each_folder(fold_id, batch_size=1):\n",
    "    \n",
    "    fold_test = datasets_obj['MUTAG'].get_test_fold(fold_id, batch_size=batch_size, shuffle=True).dataset\n",
    "    fold_train, fold_val = datasets_obj['MUTAG'].get_model_selection_fold(fold_id, inner_idx=None,\n",
    "                                                                          batch_size=batch_size, shuffle=True)\n",
    "    fold_train = fold_train.dataset\n",
    "    fold_val = fold_val.dataset\n",
    "    \n",
    "    # train_G = [pyg_utils.to_networkx(d, node_attrs=['x']) for d in fold_train.get_subset()]\n",
    "    # test_G = [pyg_utils.to_networkx(d, node_attrs=['x']) for d in fold_test.get_subset()]\n",
    "    # print('x: ',train_G[0].nodes[0]['x'])\n",
    "    \n",
    "    train_adjs, test_adjs = [], []\n",
    "    train_y, test_y = [], []\n",
    "    \n",
    "    def node_fea_to_dict(node_fea):\n",
    "        res = {}\n",
    "        for i in range(node_fea.shape[0]):\n",
    "            res[i] = node_fea[i]\n",
    "        return res\n",
    "        \n",
    "    for d in fold_train.get_subset():\n",
    "        train_y.append(d.y.item())\n",
    "        train_adjs.append([d.to_numpy_array()])\n",
    "\n",
    "    for d in fold_test.get_subset():\n",
    "        test_y.append(d.y.item())\n",
    "        test_adjs.append([d.to_numpy_array()])\n",
    "        \n",
    "    return train_adjs, test_adjs, train_y, test_y\n",
    "    # do not use val for kernel methods.\n",
    "#     for d in fold.dataset.get_subset():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform from networkx\n",
    "from grakel.utils import graph_from_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from grakel.datasets import fetch_dataset\n",
    "from grakel.kernels import ShortestPath\n",
    "\n",
    "# Loads the MUTAG dataset\n",
    "\n",
    "\n",
    "\n",
    "# MUTAG = fetch_dataset(\"MUTAG\", verbose=False)\n",
    "# G, y = MUTAG.data, MUTAG.target\n",
    "# print('G10:', G[0])\n",
    "\n",
    "def train_with_kernel(gk):\n",
    "    res=[]\n",
    "    for i in range(10):\n",
    "        G_train, G_test, y_train, y_test = get_each_folder(i)\n",
    "        \n",
    "        # G_train = [g for g in graph_from_networkx(G_train,node_labels_tag='x')]\n",
    "        # G_test = [g for g in graph_from_networkx(G_test,node_labels_tag='x')]\n",
    "        # print('G_train 10:',G_train[:10])\n",
    "        \n",
    "        # G_train, G_test, y_train, y_test = train_test_split(G_train, y_train, test_size=0.1)\n",
    "        # Uses the shortest path kernel to generate the kernel matrices\n",
    "        \n",
    "        K_train = gk.fit_transform(G_train)\n",
    "        K_test = gk.transform(G_test)\n",
    "\n",
    "        # Uses the SVM classifier to perform classification\n",
    "        clf = SVC(kernel=\"precomputed\")\n",
    "        clf.fit(K_train, y_train)\n",
    "        y_pred = clf.predict(K_test)\n",
    "\n",
    "        # Computes and prints the classification accuracy\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        res.append(acc)\n",
    "        # print(\"Accuracy:\", str(round(acc*100, 2)) + \"%\")\n",
    "        \n",
    "    res = np.array(res)\n",
    "    print(f'Acc, mean: {round(np.mean(res)*100, 4)}, std: {round(100*np.std(res),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc, mean: 80.3216, std: 8.2413\n"
     ]
    }
   ],
   "source": [
    "# ShortestPathKernel\n",
    "gk = ShortestPath(normalize=True, with_labels=False)\n",
    "train_with_kernel(gk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc, mean: 89.3275, std: 7.5947\n"
     ]
    }
   ],
   "source": [
    "from grakel.kernels import RandomWalk\n",
    "\n",
    "# TODO: other kernel\n",
    "rw_gk = RandomWalk()\n",
    "\n",
    "train_with_kernel(rw_gk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8 (default, Oct  7 2019, 12:59:55) \n[GCC 8.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

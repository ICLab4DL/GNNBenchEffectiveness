{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import pickle as pk\n",
    "import os\n",
    "\n",
    "# here..\n",
    "cmaps = {}\n",
    "\n",
    "gradient = np.linspace(0, 1, 256)\n",
    "gradient = np.vstack((gradient, gradient))\n",
    "\n",
    "\n",
    "x_y_label_font = 20\n",
    "x_y_legend_font = 20\n",
    "\n",
    "plt.rc('font', family='Times New Roman')\n",
    "fig_dpi = 220\n",
    "fig_shape_squre = (6, 5)\n",
    "\n",
    "def plot_color_gradients(category, cmap_list):\n",
    "    # Create figure and adjust figure height to number of colormaps\n",
    "    nrows = len(cmap_list)\n",
    "    figh = 0.35 + 0.15 + (nrows + (nrows - 1) * 0.1) * 0.22\n",
    "    fig, axs = plt.subplots(nrows=nrows + 1, figsize=(6.4, figh), dpi=100)\n",
    "    fig.subplots_adjust(top=1 - 0.35 / figh, bottom=0.15 / figh,\n",
    "                        left=0.2, right=0.99)\n",
    "    axs[0].set_title(f'{category} colormaps', fontsize=14)\n",
    "\n",
    "    for ax, name in zip(axs, cmap_list):\n",
    "        ax.imshow(gradient, aspect='auto', cmap=plt.get_cmap(name))\n",
    "        ax.text(-0.01, 0.5, name, va='center', ha='right', fontsize=10,\n",
    "                transform=ax.transAxes)\n",
    "\n",
    "    # Turn off *all* ticks & spines, not just the ones with colormaps.\n",
    "    for ax in axs:\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    # Save colormap list for later.\n",
    "    cmaps[category] = cmap_list\n",
    "    plt.show()\n",
    "\n",
    "class MyColor(object):\n",
    "    def __init__(self, cmap_name, skip_idx=5, backup_name='Set1', backup_color=3):\n",
    "        self.color_set  = plt.get_cmap(cmap_name).colors\n",
    "        self.backup_set = plt.get_cmap(backup_name).colors\n",
    "        self.backup_color = backup_color\n",
    "        self.skip_idx=skip_idx\n",
    "        self.idx = 0\n",
    "        self.color_len = len(self.color_set)\n",
    "        \n",
    "    def get_color(self):\n",
    "        if self.idx == self.color_len - 1:\n",
    "            self.idx = 0\n",
    "        if self.idx == self.skip_idx:\n",
    "            self.idx += 1\n",
    "            return self.backup_set[self.backup_color]\n",
    "        color = self.color_set[self.idx]\n",
    "        self.idx += 1\n",
    "        return color\n",
    "    \n",
    "def lighten_color(color, amount=0.3):\n",
    "    \"\"\"\n",
    "    Lightens the given color by multiplying (1-luminosity) by the given amount.\n",
    "    Input can be matplotlib color string, hex string, or RGB tuple.\n",
    "\n",
    "    Examples:\n",
    "    >> lighten_color('g', 0.3)\n",
    "    >> lighten_color('#F034A3', 0.6)\n",
    "    >> lighten_color((.3,.55,.1), 0.5)\n",
    "    \"\"\"\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return colorsys.hls_to_rgb(c[0], 1 - amount * (1 - c[1]), c[2])\n",
    "\n",
    "\n",
    "plot_color_gradients('Qualitative',\n",
    "                     ['Pastel1', 'Pastel2', 'Paired', 'Accent', 'Dark2',\n",
    "                      'Set1', 'Set2', 'Set3', 'tab10', 'tab20', 'tab20b',\n",
    "                      'tab20c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load from file\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dataset_name = 'MolecularFingerprint_REDDIT-BINARY_assessment'\n",
    "\n",
    "def load_logs(date=None, name=None) -> dict:\n",
    "    \n",
    "    def extract_data(data_path) -> list:\n",
    "        with open(data_path, 'r') as f:\n",
    "            data = []\n",
    "            for line in f.readlines():\n",
    "                if not line.startswith('Epoch'):\n",
    "                    continue\n",
    "                \n",
    "                line = line.strip().replace(',', '')\n",
    "                l = line.split(' ')\n",
    "                s_l = [l[4], l[7], l[10], l[13], l[16], l[19], l[-1]]\n",
    "                f_l = []\n",
    "                for i in s_l:\n",
    "                    try:\n",
    "                        fi = float(i)\n",
    "                    except Exception as e:\n",
    "                        fi = 0.0\n",
    "                    f_l.append(fi)\n",
    "                        \n",
    "                data.append(f_l)\n",
    "            return np.array(data)\n",
    "    \n",
    "    if date is not None:\n",
    "        root_dir = f'results/result_{date}/'\n",
    "        dirs = os.listdir(f'results/result_{date}/')\n",
    "        print(dirs)\n",
    "        dataset_log = {}\n",
    "        for d in dirs:\n",
    "            dd = os.path.join(root_dir, d, '10_NESTED_CV')\n",
    "            outer_dirs = os.listdir(dd)\n",
    "            log_folds = []\n",
    "            for i, id_name in enumerate(outer_dirs):\n",
    "                if not os.path.isdir(os.path.join(dd, id_name)):\n",
    "                    continue\n",
    "                \"\"\"\n",
    "                Epoch: 1, TR loss: 433.2928585476345 TR acc: 48.641975308641975, VL loss: 479.35484415690104 VL acc: 47.77777854071723 TE loss: 101.24097244262695 TE acc: 39.0\n",
    "                Epoch: 10, TR loss: 9.24662885548156 TR acc: 65.4320987654321, VL loss: 324.07152099609374 VL acc: 70.00000135633681 TE loss: 13.453640460968018 TE acc: 62.0\n",
    "                Epoch: 20, TR loss: 11.454432420377378 TR acc: 59.75308641975309, VL loss: 148.55850830078126 VL acc: 54.444445376926 TE loss: 30.56077377319336 TE acc: 53.0\n",
    "                Epoch: 30, TR l\n",
    "                \"\"\"\n",
    "                file_dir = os.path.join(dd, id_name, 'experiment.log')\n",
    "                data = extract_data(file_dir)\n",
    "                log_folds.append(data)\n",
    "            dataset_log[d] = log_folds\n",
    "        return dataset_log\n",
    "    \n",
    "    elif name is not None:\n",
    "        # TODO: search the best config:\n",
    "        root_path = f\"results/{name}/\"\n",
    "        print('input root_path:', root_path)\n",
    "        assert os.path.exists(root_path)\n",
    "        \n",
    "        dirs = os.listdir(root_path)\n",
    "        \n",
    "        folds_data = {} # TODO store data.\n",
    "        for d in dirs:\n",
    "            # search 10 folds:\n",
    "            folds = []\n",
    "            for i in range(1, 11):\n",
    "                fold_dir = os.path.join(root_path, d, f'10_NESTED_CV/OUTER_FOLD_{i}/HOLDOUT_MS/')\n",
    "                configs = os.listdir(fold_dir)\n",
    "                # print winner config. TODO.\n",
    "                best_vl_acc = 0.0\n",
    "                best_conf = None\n",
    "                if len(configs) < 3:\n",
    "                    # only one config.\n",
    "                    best_conf = 'config_1'\n",
    "                else:\n",
    "                    for cf in configs:\n",
    "                        if not os.path.isdir(os.path.join(fold_dir,cf)):\n",
    "                            continue\n",
    "                        config_res = os.path.join(fold_dir, cf, 'experiment.log')\n",
    "                        with open(config_res,'r') as f:\n",
    "                            for l in f.readlines():\n",
    "                                if 'best' in l:\n",
    "                                    vlacc = float(l.split(' ')[9].split(',')[0])\n",
    "                                    if vlacc > best_vl_acc:\n",
    "                                        best_conf = cf\n",
    "                                        best_vl_acc = vlacc\n",
    "                                    \n",
    "                # print('best_conf:', best_conf, 'acc:', best_vl_acc)\n",
    "                # TODO: load the best again.\n",
    "                best_conf_path = os.path.join(fold_dir, best_conf, 'experiment.log')\n",
    "                best_data = extract_data(best_conf_path)\n",
    "                folds.append(best_data)\n",
    "            folds_data[d] = folds\n",
    "        \n",
    "        return folds_data\n",
    "                \n",
    "                \n",
    "        # with open()\n",
    "\"\"\"\n",
    "Epoch: 750, TR loss: 1.7823815012174378 TR acc: 13.374485612406161, VL loss: 1.8264499328754566 VL acc: 16.666666949236834 TE loss: None TE acc: None\n",
    "Stopping at epoch 751, best is (1.9384536331082567, 17.489711965553063, 1.841690769901982, 22.22222222222222, None, None, 251)\n",
    "TR Accuracy: 17.489711965553063 VL Accuracy: 22.22222222222222\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot\n",
    "\n",
    "# TODO: def histogram\n",
    "def plot_loss_curve(data_states:list=None, titles:list=None):\n",
    "\n",
    "    total = len(data_states)\n",
    "    \n",
    "    if total == 1:\n",
    "        folds = data_states[0]\n",
    "        name = titles[0]\n",
    "        \n",
    "        fig, axes = plt.subplots(4, 3, figsize=(10, 8), dpi=300)\n",
    "        for idx, fold in enumerate(folds):\n",
    "            axe = axes[int(idx/3)][idx%3]\n",
    "            \n",
    "            axe.plot(fold[:, 0]) # train loss\n",
    "            axe.plot(fold[:, 2]) # val loss\n",
    "            axe.set_ylim(0, 5)\n",
    "            # TODO: acc, right axis\n",
    "            \n",
    "            axe.set_title(f'fold: {idx}')\n",
    "        if len(folds)%3 > 0:\n",
    "            for d in range(3-total%3):\n",
    "                fig.delaxes(axes[-1][-d-1])\n",
    "        fig.suptitle(','.join(name.split('_')[:2]) +\",\" + name.split('_')[-1])\n",
    "        fig.legend(['train loss', 'val_loss'], loc='lower right')\n",
    "        # fig.title(','.join(name.split('_')[:2]))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# plot gradient L2 norm:\n",
    "\n",
    "def plot_gradientnorm_curve(data_states:list=None, figure_title=None, titles:list=None, rolling=False):\n",
    "\n",
    "    total = len(data_states)\n",
    "    \n",
    "    if total == 1:\n",
    "        folds = data_states[0]\n",
    "        name = titles[0]\n",
    "        \n",
    "        fig, axes = plt.subplots(4, 3, figsize=(10, 12), dpi=300)\n",
    "        # plt.yscale(\"log\")  \n",
    "        for idx, fold in enumerate(folds):\n",
    "            axe = axes[int(idx/3)][idx%3]\n",
    "            axe.set_yscale('log', subs=[0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "            if rolling:\n",
    "                df = pd.DataFrame(fold[:, -1])\n",
    "                axe.plot(df[0], 'lightblue', df[0].rolling(10).mean(), 'b') # gradient norm\n",
    "            else:\n",
    "                axe.plot(fold[:, -1]) # gradient norm\n",
    "            # TODO: acc, right axis\n",
    "            \n",
    "            axe.set_title(f'fold: {idx}')\n",
    "        if len(folds)%3 > 0:\n",
    "            for d in range(3-total%3):\n",
    "                fig.delaxes(axes[-1][-d-1])\n",
    "        fig.suptitle(','.join(name.split('_')[:2]) + \",\" +name.split('_')[-1])\n",
    "        fig.legend(['train loss', 'val_loss'], loc='lower right')\n",
    "        # fig.title(','.join(name.split('_')[:2]))\n",
    "    else: # multi datasets:\n",
    "        fig, axes = plt.subplots(4, 3, figsize=(10, 12), dpi=300)\n",
    "        last_leg = []\n",
    "        color = MyColor(cmap_name='Set1')\n",
    "        for i, folds in enumerate(data_states):\n",
    "            # plt.yscale(\"log\")  \n",
    "            cc = color.get_color()\n",
    "            for idx, fold in enumerate(folds):\n",
    "                axe = axes[int(idx/3)][idx%3]\n",
    "                axe.set_ylim(-1, 10)\n",
    "                # axe.set_yscale('log', subs=[0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "                if rolling:\n",
    "                    df = pd.DataFrame(fold[:, -1])\n",
    "                    # axe.plot(df[0], color=lighten_color(cc), alpha=0.4)\n",
    "                    axe.plot(df[0].rolling(5).mean(), color=cc, label=titles[i]) # gradient norm\n",
    "                else:\n",
    "                    axe.plot(fold[:, -1], label=titles[i])  # gradient norm\n",
    "                # TODO: acc, right axis\n",
    "                axe.set_title(f'fold: {idx}')\n",
    "                \n",
    "        if len(folds)%3 > 0:\n",
    "            for d in range(3-total%3):\n",
    "                fig.delaxes(axes[-1][-d-1])\n",
    "        handlers, labels = axes[0][0].get_legend_handles_labels()\n",
    "        fig.legend(handlers, labels, loc='lower right')\n",
    "        fig.suptitle(figure_title)\n",
    "        \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = load_logs(name='result_GIN_0202') # random\n",
    "\n",
    "# random, overfitting!!\n",
    "for k, v in stats.items():\n",
    "    loss_log, titles = [], []\n",
    "    loss_log.append(v)\n",
    "    titles.append(k + \"_Random\")\n",
    "    plot_loss_curve(loss_log, titles)\n",
    "    plot_gradientnorm_curve(loss_log, titles)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = load_logs(name='result_GIN_0202_attr')\n",
    "\n",
    "# attr, SOTA!!\n",
    "for k, v in stats.items():\n",
    "    loss_log, titles = [], []\n",
    "    loss_log.append(v)\n",
    "    titles.append(k)\n",
    "    plot_loss_curve(loss_log, titles)\n",
    "    plot_gradientnorm_curve(loss_log, titles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = load_logs(name='result_GIN_0202_eigen')\n",
    "# stats = load_logs(name='result_GIN_0202_pagerank')\n",
    "# TODO: plot all config_17 or the best config?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in stats.items():\n",
    "    loss_log, titles = [], []\n",
    "    loss_log.append(v)\n",
    "    titles.append(k+\"_Eigenvector\")\n",
    "    plot_loss_curve(loss_log, titles)\n",
    "    plot_gradientnorm_curve(loss_log, titles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = load_logs(name='result_GIN_0202_pagerank')\n",
    "for k, v in stats.items():\n",
    "    loss_log, titles = [], []\n",
    "    loss_log.append(v)\n",
    "    titles.append(k+\"_Pagerank\")\n",
    "    plot_loss_curve(loss_log, titles)\n",
    "    plot_gradientnorm_curve(loss_log, titles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = load_logs(name='result_GIN_0202_degree')\n",
    "for k, v in stats.items():\n",
    "    loss_log, titles = [], []\n",
    "    loss_log.append(v)\n",
    "    titles.append(k+\"_Degree\")\n",
    "    plot_loss_curve(loss_log, titles)\n",
    "    plot_gradientnorm_curve(loss_log, titles, rolling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = load_logs(name='result_GIN_0202_degree_large_batchsize')\n",
    "for k, v in stats.items():\n",
    "    loss_log, titles = [], []\n",
    "    loss_log.append(v)\n",
    "    titles.append(k+\"_Degree_largeBatch\")\n",
    "    plot_loss_curve(loss_log, titles)\n",
    "    plot_gradientnorm_curve(loss_log, titles, rolling=True)\n",
    "    \n",
    "    # No difference !!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: using different node initializations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_1023 = load_logs(date=1023)\n",
    "\n",
    "for k, v in stats_1023.items():\n",
    "    print('dataset name: ', k, 'fold len:', len(v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in stats_1023.items():\n",
    "    loss_log, titles = [], []\n",
    "    loss_log.append(v)\n",
    "    titles.append(k)\n",
    "    plot_loss_curve(loss_log, titles)\n",
    "    \n",
    "# has N fold.\n",
    "# TODO: plot N fold first, then we may pick one best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: compare the loss curves of normed and unnormed random feature on MUTAG:\n",
    "\n",
    "\n",
    "\n",
    "stats_randnorm = load_logs(name='result_GIN_0207_random_norm')\n",
    "\n",
    "    \n",
    "loss_log, titles = [], []\n",
    "for k, v in stats_randnorm.items():\n",
    "    loss_log.append(v)\n",
    "    titles.append(k)\n",
    "    plot_loss_curve(loss_log, titles)\n",
    "    break\n",
    "    \n",
    "# has N fold.\n",
    "# TODO: plot N fold first, then we may pick one best.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Plot all gradient norm curves into one figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_states = load_logs(name='result_GIN_0202_degree') # random\n",
    "random_states = load_logs(name='result_GIN_0202') # random\n",
    "eigen_states = load_logs(name='result_GIN_0202_eigen') # random\n",
    "pagerank_states = load_logs(name='result_GIN_0202_pagerank') # random\n",
    "attr_states = load_logs(name='result_GIN_0202_attr') # random\n",
    "\n",
    "def extend_value(stat:dict):\n",
    "    return [v for v in stat.values()]\n",
    "\n",
    "all_stats = [degree_states, random_states, eigen_states, pagerank_states, attr_states]\n",
    "loss_logs = []\n",
    "[loss_logs.extend(extend_value(s)) for s in all_stats]\n",
    "\n",
    "titles = ['degree', 'random', 'eigen', 'pagerank', 'attr']\n",
    "\n",
    "plot_gradientnorm_curve(loss_logs,'GIN,mutag' ,titles, rolling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare real, low, high range of degree on MUTAG:\n",
    "states0 = load_logs(name='result_GIN_0208_degree_shuffle') # random\n",
    "states1 = load_logs(name='result_GIN_0211_degree_shuf01') # random\n",
    "states2 = load_logs(name='result_GIN_0210_rand_id_4') # random\n",
    "states3 = load_logs(name='result_GIN_0207_random_norm') # random\n",
    "\n",
    "def extend_value(stat:dict, name:str=None):\n",
    "    if name is None:\n",
    "        return [v for v in stat.values()]\n",
    "    else:\n",
    "        for k, v in stat.items():\n",
    "            k = k.upper()\n",
    "            if name.upper() in k:\n",
    "                return [v]\n",
    "\n",
    "# all_stats = [states1, states2]\n",
    "all_stats = [states0, states1, states2, states3]\n",
    "loss_logs = []\n",
    "for s in all_stats:\n",
    "    print(s.keys())\n",
    "    loss_logs.extend(extend_value(s, name='mutag'))\n",
    "\n",
    "titles = ['degree', 'degree_shuf01(sampling)', 'rand_id_4', 'gauss']\n",
    "\n",
    "plot_gradientnorm_curve(loss_logs,'GIN,mutag' ,titles, rolling=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot node feature dist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load npy or dataset.\n",
    "\n",
    "\n",
    "def plot_load_features(fea_path=None, fea=None):\n",
    "    \n",
    "    if fea is None:\n",
    "        with open(fea_path, 'rb') as f:\n",
    "            node_feature = pk.load(f)\n",
    "            # NOTE: pack into feature dist\n",
    "            print(node_feature[0].shape, node_feature[1].shape)\n",
    "            fea = np.concatenate(node_feature, axis=0)\n",
    "         \n",
    "    # note plot dist:\n",
    "    plt.figure()\n",
    "    plt.hist(fea[:, 0], 100, density=False, facecolor='g', alpha=0.75)\n",
    "    plt.xlabel('degree')\n",
    "    plt.ylabel('node amount')\n",
    "    plt.show()\n",
    "    \n",
    "    return fea\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutag_node_fea = plot_load_features('/li_zhengdao/github/GenerativeGNN/DATA/MUTAG/processed/MUTAG_add_degree.pkl')\n",
    "print(mutag_node_fea.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_node_fea = plot_load_features('/li_zhengdao/github/GenerativeGNN/DATA/IMDB-BINARY/processed/IMDB-BINARY_add_degree.pkl')\n",
    "print(imdb_node_fea.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/li_zhengdao/github/GenerativeGNN/DATA/IMDB-BINARY/processed/IMDB-BINARY_add_degree.pkl', 'rb') as f:\n",
    "    node_feature = pk.load(f)\n",
    "    dd = []\n",
    "    for n in node_feature:\n",
    "        dd.append((np.max(n),np.min(n)))\n",
    "    # sort:\n",
    "    sdd = sorted(dd, key=lambda x:x[0])\n",
    "    max_dd = [s[0] for s in sdd]\n",
    "    min_dd = [s[1] for s in sdd]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(max_dd)\n",
    "    plt.plot(min_dd)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    a = np.random.randint(1, 2)\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_idfea():\n",
    "    feas = []\n",
    "    with open('/li_zhengdao/github/GenerativeGNN/DATA/MUTAG/processed/MUTAG_add_degree.pkl', 'rb') as f:\n",
    "        node_feature = pk.load(f)\n",
    "        # NOTE: pack into feature dist\n",
    "        for no in node_feature:\n",
    "            feas.append(np.random.randint(1, int(4*1.0), size=no.shape[0]).reshape(no.shape[0], 1).astype(np.float32))\n",
    "    return np.concatenate(feas, axis=0)\n",
    "\n",
    "id_fea = plot_load_features(fea=generate_idfea())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check label balance:\n",
    "1-63.0/(188.0)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: pick the best config from each fold?\n",
    "# what is the majority one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
